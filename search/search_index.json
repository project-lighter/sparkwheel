{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sparkwheel","text":""},{"location":"#_1","title":"Sparkwheel","text":"<pre><code>pip install sparkwheel\n</code></pre> <ul> <li> <p> Declarative Configuration</p> <p>Define complex Python objects in clean YAML files. Replace boilerplate instantiation code with simple <code>_target_</code> declarations.</p> </li> <li> <p> Smart References</p> <p>Use <code>@</code> for resolved references (instantiated objects, computed values) or <code>%</code> for raw references (unprocessed YAML). Keep configurations DRY and maintainable.</p> </li> <li> <p> Flexible Composition</p> <p>Configs compose naturally by default (merge dicts, extend lists). Use <code>=</code> to replace or <code>~</code> to delete. Build modular configs for experiments and environments.</p> </li> <li> <p> Python Expressions</p> <p>Execute code with <code>$</code> prefix. Compute values, call functions, and create dynamic configurations on the fly.</p> </li> <li> <p> Schema Validation</p> <p>Validate configs with Python dataclasses. Catch errors early with type checking and required field validation.</p> </li> <li> <p> CLI Overrides</p> <p>Override any config value from command line. Perfect for hyperparameter sweeps and quick experiments.</p> </li> </ul>"},{"location":"#python-objects-from-yaml","title":"Python Objects from YAML","text":"<p>If you're tired of hardcoding parameters and want configuration-driven workflows, Sparkwheel makes it effortless. Define components in YAML, reference and compose them freely, then instantiate in Python.</p> ConfigPythonExperiment Override config.yaml<pre><code>dataset:\n  path: \"/data/train\"\n  num_classes: 10\n  batch_size: 32\n\nmodel:\n  _target_: torch.nn.Sequential\n  _args_:\n    - _target_: torch.nn.Linear\n      in_features: 784\n      out_features: \"@dataset::num_classes\"  # Reference!\n    - _target_: torch.nn.ReLU\n\ntraining:\n  epochs: 10\n  learning_rate: 0.001\n  steps_per_epoch: \"$10000 // @dataset::batch_size\"  # Expression!\n</code></pre> train.py<pre><code>from sparkwheel import Config\n\n# Load config (or multiple configs!)\nconfig = Config.load(\"config.yaml\")\n\n# Access raw values\nbatch_size = config[\"dataset::batch_size\"]  # 32\n\n# Resolve references and expressions\nsteps = config.resolve(\"training::steps_per_epoch\")  # 312\n\n# Instantiate Python objects automatically\nmodel = config.resolve(\"model\")  # Actual torch.nn.Sequential!\n</code></pre> experiment_large.yaml<pre><code># Override specific values, keep the rest (merges by default!)\nmodel:\n  _args_:\n    - 0:  # Override first layer\n        out_features: 20  # More classes\n\ntraining:\n  learning_rate: 0.0001  # Lower LR\n  # epochs inherited from base!\n</code></pre> <pre><code># Load base + experiment (composes automatically!)\nconfig = Config.load([\"config.yaml\", \"experiment_large.yaml\"])\n\n# Or override from CLI\nconfig = Config.from_cli(\n    \"config.yaml\",\n    [\"training::learning_rate=0.01\", \"dataset::batch_size=64\"]\n)\n</code></pre>"},{"location":"#understanding-references","title":"Understanding References","text":"<p>Sparkwheel has two types of references with distinct purposes:</p> <p>@ - Resolved References</p> <p>Get the final, computed value after instantiation and evaluation.</p> <pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\n# @ follows the reference and gets the instantiated object\ntrained_model: \"@model\"  # Gets the actual torch.nn.Linear instance\n</code></pre> <p>Use <code>@</code> when you want the result of computation.</p> <p>% - Raw References</p> <p>Get the unprocessed YAML content before any resolution.</p> <pre><code># base.yaml\ndefaults:\n  learning_rate: 0.001\n\n# config.yaml\n# % copies the raw YAML definition (can be from external files or same file)\noptimizer:\n  lr: \"%base.yaml::defaults::learning_rate\"  # Gets raw value: 0.001\n\n# Or reference within same file\nbackup_defaults: \"%defaults\"  # Gets the entire defaults dict as-is\n</code></pre> <p>Use <code>%</code> when you want to copy/import raw YAML (like copy-paste).</p>"},{"location":"#why-sparkwheel","title":"Why Sparkwheel?","text":"<p>Familiar, But More Powerful</p> <p>If you've used Hydra or OmegaConf, you'll feel right at home. Sparkwheel adds:</p> <ul> <li>Composition-by-default - Configs merge/extend naturally, no operators needed for common case</li> <li>List extension - Lists extend by default (unique vs Hydra!)</li> <li><code>=</code> replace operator - Explicit control when you need replacement</li> <li><code>~</code> delete operator - Remove inherited keys cleanly (idempotent!)</li> <li>Python expressions with <code>$</code> - Compute values dynamically</li> <li>Dataclass validation - Type-safe configs without boilerplate</li> <li>Dual reference system - <code>@</code> for resolved values, <code>%</code> for raw YAML</li> <li>Simpler API - Less magic, clearer behavior</li> </ul> <pre><code># Merges by default - no operator needed!\nmodel:\n  hidden_size: 1024  # Override just this\n  ~dropout: null     # Remove dropout\n  # Other fields preserved automatically!\n</code></pre>"},{"location":"#start-learning","title":"Start Learning","text":"<ul> <li> <p> Quick Start</p> <p>Get productive in 5 minutes with a hands-on tutorial</p> <p> Quick Start</p> </li> <li> <p> User Guide</p> <p>Deep dive into references, expressions, and composition</p> <p> Core Concepts</p> </li> <li> <p> Examples</p> <p>See complete real-world configuration patterns</p> <p> View Examples</p> </li> <li> <p> API Reference</p> <p>Complete API documentation and reference</p> <p> Browse API</p> </li> </ul>"},{"location":"#feature-deep-dives","title":"Feature Deep Dives","text":"<ul> <li> <p> References</p> <p>Link config values with <code>@</code> to eliminate duplication</p> </li> <li> <p> Expressions</p> <p>Execute Python code in configs with <code>$</code></p> </li> <li> <p> Composition &amp; Operators</p> <p>Composition-by-default with <code>=</code> (replace) and <code>~</code> (delete) operators</p> </li> <li> <p> Schema Validation</p> <p>Validate with Python dataclasses</p> </li> <li> <p> CLI Support</p> <p>Override configs from command line</p> </li> <li> <p> Instantiation</p> <p>Create Python objects with <code>_target_</code></p> </li> </ul>"},{"location":"#about","title":"About","text":"<p>Sparkwheel is a hard fork of MONAI Bundle's configuration system, refined and expanded for general-purpose use. We're deeply grateful to the MONAI team for their excellent foundation.</p> <p>Sparkwheel powers Lighter, a configuration-driven deep learning framework built on PyTorch Lightning.</p> <p>Ready to contribute?  View on GitHub</p> <p></p>"},{"location":"examples/custom-classes/","title":"Custom Classes Example","text":"<p>Using Sparkwheel with your own classes.</p>"},{"location":"examples/custom-classes/#python-code","title":"Python Code","text":"<pre><code># myproject/models.py\nclass CustomModel:\n    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n\n    def forward(self, x):\n        # Your model logic\n        pass\n</code></pre>"},{"location":"examples/custom-classes/#configuration","title":"Configuration","text":"<pre><code># config.yaml\nmodel:\n  _target_: myproject.models.CustomModel\n  input_size: 784\n  hidden_size: 256\n  output_size: 10\n</code></pre>"},{"location":"examples/custom-classes/#usage","title":"Usage","text":"<pre><code>from sparkwheel import Config\n\nconfig = Config.load(\"config.yaml\")\n\nmodel = config.resolve(\"model\")\n# model is now an instance of CustomModel!\n</code></pre>"},{"location":"examples/deep-learning/","title":"Deep Learning Example","text":"<p>Complete deep learning setup with model, optimizer, and data pipeline.</p>"},{"location":"examples/deep-learning/#configuration","title":"Configuration","text":"<pre><code># training_config.yaml\ndataset:\n  root: \"/data/cifar10\"\n  num_classes: 10\n\ntransforms:\n  train:\n    _target_: torchvision.transforms.Compose\n    transforms:\n      - _target_: torchvision.transforms.RandomHorizontalFlip\n      - _target_: torchvision.transforms.ToTensor\n      - _target_: torchvision.transforms.Normalize\n        mean: [0.485, 0.456, 0.406]\n        std: [0.229, 0.224, 0.225]\n\nmodel:\n  _target_: torchvision.models.resnet18\n  num_classes: \"@dataset::num_classes\"\n\noptimizer:\n  _target_: torch.optim.Adam\n  params: \"$@model.parameters()\"\n  lr: 0.001\n\nscheduler:\n  _target_: torch.optim.lr_scheduler.StepLR\n  optimizer: \"@optimizer\"\n  step_size: 30\n  gamma: 0.1\n\ntraining:\n  epochs: 100\n  batch_size: 64\n  device: \"$'cuda' if torch.cuda.is_available() else 'cpu'\"\n</code></pre> <p>See the User Guide for more details.</p>"},{"location":"examples/simple/","title":"Simple Configuration Example","text":"<p>A basic example showing core Sparkwheel features.</p>"},{"location":"examples/simple/#configuration-file","title":"Configuration File","text":"<pre><code># simple_config.yaml\nproject:\n  name: \"Image Classifier\"\n  version: \"1.0.0\"\n\ndataset:\n  path: \"/data/images\"\n  num_classes: 10\n  image_size: 224\n\nmodel:\n  _target_: torch.nn.Linear\n  in_features: \"$@dataset::image_size ** 2 * 3\"  # 224*224*3\n  out_features: \"@dataset::num_classes\"\n\ntraining:\n  batch_size: 32\n  epochs: 10\n  learning_rate: 0.001\n</code></pre>"},{"location":"examples/simple/#usage","title":"Usage","text":"<pre><code>import torch\nfrom sparkwheel import Config\n\n# Load configuration\nconfig = Config.load(\"simple_config.yaml\")\n\n# Get values\nproject_name = config[\"project\"][\"name\"]\nnum_classes = config[\"dataset\"][\"num_classes\"]\n\n# Instantiate model\nmodel = config.resolve(\"model\")\nprint(model)\n\n# Access training parameters\nbatch_size = config[\"training\"][\"batch_size\"]\nepochs = config[\"training\"][\"epochs\"]\nlr = config[\"training\"][\"learning_rate\"]\n\nprint(f\"Training {project_name} for {epochs} epochs with lr={lr}\")\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Sparkwheel requires Python 3.10 or higher.</p>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>The simplest way to install Sparkwheel:</p> <pre><code>pip install sparkwheel\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<p>For the latest development version:</p> <pre><code>git clone https://github.com/project-lighter/sparkwheel.git\ncd sparkwheel\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#development-setup","title":"Development Setup","text":"<p>If you want to contribute to Sparkwheel, we use uv and just for development:</p>"},{"location":"getting-started/installation/#install-uv","title":"Install uv","text":"<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"getting-started/installation/#install-just","title":"Install just","text":"macOSLinuxWindows <pre><code>brew install just\n</code></pre> <pre><code># Using cargo\ncargo install just\n\n# Or download binary from GitHub releases\n</code></pre> <pre><code># Using cargo\ncargo install just\n\n# Or use scoop\nscoop install just\n</code></pre>"},{"location":"getting-started/installation/#setup-development-environment","title":"Setup Development Environment","text":"<pre><code>git clone https://github.com/project-lighter/sparkwheel.git\ncd sparkwheel\njust setup\n</code></pre> <p>This will:</p> <ul> <li>Install all dependencies (including dev, test, and doc groups)</li> <li>Set up pre-commit hooks</li> <li>Configure your development environment</li> </ul>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Test that Sparkwheel is installed correctly:</p> <pre><code>import sparkwheel\nprint(sparkwheel.__version__)\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Sparkwheel has minimal dependencies (only PyYAML). However, for certain use cases you might want:</p>"},{"location":"getting-started/installation/#for-deep-learning","title":"For Deep Learning","text":"<pre><code>pip install torch torchvision  # PyTorch\n# or\npip install tensorflow  # TensorFlow\n</code></pre>"},{"location":"getting-started/installation/#for-development","title":"For Development","text":"<p>All development dependencies are included in the <code>dev</code> dependency group:</p> <pre><code>uv sync --all-groups\n</code></pre> <p>This includes:</p> <ul> <li>Testing: pytest, pytest-cov, coverage</li> <li>Code quality: ruff, mypy</li> <li>Documentation: mkdocs and plugins</li> <li>Tools: pre-commit, bump-my-version</li> </ul>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Learn the basics</li> <li>User Guide - Deep dive into features</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get productive with Sparkwheel in 5 minutes.</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<pre><code>pip install sparkwheel\n</code></pre>"},{"location":"getting-started/quickstart/#your-first-config","title":"Your First Config","text":"<p>Create a file <code>config.yaml</code>:</p> <pre><code># config.yaml\ndataset:\n  path: \"/data/train\"\n  num_classes: 10\n  batch_size: 32\n\nmodel:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: \"@dataset::num_classes\"  # Reference!\n\ntraining:\n  epochs: 10\n  learning_rate: 0.001\n  steps_per_epoch: \"$10000 // @dataset::batch_size\"  # Expression!\n</code></pre> <p>Load and use it in Python:</p> <pre><code>from sparkwheel import Config\n\n# Load the config\nconfig = Config.load(\"config.yaml\")\n\n# Access values with path notation\nbatch_size = config[\"dataset::batch_size\"]  # 32\nepochs = config[\"training::epochs\"]  # 10\n\n# Resolve references and expressions\nsteps = config.resolve(\"training::steps_per_epoch\")  # 312 (10000 // 32)\n\n# Instantiate objects\nmodel = config.resolve(\"model\")  # Actual torch.nn.Linear(784, 10) instance!\n\nprint(f\"Training for {epochs} epochs with batch size {batch_size}\")\nprint(f\"Model: {model}\")\n</code></pre> <p>That's it! You just:</p> <ul> <li>\u2713 Loaded a YAML config</li> <li>\u2713 Referenced resolved values with <code>@</code> (gets instantiated/computed results)</li> <li>\u2713 Computed values with <code>$</code> (Python expressions)</li> <li>\u2713 Instantiated a Python object from config with <code>_target_</code></li> </ul> <p>Two Types of References</p> <ul> <li><code>@</code> = Resolved reference - gets the final instantiated/evaluated value</li> <li><code>%</code> = Raw reference - copies unprocessed YAML content (from same or external file)</li> </ul>"},{"location":"getting-started/quickstart/#experiment-without-copying","title":"Experiment Without Copying","text":"<p>Create a variant without duplicating the base config (merges automatically!):</p> <pre><code># experiment_large.yaml\nmodel:  # Merges by default - no operator needed!\n  in_features: 1568  # Override just this\n  # out_features is still @dataset::num_classes\n\ntraining:\n  learning_rate: 0.0001  # Lower learning rate\n  # epochs and steps_per_epoch inherited from base\n</code></pre> <p>Load both configs:</p> <pre><code>config = Config.load([\"config.yaml\", \"experiment_large.yaml\"])\n\nmodel = config.resolve(\"model\")  # Linear(1568, 10) - merged automatically!\nlr = config[\"training::learning_rate\"]  # 0.0001\nepochs = config[\"training::epochs\"]  # 10 (inherited)\n</code></pre> <p>Sparkwheel composes by default! Dicts merge and lists extend - no operators needed for the common case.</p>"},{"location":"getting-started/quickstart/#cli-overrides","title":"CLI Overrides","text":"<p>Override values from the command line without editing files:</p> <pre><code># train.py\nfrom sparkwheel import Config\nimport sys\n\nconfig = Config.from_cli(\"config.yaml\", sys.argv[1:])\n# ... use config ...\n</code></pre> <p>Run with overrides:</p> <pre><code>python train.py training::learning_rate=0.01 dataset::batch_size=64\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've seen the basics:</p> <ul> <li>Core Concepts - Learn more about references, expressions, and instantiation</li> <li>Examples - See complete real-world examples</li> <li>Composition &amp; Operators - Master config composition with <code>=</code> and <code>~</code></li> <li>Schema Validation - Validate configs with dataclasses</li> </ul>"},{"location":"reference/","title":"sparkwheel","text":"<p>sparkwheel: A powerful YAML-based configuration system with references, expressions, and dynamic instantiation.</p> <p>Uses YAML format only.</p> <ul> <li>loader</li> <li>utils</li> <li>path_patterns</li> <li>cli</li> <li>items</li> <li>metadata</li> <li>preprocessor</li> <li>resolver</li> <li>operators</li> <li>errors</li> <li>path_utils</li> <li>parser</li> <li>config</li> <li>schema</li> </ul>"},{"location":"reference/#sparkwheel.BaseError","title":"<code>BaseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for sparkwheel with rich error context.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>The error message</p> <code>source_location</code> <p>Optional location in config file where error occurred</p> <code>suggestion</code> <p>Optional helpful suggestion for fixing the error</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class BaseError(Exception):\n    \"\"\"Base exception for sparkwheel with rich error context.\n\n    Attributes:\n        message: The error message\n        source_location: Optional location in config file where error occurred\n        suggestion: Optional helpful suggestion for fixing the error\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        source_location: SourceLocation | None = None,\n        suggestion: str | None = None,\n    ) -&gt; None:\n        self.source_location = source_location\n        self.suggestion = suggestion\n        self._original_message = message\n        super().__init__(self._format_message())\n\n    def _format_message(self) -&gt; str:\n        \"\"\"Format error message with source location and suggestions.\n\n        Critical info (file:line) is on the first line for Rich compatibility,\n        since Rich's traceback only shows the first line of exception messages.\n        \"\"\"\n        parts = []\n\n        # Put file:line on the FIRST line for Rich visibility\n        if self.source_location:\n            location = f\"{self.source_location.filepath}:{self.source_location.line}\"\n            if self.source_location.id:\n                parts.append(f\"[{location} @ {self.source_location.id}] {self._original_message}\")\n            else:\n                parts.append(f\"[{location}] {self._original_message}\")\n        else:\n            parts.append(self._original_message)\n\n        # Add code snippet on subsequent lines (will be visible in full traceback)\n        if self.source_location:\n            snippet = self._get_config_snippet()\n            if snippet:\n                parts.append(f\"\\n\\n{snippet}\")\n\n        if self.suggestion:\n            parts.append(f\"\\n\\n  \ud83d\udca1 {self.suggestion}\")\n\n        return \"\".join(parts)\n\n    def _get_config_snippet(self) -&gt; str:\n        \"\"\"Extract and format a code snippet from the config file.\"\"\"\n        if not self.source_location:\n            return \"\"\n\n        try:\n            filepath = Path(self.source_location.filepath)\n            if not filepath.exists():\n                return \"\"\n\n            with open(filepath) as f:\n                lines = f.readlines()\n\n            # Show 2 lines before and 1 line after the error\n            line_num = self.source_location.line\n            start = max(0, line_num - 3)\n            end = min(len(lines), line_num + 2)\n\n            snippet_lines = []\n            for i in range(start, end):\n                marker = \"\u2192\" if i == line_num - 1 else \" \"\n                # Use 4-digit line numbers for alignment\n                snippet_lines.append(f\"  {marker} {i + 1:4d} \u2502 {lines[i].rstrip()}\")\n\n            return \"\\n\".join(snippet_lines)\n        except Exception:\n            # If we can't read the file, just skip the snippet\n            return \"\"\n</code></pre>"},{"location":"reference/#sparkwheel.BaseError._format_message","title":"<code>_format_message()</code>","text":"<p>Format error message with source location and suggestions.</p> <p>Critical info (file:line) is on the first line for Rich compatibility, since Rich's traceback only shows the first line of exception messages.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _format_message(self) -&gt; str:\n    \"\"\"Format error message with source location and suggestions.\n\n    Critical info (file:line) is on the first line for Rich compatibility,\n    since Rich's traceback only shows the first line of exception messages.\n    \"\"\"\n    parts = []\n\n    # Put file:line on the FIRST line for Rich visibility\n    if self.source_location:\n        location = f\"{self.source_location.filepath}:{self.source_location.line}\"\n        if self.source_location.id:\n            parts.append(f\"[{location} @ {self.source_location.id}] {self._original_message}\")\n        else:\n            parts.append(f\"[{location}] {self._original_message}\")\n    else:\n        parts.append(self._original_message)\n\n    # Add code snippet on subsequent lines (will be visible in full traceback)\n    if self.source_location:\n        snippet = self._get_config_snippet()\n        if snippet:\n            parts.append(f\"\\n\\n{snippet}\")\n\n    if self.suggestion:\n        parts.append(f\"\\n\\n  \ud83d\udca1 {self.suggestion}\")\n\n    return \"\".join(parts)\n</code></pre>"},{"location":"reference/#sparkwheel.BaseError._get_config_snippet","title":"<code>_get_config_snippet()</code>","text":"<p>Extract and format a code snippet from the config file.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _get_config_snippet(self) -&gt; str:\n    \"\"\"Extract and format a code snippet from the config file.\"\"\"\n    if not self.source_location:\n        return \"\"\n\n    try:\n        filepath = Path(self.source_location.filepath)\n        if not filepath.exists():\n            return \"\"\n\n        with open(filepath) as f:\n            lines = f.readlines()\n\n        # Show 2 lines before and 1 line after the error\n        line_num = self.source_location.line\n        start = max(0, line_num - 3)\n        end = min(len(lines), line_num + 2)\n\n        snippet_lines = []\n        for i in range(start, end):\n            marker = \"\u2192\" if i == line_num - 1 else \" \"\n            # Use 4-digit line numbers for alignment\n            snippet_lines.append(f\"  {marker} {i + 1:4d} \u2502 {lines[i].rstrip()}\")\n\n        return \"\\n\".join(snippet_lines)\n    except Exception:\n        # If we can't read the file, just skip the snippet\n        return \"\"\n</code></pre>"},{"location":"reference/#sparkwheel.CircularReferenceError","title":"<code>CircularReferenceError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when circular references are detected in config.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class CircularReferenceError(BaseError):\n    \"\"\"Raised when circular references are detected in config.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#sparkwheel.Component","title":"<code>Component</code>","text":"<p>               Bases: <code>Item</code>, <code>Instantiable</code></p> <p>Component that can be instantiated from configuration.</p> <p>Uses a dictionary with string keys to represent a Python class or function that can be dynamically instantiated. Other keys are passed as arguments to the target component.</p> Example <pre><code>from sparkwheel import Component\nfrom collections import Counter\n\nconfig = {\n    \"_target_\": \"collections.Counter\",\n    \"iterable\": [1, 2, 2, 3, 3, 3]\n}\n\ncomponent = Component(config, id=\"counter\")\ncounter = component.instantiate()\nprint(counter)  # Counter({3: 3, 2: 2, 1: 1})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Configuration content</p> required <code>id</code> <code>str</code> <p>Identifier for this config item, defaults to \"\"</p> <code>''</code> Note <p>Special configuration keys:</p> <ul> <li><code>_target_</code>: Full module path (e.g., \"collections.Counter\")</li> <li><code>_requires_</code>: Dependencies to evaluate/instantiate first</li> <li><code>_disabled_</code>: Skip instantiation if True</li> <li><code>_mode_</code>: Instantiation mode:<ul> <li><code>\"default\"</code>: Returns component(**kwargs)</li> <li><code>\"callable\"</code>: Returns functools.partial(component, **kwargs)</li> <li><code>\"debug\"</code>: Returns pdb.runcall(component, **kwargs)</li> </ul> </li> </ul> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Component(Item, Instantiable):\n    \"\"\"Component that can be instantiated from configuration.\n\n    Uses a dictionary with string keys to represent a Python class or function\n    that can be dynamically instantiated. Other keys are passed as arguments\n    to the target component.\n\n    Example:\n        ```python\n        from sparkwheel import Component\n        from collections import Counter\n\n        config = {\n            \"_target_\": \"collections.Counter\",\n            \"iterable\": [1, 2, 2, 3, 3, 3]\n        }\n\n        component = Component(config, id=\"counter\")\n        counter = component.instantiate()\n        print(counter)  # Counter({3: 3, 2: 2, 1: 1})\n        ```\n\n    Args:\n        config: Configuration content\n        id: Identifier for this config item, defaults to \"\"\n\n    Note:\n        Special configuration keys:\n\n        - `_target_`: Full module path (e.g., \"collections.Counter\")\n        - `_requires_`: Dependencies to evaluate/instantiate first\n        - `_disabled_`: Skip instantiation if True\n        - `_mode_`: Instantiation mode:\n            - `\"default\"`: Returns component(**kwargs)\n            - `\"callable\"`: Returns functools.partial(component, **kwargs)\n            - `\"debug\"`: Returns pdb.runcall(component, **kwargs)\n    \"\"\"\n\n    non_arg_keys = {\"_target_\", \"_disabled_\", \"_requires_\", \"_mode_\"}\n\n    def __init__(self, config: Any, id: str = \"\", source_location: SourceLocation | None = None) -&gt; None:\n        super().__init__(config=config, id=id, source_location=source_location)\n\n    @staticmethod\n    def is_instantiable(config: Any) -&gt; bool:\n        \"\"\"\n        Check whether this config represents a `class` or `function` that is to be instantiated.\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        return isinstance(config, Mapping) and \"_target_\" in config\n\n    def resolve_module_name(self):\n        \"\"\"Resolve the target module name from configuration.\n\n        Requires full module path (e.g., \"collections.Counter\").\n        No automatic module discovery is performed.\n\n        Returns:\n            str or callable: The module path or callable from _target_\n        \"\"\"\n        config = dict(self.get_config())\n        target = config.get(\"_target_\")\n        if not isinstance(target, str):\n            return target  # for cases where _target_ is already a callable\n\n        # No ComponentLocator - just return the target as-is (must be full path)\n        return target\n\n    def resolve_args(self):\n        \"\"\"\n        Utility function used in `instantiate()` to resolve the arguments from current config content.\n        \"\"\"\n        config = self.get_config()\n        if not isinstance(config, Mapping):\n            raise TypeError(\n                f\"Expected config to be a Mapping (dict-like), but got {type(config).__name__}. \"\n                f\"Cannot resolve arguments from non-mapping config.\"\n            )\n        return {k: v for k, v in config.items() if k not in self.non_arg_keys}\n\n    def is_disabled(self) -&gt; bool:\n        \"\"\"\n        Utility function used in `instantiate()` to check whether to skip the instantiation.\n        \"\"\"\n        _is_disabled = self.get_config().get(\"_disabled_\", False)\n        return _is_disabled.lower().strip() == \"true\" if isinstance(_is_disabled, str) else bool(_is_disabled)\n\n    def instantiate(self, **kwargs: Any) -&gt; object:\n        \"\"\"\n        Instantiate component based on ``self.config`` content.\n        The target component must be a `class` or a `function`, otherwise, return `None`.\n\n        Args:\n            kwargs: args to override / add the config args when instantiation.\n        \"\"\"\n        if not self.is_instantiable(self.get_config()) or self.is_disabled():\n            # if not a class or function or marked as `disabled`, skip parsing and return `None`\n            return None\n\n        modname = self.resolve_module_name()\n        mode = self.get_config().get(\"_mode_\", CompInitMode.DEFAULT)\n        args = self.resolve_args()\n        args.update(kwargs)\n\n        try:\n            return instantiate(modname, mode, **args)\n        except ModuleNotFoundError as e:\n            # Re-raise with source location and suggestions\n            suggestion = self._suggest_similar_modules(modname) if isinstance(modname, str) else None\n            raise ModuleNotFoundError(\n                f\"Cannot locate class or function: '{modname}'\",\n                source_location=self.source_location,\n                suggestion=suggestion,\n            ) from e\n        except Exception as e:\n            # Wrap other errors with location context (points to _target_ line)\n            raise InstantiationError(\n                f\"Failed to instantiate '{modname}': {type(e).__name__}: {e}\",\n                source_location=self.source_location,\n            ) from e\n\n    def _suggest_similar_modules(self, target: str) -&gt; str | None:\n        \"\"\"Suggest similar valid module names using fuzzy matching.\n\n        Args:\n            target: The module path that couldn't be found (e.g., 'torch.optim.Adamfad')\n\n        Returns:\n            A helpful suggestion string, or None if no good suggestions found.\n        \"\"\"\n        if not isinstance(target, str) or \".\" not in target:\n            return None\n\n        try:\n            from pydoc import locate\n\n            from .utils import damerau_levenshtein_distance\n\n            # Split into module path and attribute name\n            parts = target.rsplit(\".\", 1)\n            base_module, attr_name = parts[0], parts[1]\n\n            # Try to import the base module\n            base = locate(base_module)\n            if base is None:\n                return None\n\n            # Find similar attribute names in the module\n            similar = []\n            for name in dir(base):\n                if name.startswith(\"_\"):\n                    continue\n                distance = damerau_levenshtein_distance(name, attr_name)\n                if distance &lt;= 2:  # Allow up to 2 character edits\n                    similar.append((distance, name))\n\n            if similar:\n                # Sort by distance and return the closest match\n                similar.sort(key=lambda x: x[0])\n                closest = similar[0][1]\n                return f\"Did you mean '{base_module}.{closest}'?\"\n        except Exception:\n            # If anything fails during suggestion generation, just skip it\n            pass\n\n        return None\n</code></pre>"},{"location":"reference/#sparkwheel.Component._suggest_similar_modules","title":"<code>_suggest_similar_modules(target)</code>","text":"<p>Suggest similar valid module names using fuzzy matching.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The module path that couldn't be found (e.g., 'torch.optim.Adamfad')</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A helpful suggestion string, or None if no good suggestions found.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def _suggest_similar_modules(self, target: str) -&gt; str | None:\n    \"\"\"Suggest similar valid module names using fuzzy matching.\n\n    Args:\n        target: The module path that couldn't be found (e.g., 'torch.optim.Adamfad')\n\n    Returns:\n        A helpful suggestion string, or None if no good suggestions found.\n    \"\"\"\n    if not isinstance(target, str) or \".\" not in target:\n        return None\n\n    try:\n        from pydoc import locate\n\n        from .utils import damerau_levenshtein_distance\n\n        # Split into module path and attribute name\n        parts = target.rsplit(\".\", 1)\n        base_module, attr_name = parts[0], parts[1]\n\n        # Try to import the base module\n        base = locate(base_module)\n        if base is None:\n            return None\n\n        # Find similar attribute names in the module\n        similar = []\n        for name in dir(base):\n            if name.startswith(\"_\"):\n                continue\n            distance = damerau_levenshtein_distance(name, attr_name)\n            if distance &lt;= 2:  # Allow up to 2 character edits\n                similar.append((distance, name))\n\n        if similar:\n            # Sort by distance and return the closest match\n            similar.sort(key=lambda x: x[0])\n            closest = similar[0][1]\n            return f\"Did you mean '{base_module}.{closest}'?\"\n    except Exception:\n        # If anything fails during suggestion generation, just skip it\n        pass\n\n    return None\n</code></pre>"},{"location":"reference/#sparkwheel.Component.instantiate","title":"<code>instantiate(**kwargs)</code>","text":"<p>Instantiate component based on <code>self.config</code> content. The target component must be a <code>class</code> or a <code>function</code>, otherwise, return <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Any</code> <p>args to override / add the config args when instantiation.</p> <code>{}</code> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def instantiate(self, **kwargs: Any) -&gt; object:\n    \"\"\"\n    Instantiate component based on ``self.config`` content.\n    The target component must be a `class` or a `function`, otherwise, return `None`.\n\n    Args:\n        kwargs: args to override / add the config args when instantiation.\n    \"\"\"\n    if not self.is_instantiable(self.get_config()) or self.is_disabled():\n        # if not a class or function or marked as `disabled`, skip parsing and return `None`\n        return None\n\n    modname = self.resolve_module_name()\n    mode = self.get_config().get(\"_mode_\", CompInitMode.DEFAULT)\n    args = self.resolve_args()\n    args.update(kwargs)\n\n    try:\n        return instantiate(modname, mode, **args)\n    except ModuleNotFoundError as e:\n        # Re-raise with source location and suggestions\n        suggestion = self._suggest_similar_modules(modname) if isinstance(modname, str) else None\n        raise ModuleNotFoundError(\n            f\"Cannot locate class or function: '{modname}'\",\n            source_location=self.source_location,\n            suggestion=suggestion,\n        ) from e\n    except Exception as e:\n        # Wrap other errors with location context (points to _target_ line)\n        raise InstantiationError(\n            f\"Failed to instantiate '{modname}': {type(e).__name__}: {e}\",\n            source_location=self.source_location,\n        ) from e\n</code></pre>"},{"location":"reference/#sparkwheel.Component.is_disabled","title":"<code>is_disabled()</code>","text":"<p>Utility function used in <code>instantiate()</code> to check whether to skip the instantiation.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def is_disabled(self) -&gt; bool:\n    \"\"\"\n    Utility function used in `instantiate()` to check whether to skip the instantiation.\n    \"\"\"\n    _is_disabled = self.get_config().get(\"_disabled_\", False)\n    return _is_disabled.lower().strip() == \"true\" if isinstance(_is_disabled, str) else bool(_is_disabled)\n</code></pre>"},{"location":"reference/#sparkwheel.Component.is_instantiable","title":"<code>is_instantiable(config)</code>  <code>staticmethod</code>","text":"<p>Check whether this config represents a <code>class</code> or <code>function</code> that is to be instantiated.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@staticmethod\ndef is_instantiable(config: Any) -&gt; bool:\n    \"\"\"\n    Check whether this config represents a `class` or `function` that is to be instantiated.\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    return isinstance(config, Mapping) and \"_target_\" in config\n</code></pre>"},{"location":"reference/#sparkwheel.Component.resolve_args","title":"<code>resolve_args()</code>","text":"<p>Utility function used in <code>instantiate()</code> to resolve the arguments from current config content.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def resolve_args(self):\n    \"\"\"\n    Utility function used in `instantiate()` to resolve the arguments from current config content.\n    \"\"\"\n    config = self.get_config()\n    if not isinstance(config, Mapping):\n        raise TypeError(\n            f\"Expected config to be a Mapping (dict-like), but got {type(config).__name__}. \"\n            f\"Cannot resolve arguments from non-mapping config.\"\n        )\n    return {k: v for k, v in config.items() if k not in self.non_arg_keys}\n</code></pre>"},{"location":"reference/#sparkwheel.Component.resolve_module_name","title":"<code>resolve_module_name()</code>","text":"<p>Resolve the target module name from configuration.</p> <p>Requires full module path (e.g., \"collections.Counter\"). No automatic module discovery is performed.</p> <p>Returns:</p> Type Description <p>str or callable: The module path or callable from target</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def resolve_module_name(self):\n    \"\"\"Resolve the target module name from configuration.\n\n    Requires full module path (e.g., \"collections.Counter\").\n    No automatic module discovery is performed.\n\n    Returns:\n        str or callable: The module path or callable from _target_\n    \"\"\"\n    config = dict(self.get_config())\n    target = config.get(\"_target_\")\n    if not isinstance(target, str):\n        return target  # for cases where _target_ is already a callable\n\n    # No ComponentLocator - just return the target as-is (must be full path)\n    return target\n</code></pre>"},{"location":"reference/#sparkwheel.Config","title":"<code>Config</code>","text":"<p>Configuration management with resolved references, raw references, expressions, and instantiation.</p> <p>Main entry point for loading, managing, and resolving configurations. Supports YAML files with resolved references (@), raw references (%), expressions ($), and dynamic instantiation (target).</p> Example <pre><code>from sparkwheel import Config\n\n# Load from file\nconfig = Config.load(\"config.yaml\")\n\n# Load from dict\nconfig = Config.load({\"model\": {\"lr\": 0.001}})\n\n# Load multiple files (merged in order)\nconfig = Config.load([\"base.yaml\", \"override.yaml\"])\n\n# Access raw values\nlr = config.get(\"model::lr\")\n\n# Set values\nconfig.set(\"model::dropout\", 0.1)\n\n# Update with additional config\nconfig.update(\"experiment.yaml\")\nconfig.update({\"model::lr\": 0.01})\n\n# Resolve references and instantiate\nmodel = config.resolve(\"model\")\neverything = config.resolve()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict | None</code> <p>Initial configuration data</p> <code>None</code> <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions (e.g., {\"torch\": \"torch\"})</p> <code>None</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>class Config:\n    \"\"\"Configuration management with resolved references, raw references, expressions, and instantiation.\n\n    Main entry point for loading, managing, and resolving configurations.\n    Supports YAML files with resolved references (@), raw references (%), expressions ($),\n    and dynamic instantiation (_target_).\n\n    Example:\n        ```python\n        from sparkwheel import Config\n\n        # Load from file\n        config = Config.load(\"config.yaml\")\n\n        # Load from dict\n        config = Config.load({\"model\": {\"lr\": 0.001}})\n\n        # Load multiple files (merged in order)\n        config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n        # Access raw values\n        lr = config.get(\"model::lr\")\n\n        # Set values\n        config.set(\"model::dropout\", 0.1)\n\n        # Update with additional config\n        config.update(\"experiment.yaml\")\n        config.update({\"model::lr\": 0.01})\n\n        # Resolve references and instantiate\n        model = config.resolve(\"model\")\n        everything = config.resolve()\n        ```\n\n    Args:\n        data: Initial configuration data\n        globals: Pre-imported packages for expressions (e.g., {\"torch\": \"torch\"})\n    \"\"\"\n\n    def __init__(self, data: dict | None = None, globals: dict[str, Any] | None = None):\n        \"\"\"Initialize Config (use Config.load() instead for most cases).\n\n        Args:\n            data: Initial configuration dictionary\n            globals: Global variables for expression evaluation\n        \"\"\"\n        self._data: dict = data or {}\n        self._metadata = MetadataRegistry()\n        self._resolver = Resolver()\n        self._is_parsed = False\n\n        # Process globals (import string module paths)\n        self._globals: dict[str, Any] = {}\n        if isinstance(globals, dict):\n            for k, v in globals.items():\n                self._globals[k] = optional_import(v)[0] if isinstance(v, str) else v\n\n        self._loader = Loader()\n        self._preprocessor = Preprocessor(self._loader, self._globals)\n\n    @classmethod\n    def load(\n        cls,\n        source: PathLike | Sequence[PathLike] | dict,\n        globals: dict[str, Any] | None = None,\n        schema: type | None = None,\n    ) -&gt; \"Config\":\n        \"\"\"Load configuration from file(s) or dict.\n\n        Primary method for creating Config instances.\n\n        Args:\n            source: File path, list of paths, or config dict\n            globals: Pre-imported packages for expressions\n            schema: Optional dataclass schema for validation\n\n        Returns:\n            New Config instance\n\n        Merge Behavior:\n            Files are merged in order (composition-by-default). Use operators to control merging:\n            - key: value   - Compose (default): merge dict or extend list\n            - =key: value  - Replace operator: completely replace value\n            - ~key: null   - Remove operator: delete key (idempotent)\n\n        Examples:\n            &gt;&gt;&gt; # Single file\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n\n            &gt;&gt;&gt; # Multiple files (merged)\n            &gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n            &gt;&gt;&gt; # From dict\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n\n            &gt;&gt;&gt; # With globals for expressions\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n\n            &gt;&gt;&gt; # With schema validation\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class MySchema:\n            ...     name: str\n            ...     value: int\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n        \"\"\"\n        config = cls(globals=globals)\n\n        # Handle dict input\n        if isinstance(source, dict):\n            config._data = source\n            if schema is not None:\n                config.validate(schema)\n            return config\n\n        # Handle file(s) input\n        file_list = ensure_tuple(source)\n        for filepath in file_list:\n            loaded_data, loaded_metadata = config._loader.load_file(filepath)\n            # Validate operators before applying\n            validate_operators(loaded_data)\n            # Merge data and metadata\n            config._data = apply_operators(config._data, loaded_data)\n            config._metadata.merge(loaded_metadata)\n\n        # Validate against schema if provided\n        if schema is not None:\n            config.validate(schema)\n\n        return config\n\n    @classmethod\n    def from_cli(\n        cls,\n        source: PathLike | Sequence[PathLike] | dict,\n        cli_overrides: list[str],\n        globals: dict[str, Any] | None = None,\n        schema: type | None = None,\n    ) -&gt; \"Config\":\n        \"\"\"Load configuration with CLI overrides applied.\n\n        Convenience method for loading configs with command-line overrides.\n        First loads the base config, then applies CLI overrides in the format\n        \"key::path=value\", and optionally validates against a schema.\n\n        Args:\n            source: File path, list of paths, or config dict\n            cli_overrides: List of override strings in format \"key::path=value\"\n            globals: Pre-imported packages for expressions\n            schema: Optional dataclass schema for validation\n\n        Returns:\n            New Config instance with CLI overrides applied\n\n        Examples:\n            &gt;&gt;&gt; # Load with CLI overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n            ... )\n\n            &gt;&gt;&gt; # Multiple files with overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     [\"base.yaml\", \"experiment.yaml\"],\n            ...     [\"model::lr=0.001\"]\n            ... )\n\n            &gt;&gt;&gt; # With schema validation\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class TrainingConfig:\n            ...     model: dict\n            ...     trainer: dict\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\"model::lr=0.001\"],\n            ...     schema=TrainingConfig\n            ... )\n\n            &gt;&gt;&gt; # Complex overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\n            ...         \"model::lr=0.001\",\n            ...         \"trainer::devices=[0,1,2]\",\n            ...         \"model::layers=[128,256,512]\",\n            ...         \"debug=True\"\n            ...     ]\n            ... )\n        \"\"\"\n        from .cli import parse_overrides\n\n        # Load base configuration\n        config = cls.load(source, globals=globals, schema=schema)\n\n        # Apply CLI overrides\n        if cli_overrides:\n            overrides = parse_overrides(cli_overrides)\n            for key, value in overrides.items():\n                config.set(key, value)\n\n            # Re-validate after overrides if schema provided\n            if schema is not None:\n                config.validate(schema)\n\n        return config\n\n    def get(self, id: str = \"\", default: Any = None) -&gt; Any:\n        \"\"\"Get raw config value (unresolved).\n\n        Args:\n            id: Configuration path (use :: for nesting, e.g., \"model::lr\")\n                Empty string returns entire config\n            default: Default value if id not found\n\n        Returns:\n            Raw configuration value (resolved references not resolved, raw references not expanded)\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}})\n            &gt;&gt;&gt; config.get(\"model::lr\")\n            0.001\n            &gt;&gt;&gt; config.get(\"model::ref\")\n            \"@model::lr\"  # Unresolved resolved reference\n        \"\"\"\n        try:\n            return self._get_by_id(id)\n        except (KeyError, IndexError, ValueError):\n            return default\n\n    def set(self, id: str, value: Any) -&gt; None:\n        \"\"\"Set config value, creating paths as needed.\n\n        Args:\n            id: Configuration path (use :: for nesting)\n            value: Value to set\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({})\n            &gt;&gt;&gt; config.set(\"model::lr\", 0.001)\n            &gt;&gt;&gt; config.get(\"model::lr\")\n            0.001\n        \"\"\"\n        if id == \"\":\n            self._data = value\n            self._invalidate_resolution()\n            return\n\n        keys = split_id(id)\n\n        # Ensure root is dict\n        if not isinstance(self._data, dict):\n            self._data = {}\n\n        # Create missing intermediate paths\n        current = self._data\n        for k in keys[:-1]:\n            if k not in current:\n                current[k] = {}\n            elif not isinstance(current[k], dict):\n                current[k] = {}\n            current = current[k]\n\n        # Set final value\n        current[keys[-1]] = value\n        self._invalidate_resolution()\n\n    def validate(self, schema: type) -&gt; None:\n        \"\"\"Validate configuration against a dataclass schema.\n\n        Args:\n            schema: Dataclass type defining the expected structure and types\n\n        Raises:\n            ValidationError: If configuration doesn't match schema\n            TypeError: If schema is not a dataclass\n\n        Example:\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class ModelConfig:\n            ...     hidden_size: int\n            ...     dropout: float\n            &gt;&gt;&gt; config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1})\n            &gt;&gt;&gt; config.validate(ModelConfig)  # Passes\n            &gt;&gt;&gt; bad_config = Config.load({\"hidden_size\": \"not an int\"})\n            &gt;&gt;&gt; bad_config.validate(ModelConfig)  # Raises ValidationError\n        \"\"\"\n        from .schema import validate as validate_schema\n\n        validate_schema(self._data, schema, metadata=self._metadata)\n\n    def update(self, source: PathLike | dict | \"Config\") -&gt; None:\n        \"\"\"Update configuration with changes from another source.\n\n        Applies changes using operators for fine-grained control.\n        Supports nested paths (::) and compose/replace/delete operators.\n\n        Args:\n            source: File path, dict, or Config instance to update from\n\n        Operators:\n            - key: value   - Compose (default): merge dict or extend list\n            - =key: value  - Replace operator: completely replace value\n            - ~key: null   - Remove operator: delete key (idempotent)\n\n        Examples:\n            &gt;&gt;&gt; # Update from file\n            &gt;&gt;&gt; config.update(\"override.yaml\")\n\n            &gt;&gt;&gt; # Update from dict (merges by default)\n            &gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n\n            &gt;&gt;&gt; # Update from another Config instance\n            &gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n            &gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n            &gt;&gt;&gt; config1.update(config2)\n\n            &gt;&gt;&gt; # Nested path updates\n            &gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n        \"\"\"\n        if isinstance(source, Config):\n            self._update_from_config(source)\n        elif isinstance(source, dict):\n            if self._uses_nested_paths(source):\n                self._apply_path_updates(source)\n            else:\n                self._apply_structural_update(source)\n        else:\n            self._update_from_file(source)\n\n    def _update_from_config(self, source: \"Config\") -&gt; None:\n        \"\"\"Update from another Config instance.\"\"\"\n        self._data = apply_operators(self._data, source._data)\n        self._metadata.merge(source._metadata)\n        self._invalidate_resolution()\n\n    def _uses_nested_paths(self, source: dict) -&gt; bool:\n        \"\"\"Check if dict uses :: path syntax.\"\"\"\n        return any(ID_SEP_KEY in str(k).lstrip(REPLACE_KEY).lstrip(REMOVE_KEY) for k in source.keys())\n\n    def _apply_path_updates(self, source: dict) -&gt; None:\n        \"\"\"Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).\"\"\"\n        for key, value in source.items():\n            if not isinstance(key, str):\n                self.set(str(key), value)\n                continue\n\n            if key.startswith(REPLACE_KEY):\n                # Replace operator: =key (explicit override)\n                actual_key = key[1:]\n                self.set(actual_key, value)\n\n            elif key.startswith(REMOVE_KEY):\n                # Delete operator: ~key (idempotent)\n                actual_key = key[1:]\n                _validate_delete_operator(actual_key, value)\n\n                if actual_key in self:\n                    self._delete_nested_key(actual_key)\n\n            else:\n                # Default: compose (merge dict or extend list)\n                if key in self and isinstance(self[key], dict) and isinstance(value, dict):\n                    merged = apply_operators(self[key], value)\n                    self.set(key, merged)\n                elif key in self and isinstance(self[key], list) and isinstance(value, list):\n                    self.set(key, self[key] + value)\n                else:\n                    # Normal set (handles nested paths with ::)\n                    self.set(key, value)\n\n    def _delete_nested_key(self, key: str) -&gt; None:\n        \"\"\"Delete a key, supporting nested paths with ::.\"\"\"\n        if ID_SEP_KEY in key:\n            keys = split_id(key)\n            parent_id = ID_SEP_KEY.join(keys[:-1])\n            parent = self[parent_id] if parent_id else self._data\n            if isinstance(parent, dict) and keys[-1] in parent:\n                del parent[keys[-1]]\n        else:\n            # Top-level key\n            if isinstance(self._data, dict) and key in self._data:\n                del self._data[key]\n        self._invalidate_resolution()\n\n    def _apply_structural_update(self, source: dict) -&gt; None:\n        \"\"\"Apply structural update with operators.\"\"\"\n        validate_operators(source)\n        self._data = apply_operators(self._data, source)\n        self._invalidate_resolution()\n\n    def _update_from_file(self, source: PathLike) -&gt; None:\n        \"\"\"Load and update from a file.\"\"\"\n        new_data, new_metadata = self._loader.load_file(source)\n        validate_operators(new_data)\n        self._data = apply_operators(self._data, new_data)\n        self._metadata.merge(new_metadata)\n        self._invalidate_resolution()\n\n    def resolve(\n        self,\n        id: str = \"\",\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        lazy: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Resolve resolved references (@) and return parsed config.\n\n        Automatically parses config on first call. Resolves @ resolved references (follows\n        them to get instantiated/evaluated values), evaluates $ expressions, and\n        instantiates _target_ components. Note: % raw references are expanded during\n        preprocessing (before this stage).\n\n        Args:\n            id: Config path to resolve (empty string for entire config)\n            instantiate: Whether to instantiate components with _target_\n            eval_expr: Whether to evaluate $ expressions\n            lazy: Whether to use cached resolution\n            default: Default value if id not found (returns default.get_config() if Item)\n\n        Returns:\n            Resolved value (instantiated objects, evaluated expressions, etc.)\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\n            ...     \"lr\": 0.001,\n            ...     \"doubled\": \"$@lr * 2\",\n            ...     \"optimizer\": {\n            ...         \"_target_\": \"torch.optim.Adam\",\n            ...         \"lr\": \"@lr\"\n            ...     }\n            ... })\n            &gt;&gt;&gt; config.resolve(\"lr\")\n            0.001\n            &gt;&gt;&gt; config.resolve(\"doubled\")\n            0.002\n            &gt;&gt;&gt; optimizer = config.resolve(\"optimizer\")\n            &gt;&gt;&gt; type(optimizer).__name__\n            'Adam'\n        \"\"\"\n        # Parse if needed\n        if not self._is_parsed or not lazy:\n            self._parse()\n\n        # Resolve and return\n        try:\n            return self._resolver.resolve(id=id, instantiate=instantiate, eval_expr=eval_expr)\n        except (KeyError, ConfigKeyError):\n            if default is not None:\n                # If default is an Item, return its config\n                from .items import Item\n\n                if isinstance(default, Item):\n                    return default.get_config()\n                return default\n            raise\n\n    def _parse(self, reset: bool = True) -&gt; None:\n        \"\"\"Parse config tree and prepare for resolution.\n\n        Internal method called automatically by resolve().\n\n        Args:\n            reset: Whether to reset the resolver before parsing (default: True)\n        \"\"\"\n        # Reset resolver if requested\n        if reset:\n            self._resolver.reset()\n\n        # Stage 1: Preprocess (% raw references, @:: relative resolved IDs)\n        self._data = self._preprocessor.process(self._data, self._data, id=\"\")\n\n        # Stage 2: Parse config tree to create Items\n        parser = Parser(globals=self._globals, metadata=self._metadata)\n        items = parser.parse(self._data)\n\n        # Stage 3: Add items to resolver\n        self._resolver.add_items(items)\n\n        self._is_parsed = True\n\n    def _get_by_id(self, id: str) -&gt; Any:\n        \"\"\"Get config value by ID path.\n\n        Args:\n            id: ID path (e.g., \"model::lr\")\n\n        Returns:\n            Config value at that path\n\n        Raises:\n            KeyError: If path not found\n        \"\"\"\n        if id == \"\":\n            return self._data\n\n        config = self._data\n        for k in split_id(id):\n            if not isinstance(config, (dict, list)):\n                raise ValueError(f\"Config must be dict or list for key `{k}`, but got {type(config)}: {config}\")\n            try:\n                config = look_up_option(k, config, print_all_options=False) if isinstance(config, dict) else config[int(k)]\n            except ValueError as e:\n                raise KeyError(f\"Key not found: {k}\") from e\n\n        return config\n\n    def _invalidate_resolution(self) -&gt; None:\n        \"\"\"Invalidate cached resolution (called when config changes).\"\"\"\n        self._is_parsed = False\n        self._resolver.reset()\n\n    def __getitem__(self, id: str) -&gt; Any:\n        \"\"\"Get config value by ID (subscript access).\n\n        Args:\n            id: Configuration path\n\n        Returns:\n            Config value at that path\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n            &gt;&gt;&gt; config[\"model::lr\"]\n            0.001\n        \"\"\"\n        return self._get_by_id(id)\n\n    def __setitem__(self, id: str, value: Any) -&gt; None:\n        \"\"\"Set config value by ID (subscript access).\n\n        Args:\n            id: Configuration path\n            value: Value to set\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({})\n            &gt;&gt;&gt; config[\"model::lr\"] = 0.001\n        \"\"\"\n        self.set(id, value)\n\n    def __contains__(self, id: str) -&gt; bool:\n        \"\"\"Check if ID exists in config.\n\n        Args:\n            id: ID path to check\n\n        Returns:\n            True if exists, False otherwise\n        \"\"\"\n        try:\n            self._get_by_id(id)\n            return True\n        except (KeyError, IndexError, ValueError):\n            return False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of config.\"\"\"\n        return f\"Config({self._data})\"\n\n    @staticmethod\n    def export_config_file(config: dict, filepath: PathLike, **kwargs: Any) -&gt; None:\n        \"\"\"Export config to YAML file.\n\n        Args:\n            config: Config dict to export\n            filepath: Target file path\n            kwargs: Additional arguments for yaml.safe_dump\n        \"\"\"\n        import yaml\n\n        filepath_str = str(Path(filepath))\n        with open(filepath_str, \"w\") as f:\n            yaml.safe_dump(config, f, **kwargs)\n</code></pre>"},{"location":"reference/#sparkwheel.Config.__contains__","title":"<code>__contains__(id)</code>","text":"<p>Check if ID exists in config.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID path to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if exists, False otherwise</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __contains__(self, id: str) -&gt; bool:\n    \"\"\"Check if ID exists in config.\n\n    Args:\n        id: ID path to check\n\n    Returns:\n        True if exists, False otherwise\n    \"\"\"\n    try:\n        self._get_by_id(id)\n        return True\n    except (KeyError, IndexError, ValueError):\n        return False\n</code></pre>"},{"location":"reference/#sparkwheel.Config.__getitem__","title":"<code>__getitem__(id)</code>","text":"<p>Get config value by ID (subscript access).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Config value at that path</p> Example <p>config = Config.load({\"model\": {\"lr\": 0.001}}) config[\"model::lr\"] 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __getitem__(self, id: str) -&gt; Any:\n    \"\"\"Get config value by ID (subscript access).\n\n    Args:\n        id: Configuration path\n\n    Returns:\n        Config value at that path\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n        &gt;&gt;&gt; config[\"model::lr\"]\n        0.001\n    \"\"\"\n    return self._get_by_id(id)\n</code></pre>"},{"location":"reference/#sparkwheel.Config.__init__","title":"<code>__init__(data=None, globals=None)</code>","text":"<p>Initialize Config (use Config.load() instead for most cases).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict | None</code> <p>Initial configuration dictionary</p> <code>None</code> <code>globals</code> <code>dict[str, Any] | None</code> <p>Global variables for expression evaluation</p> <code>None</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __init__(self, data: dict | None = None, globals: dict[str, Any] | None = None):\n    \"\"\"Initialize Config (use Config.load() instead for most cases).\n\n    Args:\n        data: Initial configuration dictionary\n        globals: Global variables for expression evaluation\n    \"\"\"\n    self._data: dict = data or {}\n    self._metadata = MetadataRegistry()\n    self._resolver = Resolver()\n    self._is_parsed = False\n\n    # Process globals (import string module paths)\n    self._globals: dict[str, Any] = {}\n    if isinstance(globals, dict):\n        for k, v in globals.items():\n            self._globals[k] = optional_import(v)[0] if isinstance(v, str) else v\n\n    self._loader = Loader()\n    self._preprocessor = Preprocessor(self._loader, self._globals)\n</code></pre>"},{"location":"reference/#sparkwheel.Config.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of config.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of config.\"\"\"\n    return f\"Config({self._data})\"\n</code></pre>"},{"location":"reference/#sparkwheel.Config.__setitem__","title":"<code>__setitem__(id, value)</code>","text":"<p>Set config value by ID (subscript access).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required Example <p>config = Config.load({}) config[\"model::lr\"] = 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __setitem__(self, id: str, value: Any) -&gt; None:\n    \"\"\"Set config value by ID (subscript access).\n\n    Args:\n        id: Configuration path\n        value: Value to set\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({})\n        &gt;&gt;&gt; config[\"model::lr\"] = 0.001\n    \"\"\"\n    self.set(id, value)\n</code></pre>"},{"location":"reference/#sparkwheel.Config._apply_path_updates","title":"<code>_apply_path_updates(source)</code>","text":"<p>Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _apply_path_updates(self, source: dict) -&gt; None:\n    \"\"\"Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).\"\"\"\n    for key, value in source.items():\n        if not isinstance(key, str):\n            self.set(str(key), value)\n            continue\n\n        if key.startswith(REPLACE_KEY):\n            # Replace operator: =key (explicit override)\n            actual_key = key[1:]\n            self.set(actual_key, value)\n\n        elif key.startswith(REMOVE_KEY):\n            # Delete operator: ~key (idempotent)\n            actual_key = key[1:]\n            _validate_delete_operator(actual_key, value)\n\n            if actual_key in self:\n                self._delete_nested_key(actual_key)\n\n        else:\n            # Default: compose (merge dict or extend list)\n            if key in self and isinstance(self[key], dict) and isinstance(value, dict):\n                merged = apply_operators(self[key], value)\n                self.set(key, merged)\n            elif key in self and isinstance(self[key], list) and isinstance(value, list):\n                self.set(key, self[key] + value)\n            else:\n                # Normal set (handles nested paths with ::)\n                self.set(key, value)\n</code></pre>"},{"location":"reference/#sparkwheel.Config._apply_structural_update","title":"<code>_apply_structural_update(source)</code>","text":"<p>Apply structural update with operators.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _apply_structural_update(self, source: dict) -&gt; None:\n    \"\"\"Apply structural update with operators.\"\"\"\n    validate_operators(source)\n    self._data = apply_operators(self._data, source)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/#sparkwheel.Config._delete_nested_key","title":"<code>_delete_nested_key(key)</code>","text":"<p>Delete a key, supporting nested paths with ::.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _delete_nested_key(self, key: str) -&gt; None:\n    \"\"\"Delete a key, supporting nested paths with ::.\"\"\"\n    if ID_SEP_KEY in key:\n        keys = split_id(key)\n        parent_id = ID_SEP_KEY.join(keys[:-1])\n        parent = self[parent_id] if parent_id else self._data\n        if isinstance(parent, dict) and keys[-1] in parent:\n            del parent[keys[-1]]\n    else:\n        # Top-level key\n        if isinstance(self._data, dict) and key in self._data:\n            del self._data[key]\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/#sparkwheel.Config._get_by_id","title":"<code>_get_by_id(id)</code>","text":"<p>Get config value by ID path.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID path (e.g., \"model::lr\")</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Config value at that path</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If path not found</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _get_by_id(self, id: str) -&gt; Any:\n    \"\"\"Get config value by ID path.\n\n    Args:\n        id: ID path (e.g., \"model::lr\")\n\n    Returns:\n        Config value at that path\n\n    Raises:\n        KeyError: If path not found\n    \"\"\"\n    if id == \"\":\n        return self._data\n\n    config = self._data\n    for k in split_id(id):\n        if not isinstance(config, (dict, list)):\n            raise ValueError(f\"Config must be dict or list for key `{k}`, but got {type(config)}: {config}\")\n        try:\n            config = look_up_option(k, config, print_all_options=False) if isinstance(config, dict) else config[int(k)]\n        except ValueError as e:\n            raise KeyError(f\"Key not found: {k}\") from e\n\n    return config\n</code></pre>"},{"location":"reference/#sparkwheel.Config._invalidate_resolution","title":"<code>_invalidate_resolution()</code>","text":"<p>Invalidate cached resolution (called when config changes).</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _invalidate_resolution(self) -&gt; None:\n    \"\"\"Invalidate cached resolution (called when config changes).\"\"\"\n    self._is_parsed = False\n    self._resolver.reset()\n</code></pre>"},{"location":"reference/#sparkwheel.Config._parse","title":"<code>_parse(reset=True)</code>","text":"<p>Parse config tree and prepare for resolution.</p> <p>Internal method called automatically by resolve().</p> <p>Parameters:</p> Name Type Description Default <code>reset</code> <code>bool</code> <p>Whether to reset the resolver before parsing (default: True)</p> <code>True</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _parse(self, reset: bool = True) -&gt; None:\n    \"\"\"Parse config tree and prepare for resolution.\n\n    Internal method called automatically by resolve().\n\n    Args:\n        reset: Whether to reset the resolver before parsing (default: True)\n    \"\"\"\n    # Reset resolver if requested\n    if reset:\n        self._resolver.reset()\n\n    # Stage 1: Preprocess (% raw references, @:: relative resolved IDs)\n    self._data = self._preprocessor.process(self._data, self._data, id=\"\")\n\n    # Stage 2: Parse config tree to create Items\n    parser = Parser(globals=self._globals, metadata=self._metadata)\n    items = parser.parse(self._data)\n\n    # Stage 3: Add items to resolver\n    self._resolver.add_items(items)\n\n    self._is_parsed = True\n</code></pre>"},{"location":"reference/#sparkwheel.Config._update_from_config","title":"<code>_update_from_config(source)</code>","text":"<p>Update from another Config instance.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _update_from_config(self, source: \"Config\") -&gt; None:\n    \"\"\"Update from another Config instance.\"\"\"\n    self._data = apply_operators(self._data, source._data)\n    self._metadata.merge(source._metadata)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/#sparkwheel.Config._update_from_file","title":"<code>_update_from_file(source)</code>","text":"<p>Load and update from a file.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _update_from_file(self, source: PathLike) -&gt; None:\n    \"\"\"Load and update from a file.\"\"\"\n    new_data, new_metadata = self._loader.load_file(source)\n    validate_operators(new_data)\n    self._data = apply_operators(self._data, new_data)\n    self._metadata.merge(new_metadata)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/#sparkwheel.Config._uses_nested_paths","title":"<code>_uses_nested_paths(source)</code>","text":"<p>Check if dict uses :: path syntax.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _uses_nested_paths(self, source: dict) -&gt; bool:\n    \"\"\"Check if dict uses :: path syntax.\"\"\"\n    return any(ID_SEP_KEY in str(k).lstrip(REPLACE_KEY).lstrip(REMOVE_KEY) for k in source.keys())\n</code></pre>"},{"location":"reference/#sparkwheel.Config.export_config_file","title":"<code>export_config_file(config, filepath, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Export config to YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Config dict to export</p> required <code>filepath</code> <code>PathLike</code> <p>Target file path</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for yaml.safe_dump</p> <code>{}</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@staticmethod\ndef export_config_file(config: dict, filepath: PathLike, **kwargs: Any) -&gt; None:\n    \"\"\"Export config to YAML file.\n\n    Args:\n        config: Config dict to export\n        filepath: Target file path\n        kwargs: Additional arguments for yaml.safe_dump\n    \"\"\"\n    import yaml\n\n    filepath_str = str(Path(filepath))\n    with open(filepath_str, \"w\") as f:\n        yaml.safe_dump(config, f, **kwargs)\n</code></pre>"},{"location":"reference/#sparkwheel.Config.from_cli","title":"<code>from_cli(source, cli_overrides, globals=None, schema=None)</code>  <code>classmethod</code>","text":"<p>Load configuration with CLI overrides applied.</p> <p>Convenience method for loading configs with command-line overrides. First loads the base config, then applies CLI overrides in the format \"key::path=value\", and optionally validates against a schema.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | Sequence[PathLike] | dict</code> <p>File path, list of paths, or config dict</p> required <code>cli_overrides</code> <code>list[str]</code> <p>List of override strings in format \"key::path=value\"</p> required <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions</p> <code>None</code> <code>schema</code> <code>type | None</code> <p>Optional dataclass schema for validation</p> <code>None</code> <p>Returns:</p> Type Description <code>Config</code> <p>New Config instance with CLI overrides applied</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load with CLI overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple files with overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     [\"base.yaml\", \"experiment.yaml\"],\n...     [\"model::lr=0.001\"]\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # With schema validation\n&gt;&gt;&gt; from dataclasses import dataclass\n&gt;&gt;&gt; @dataclass\n... class TrainingConfig:\n...     model: dict\n...     trainer: dict\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\"model::lr=0.001\"],\n...     schema=TrainingConfig\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Complex overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\n...         \"model::lr=0.001\",\n...         \"trainer::devices=[0,1,2]\",\n...         \"model::layers=[128,256,512]\",\n...         \"debug=True\"\n...     ]\n... )\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@classmethod\ndef from_cli(\n    cls,\n    source: PathLike | Sequence[PathLike] | dict,\n    cli_overrides: list[str],\n    globals: dict[str, Any] | None = None,\n    schema: type | None = None,\n) -&gt; \"Config\":\n    \"\"\"Load configuration with CLI overrides applied.\n\n    Convenience method for loading configs with command-line overrides.\n    First loads the base config, then applies CLI overrides in the format\n    \"key::path=value\", and optionally validates against a schema.\n\n    Args:\n        source: File path, list of paths, or config dict\n        cli_overrides: List of override strings in format \"key::path=value\"\n        globals: Pre-imported packages for expressions\n        schema: Optional dataclass schema for validation\n\n    Returns:\n        New Config instance with CLI overrides applied\n\n    Examples:\n        &gt;&gt;&gt; # Load with CLI overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n        ... )\n\n        &gt;&gt;&gt; # Multiple files with overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     [\"base.yaml\", \"experiment.yaml\"],\n        ...     [\"model::lr=0.001\"]\n        ... )\n\n        &gt;&gt;&gt; # With schema validation\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class TrainingConfig:\n        ...     model: dict\n        ...     trainer: dict\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\"model::lr=0.001\"],\n        ...     schema=TrainingConfig\n        ... )\n\n        &gt;&gt;&gt; # Complex overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\n        ...         \"model::lr=0.001\",\n        ...         \"trainer::devices=[0,1,2]\",\n        ...         \"model::layers=[128,256,512]\",\n        ...         \"debug=True\"\n        ...     ]\n        ... )\n    \"\"\"\n    from .cli import parse_overrides\n\n    # Load base configuration\n    config = cls.load(source, globals=globals, schema=schema)\n\n    # Apply CLI overrides\n    if cli_overrides:\n        overrides = parse_overrides(cli_overrides)\n        for key, value in overrides.items():\n            config.set(key, value)\n\n        # Re-validate after overrides if schema provided\n        if schema is not None:\n            config.validate(schema)\n\n    return config\n</code></pre>"},{"location":"reference/#sparkwheel.Config.get","title":"<code>get(id='', default=None)</code>","text":"<p>Get raw config value (unresolved).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path (use :: for nesting, e.g., \"model::lr\") Empty string returns entire config</p> <code>''</code> <code>default</code> <code>Any</code> <p>Default value if id not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Raw configuration value (resolved references not resolved, raw references not expanded)</p> Example <p>config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}}) config.get(\"model::lr\") 0.001 config.get(\"model::ref\") \"@model::lr\"  # Unresolved resolved reference</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def get(self, id: str = \"\", default: Any = None) -&gt; Any:\n    \"\"\"Get raw config value (unresolved).\n\n    Args:\n        id: Configuration path (use :: for nesting, e.g., \"model::lr\")\n            Empty string returns entire config\n        default: Default value if id not found\n\n    Returns:\n        Raw configuration value (resolved references not resolved, raw references not expanded)\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}})\n        &gt;&gt;&gt; config.get(\"model::lr\")\n        0.001\n        &gt;&gt;&gt; config.get(\"model::ref\")\n        \"@model::lr\"  # Unresolved resolved reference\n    \"\"\"\n    try:\n        return self._get_by_id(id)\n    except (KeyError, IndexError, ValueError):\n        return default\n</code></pre>"},{"location":"reference/#sparkwheel.Config.load","title":"<code>load(source, globals=None, schema=None)</code>  <code>classmethod</code>","text":"<p>Load configuration from file(s) or dict.</p> <p>Primary method for creating Config instances.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | Sequence[PathLike] | dict</code> <p>File path, list of paths, or config dict</p> required <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions</p> <code>None</code> <code>schema</code> <code>type | None</code> <p>Optional dataclass schema for validation</p> <code>None</code> <p>Returns:</p> Type Description <code>Config</code> <p>New Config instance</p> Merge Behavior <p>Files are merged in order (composition-by-default). Use operators to control merging: - key: value   - Compose (default): merge dict or extend list - =key: value  - Replace operator: completely replace value - ~key: null   - Remove operator: delete key (idempotent)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Single file\n&gt;&gt;&gt; config = Config.load(\"config.yaml\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple files (merged)\n&gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n</code></pre> <pre><code>&gt;&gt;&gt; # From dict\n&gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n</code></pre> <pre><code>&gt;&gt;&gt; # With globals for expressions\n&gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n</code></pre> <pre><code>&gt;&gt;&gt; # With schema validation\n&gt;&gt;&gt; from dataclasses import dataclass\n&gt;&gt;&gt; @dataclass\n... class MySchema:\n...     name: str\n...     value: int\n&gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@classmethod\ndef load(\n    cls,\n    source: PathLike | Sequence[PathLike] | dict,\n    globals: dict[str, Any] | None = None,\n    schema: type | None = None,\n) -&gt; \"Config\":\n    \"\"\"Load configuration from file(s) or dict.\n\n    Primary method for creating Config instances.\n\n    Args:\n        source: File path, list of paths, or config dict\n        globals: Pre-imported packages for expressions\n        schema: Optional dataclass schema for validation\n\n    Returns:\n        New Config instance\n\n    Merge Behavior:\n        Files are merged in order (composition-by-default). Use operators to control merging:\n        - key: value   - Compose (default): merge dict or extend list\n        - =key: value  - Replace operator: completely replace value\n        - ~key: null   - Remove operator: delete key (idempotent)\n\n    Examples:\n        &gt;&gt;&gt; # Single file\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n\n        &gt;&gt;&gt; # Multiple files (merged)\n        &gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n        &gt;&gt;&gt; # From dict\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n\n        &gt;&gt;&gt; # With globals for expressions\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n\n        &gt;&gt;&gt; # With schema validation\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class MySchema:\n        ...     name: str\n        ...     value: int\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n    \"\"\"\n    config = cls(globals=globals)\n\n    # Handle dict input\n    if isinstance(source, dict):\n        config._data = source\n        if schema is not None:\n            config.validate(schema)\n        return config\n\n    # Handle file(s) input\n    file_list = ensure_tuple(source)\n    for filepath in file_list:\n        loaded_data, loaded_metadata = config._loader.load_file(filepath)\n        # Validate operators before applying\n        validate_operators(loaded_data)\n        # Merge data and metadata\n        config._data = apply_operators(config._data, loaded_data)\n        config._metadata.merge(loaded_metadata)\n\n    # Validate against schema if provided\n    if schema is not None:\n        config.validate(schema)\n\n    return config\n</code></pre>"},{"location":"reference/#sparkwheel.Config.resolve","title":"<code>resolve(id='', instantiate=True, eval_expr=True, lazy=True, default=None)</code>","text":"<p>Resolve resolved references (@) and return parsed config.</p> <p>Automatically parses config on first call. Resolves @ resolved references (follows them to get instantiated/evaluated values), evaluates $ expressions, and instantiates target components. Note: % raw references are expanded during preprocessing (before this stage).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Config path to resolve (empty string for entire config)</p> <code>''</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components with target</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate $ expressions</p> <code>True</code> <code>lazy</code> <code>bool</code> <p>Whether to use cached resolution</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if id not found (returns default.get_config() if Item)</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value (instantiated objects, evaluated expressions, etc.)</p> Example <p>config = Config.load({ ...     \"lr\": 0.001, ...     \"doubled\": \"$@lr * 2\", ...     \"optimizer\": { ...         \"target\": \"torch.optim.Adam\", ...         \"lr\": \"@lr\" ...     } ... }) config.resolve(\"lr\") 0.001 config.resolve(\"doubled\") 0.002 optimizer = config.resolve(\"optimizer\") type(optimizer).name 'Adam'</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def resolve(\n    self,\n    id: str = \"\",\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    lazy: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Resolve resolved references (@) and return parsed config.\n\n    Automatically parses config on first call. Resolves @ resolved references (follows\n    them to get instantiated/evaluated values), evaluates $ expressions, and\n    instantiates _target_ components. Note: % raw references are expanded during\n    preprocessing (before this stage).\n\n    Args:\n        id: Config path to resolve (empty string for entire config)\n        instantiate: Whether to instantiate components with _target_\n        eval_expr: Whether to evaluate $ expressions\n        lazy: Whether to use cached resolution\n        default: Default value if id not found (returns default.get_config() if Item)\n\n    Returns:\n        Resolved value (instantiated objects, evaluated expressions, etc.)\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\n        ...     \"lr\": 0.001,\n        ...     \"doubled\": \"$@lr * 2\",\n        ...     \"optimizer\": {\n        ...         \"_target_\": \"torch.optim.Adam\",\n        ...         \"lr\": \"@lr\"\n        ...     }\n        ... })\n        &gt;&gt;&gt; config.resolve(\"lr\")\n        0.001\n        &gt;&gt;&gt; config.resolve(\"doubled\")\n        0.002\n        &gt;&gt;&gt; optimizer = config.resolve(\"optimizer\")\n        &gt;&gt;&gt; type(optimizer).__name__\n        'Adam'\n    \"\"\"\n    # Parse if needed\n    if not self._is_parsed or not lazy:\n        self._parse()\n\n    # Resolve and return\n    try:\n        return self._resolver.resolve(id=id, instantiate=instantiate, eval_expr=eval_expr)\n    except (KeyError, ConfigKeyError):\n        if default is not None:\n            # If default is an Item, return its config\n            from .items import Item\n\n            if isinstance(default, Item):\n                return default.get_config()\n            return default\n        raise\n</code></pre>"},{"location":"reference/#sparkwheel.Config.set","title":"<code>set(id, value)</code>","text":"<p>Set config value, creating paths as needed.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path (use :: for nesting)</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required Example <p>config = Config.load({}) config.set(\"model::lr\", 0.001) config.get(\"model::lr\") 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def set(self, id: str, value: Any) -&gt; None:\n    \"\"\"Set config value, creating paths as needed.\n\n    Args:\n        id: Configuration path (use :: for nesting)\n        value: Value to set\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({})\n        &gt;&gt;&gt; config.set(\"model::lr\", 0.001)\n        &gt;&gt;&gt; config.get(\"model::lr\")\n        0.001\n    \"\"\"\n    if id == \"\":\n        self._data = value\n        self._invalidate_resolution()\n        return\n\n    keys = split_id(id)\n\n    # Ensure root is dict\n    if not isinstance(self._data, dict):\n        self._data = {}\n\n    # Create missing intermediate paths\n    current = self._data\n    for k in keys[:-1]:\n        if k not in current:\n            current[k] = {}\n        elif not isinstance(current[k], dict):\n            current[k] = {}\n        current = current[k]\n\n    # Set final value\n    current[keys[-1]] = value\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/#sparkwheel.Config.update","title":"<code>update(source)</code>","text":"<p>Update configuration with changes from another source.</p> <p>Applies changes using operators for fine-grained control. Supports nested paths (::) and compose/replace/delete operators.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | dict | Config</code> <p>File path, dict, or Config instance to update from</p> required Operators <ul> <li>key: value   - Compose (default): merge dict or extend list</li> <li>=key: value  - Replace operator: completely replace value</li> <li>~key: null   - Remove operator: delete key (idempotent)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Update from file\n&gt;&gt;&gt; config.update(\"override.yaml\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Update from dict (merges by default)\n&gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n</code></pre> <pre><code>&gt;&gt;&gt; # Update from another Config instance\n&gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n&gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n&gt;&gt;&gt; config1.update(config2)\n</code></pre> <pre><code>&gt;&gt;&gt; # Nested path updates\n&gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def update(self, source: PathLike | dict | \"Config\") -&gt; None:\n    \"\"\"Update configuration with changes from another source.\n\n    Applies changes using operators for fine-grained control.\n    Supports nested paths (::) and compose/replace/delete operators.\n\n    Args:\n        source: File path, dict, or Config instance to update from\n\n    Operators:\n        - key: value   - Compose (default): merge dict or extend list\n        - =key: value  - Replace operator: completely replace value\n        - ~key: null   - Remove operator: delete key (idempotent)\n\n    Examples:\n        &gt;&gt;&gt; # Update from file\n        &gt;&gt;&gt; config.update(\"override.yaml\")\n\n        &gt;&gt;&gt; # Update from dict (merges by default)\n        &gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n\n        &gt;&gt;&gt; # Update from another Config instance\n        &gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n        &gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n        &gt;&gt;&gt; config1.update(config2)\n\n        &gt;&gt;&gt; # Nested path updates\n        &gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n    \"\"\"\n    if isinstance(source, Config):\n        self._update_from_config(source)\n    elif isinstance(source, dict):\n        if self._uses_nested_paths(source):\n            self._apply_path_updates(source)\n        else:\n            self._apply_structural_update(source)\n    else:\n        self._update_from_file(source)\n</code></pre>"},{"location":"reference/#sparkwheel.Config.validate","title":"<code>validate(schema)</code>","text":"<p>Validate configuration against a dataclass schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>type</code> <p>Dataclass type defining the expected structure and types</p> required <p>Raises:</p> Type Description <code>ValidationError</code> <p>If configuration doesn't match schema</p> <code>TypeError</code> <p>If schema is not a dataclass</p> Example <p>from dataclasses import dataclass @dataclass ... class ModelConfig: ...     hidden_size: int ...     dropout: float config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1}) config.validate(ModelConfig)  # Passes bad_config = Config.load({\"hidden_size\": \"not an int\"}) bad_config.validate(ModelConfig)  # Raises ValidationError</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def validate(self, schema: type) -&gt; None:\n    \"\"\"Validate configuration against a dataclass schema.\n\n    Args:\n        schema: Dataclass type defining the expected structure and types\n\n    Raises:\n        ValidationError: If configuration doesn't match schema\n        TypeError: If schema is not a dataclass\n\n    Example:\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class ModelConfig:\n        ...     hidden_size: int\n        ...     dropout: float\n        &gt;&gt;&gt; config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1})\n        &gt;&gt;&gt; config.validate(ModelConfig)  # Passes\n        &gt;&gt;&gt; bad_config = Config.load({\"hidden_size\": \"not an int\"})\n        &gt;&gt;&gt; bad_config.validate(ModelConfig)  # Raises ValidationError\n    \"\"\"\n    from .schema import validate as validate_schema\n\n    validate_schema(self._data, schema, metadata=self._metadata)\n</code></pre>"},{"location":"reference/#sparkwheel.ConfigKeyError","title":"<code>ConfigKeyError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when a config key is not found.</p> <p>Supports smart suggestions and available keys display.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ConfigKeyError(BaseError):\n    \"\"\"Raised when a config key is not found.\n\n    Supports smart suggestions and available keys display.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        source_location: SourceLocation | None = None,\n        suggestion: str | None = None,\n        missing_key: str | None = None,\n        available_keys: list[str] | None = None,\n        config_context: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize ConfigKeyError with enhanced context.\n\n        Args:\n            message: Error message\n            source_location: Location where error occurred\n            suggestion: Manual suggestion (optional)\n            missing_key: The key that wasn't found\n            available_keys: List of available keys for suggestions\n            config_context: The config dict where the key wasn't found (for displaying available keys)\n        \"\"\"\n        self.missing_key = missing_key\n        self.available_keys = available_keys or []\n        self.config_context = config_context\n\n        # Auto-generate suggestion if not provided\n        if not suggestion and missing_key and available_keys:\n            suggestion = self._generate_suggestion()\n\n        super().__init__(message, source_location, suggestion)\n\n    def _generate_suggestion(self) -&gt; str | None:\n        \"\"\"Generate smart suggestion with typo detection and available keys.\"\"\"\n        from ..errors import format_available_keys, format_suggestions, get_suggestions\n\n        parts = []\n\n        # Try to find similar keys\n        if self.missing_key and self.available_keys:\n            suggestions = get_suggestions(self.missing_key, self.available_keys)\n            if suggestions:\n                parts.append(format_suggestions(suggestions))\n\n        # Show available keys if we have config context and not too many keys\n        if self.config_context and len(self.config_context) &lt;= 10:\n            available = format_available_keys(self.config_context)\n            if available:\n                if parts:\n                    parts.append(\"\")  # Blank line separator\n                parts.append(available)\n\n        return \"\\n\".join(parts) if parts else None\n</code></pre>"},{"location":"reference/#sparkwheel.ConfigKeyError.__init__","title":"<code>__init__(message, source_location=None, suggestion=None, missing_key=None, available_keys=None, config_context=None)</code>","text":"<p>Initialize ConfigKeyError with enhanced context.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message</p> required <code>source_location</code> <code>SourceLocation | None</code> <p>Location where error occurred</p> <code>None</code> <code>suggestion</code> <code>str | None</code> <p>Manual suggestion (optional)</p> <code>None</code> <code>missing_key</code> <code>str | None</code> <p>The key that wasn't found</p> <code>None</code> <code>available_keys</code> <code>list[str] | None</code> <p>List of available keys for suggestions</p> <code>None</code> <code>config_context</code> <code>dict[str, Any] | None</code> <p>The config dict where the key wasn't found (for displaying available keys)</p> <code>None</code> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    source_location: SourceLocation | None = None,\n    suggestion: str | None = None,\n    missing_key: str | None = None,\n    available_keys: list[str] | None = None,\n    config_context: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Initialize ConfigKeyError with enhanced context.\n\n    Args:\n        message: Error message\n        source_location: Location where error occurred\n        suggestion: Manual suggestion (optional)\n        missing_key: The key that wasn't found\n        available_keys: List of available keys for suggestions\n        config_context: The config dict where the key wasn't found (for displaying available keys)\n    \"\"\"\n    self.missing_key = missing_key\n    self.available_keys = available_keys or []\n    self.config_context = config_context\n\n    # Auto-generate suggestion if not provided\n    if not suggestion and missing_key and available_keys:\n        suggestion = self._generate_suggestion()\n\n    super().__init__(message, source_location, suggestion)\n</code></pre>"},{"location":"reference/#sparkwheel.ConfigKeyError._generate_suggestion","title":"<code>_generate_suggestion()</code>","text":"<p>Generate smart suggestion with typo detection and available keys.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _generate_suggestion(self) -&gt; str | None:\n    \"\"\"Generate smart suggestion with typo detection and available keys.\"\"\"\n    from ..errors import format_available_keys, format_suggestions, get_suggestions\n\n    parts = []\n\n    # Try to find similar keys\n    if self.missing_key and self.available_keys:\n        suggestions = get_suggestions(self.missing_key, self.available_keys)\n        if suggestions:\n            parts.append(format_suggestions(suggestions))\n\n    # Show available keys if we have config context and not too many keys\n    if self.config_context and len(self.config_context) &lt;= 10:\n        available = format_available_keys(self.config_context)\n        if available:\n            if parts:\n                parts.append(\"\")  # Blank line separator\n            parts.append(available)\n\n    return \"\\n\".join(parts) if parts else None\n</code></pre>"},{"location":"reference/#sparkwheel.ConfigMergeError","title":"<code>ConfigMergeError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when configuration merge operation fails.</p> <p>This is typically raised when using operators (= or ~) incorrectly: - Using ~ on a non-existent key - Using ~ with invalid value (must be null, empty, or list) - Type mismatch during merge (e.g., trying to merge dict into list)</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ConfigMergeError(BaseError):\n    \"\"\"Raised when configuration merge operation fails.\n\n    This is typically raised when using operators (= or ~) incorrectly:\n    - Using ~ on a non-existent key\n    - Using ~ with invalid value (must be null, empty, or list)\n    - Type mismatch during merge (e.g., trying to merge dict into list)\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#sparkwheel.EvaluationError","title":"<code>EvaluationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when evaluating an expression fails.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class EvaluationError(BaseError):\n    \"\"\"Raised when evaluating an expression fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#sparkwheel.Expression","title":"<code>Expression</code>","text":"<p>               Bases: <code>Item</code></p> <p>Executable expression that evaluates Python code.</p> <p>Expressions start with <code>$</code> and are evaluated using Python's <code>eval()</code>, or imported if they're import statements.</p> Example <pre><code>from sparkwheel import Expression\n\nconfig = \"$len([1, 2, 3])\"\nexpression = Expression(config, id=\"test\", globals={\"len\": len})\nprint(expression.evaluate())  # 3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Expression string starting with <code>$</code></p> required <code>id</code> <code>str</code> <p>Identifier for this config item, defaults to \"\"</p> <code>''</code> <code>globals</code> <code>dict | None</code> <p>Additional global context for evaluation</p> <code>None</code> See Also <p>Python eval documentation</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Expression(Item):\n    \"\"\"Executable expression that evaluates Python code.\n\n    Expressions start with `$` and are evaluated using Python's `eval()`,\n    or imported if they're import statements.\n\n    Example:\n        ```python\n        from sparkwheel import Expression\n\n        config = \"$len([1, 2, 3])\"\n        expression = Expression(config, id=\"test\", globals={\"len\": len})\n        print(expression.evaluate())  # 3\n        ```\n\n    Args:\n        config: Expression string starting with `$`\n        id: Identifier for this config item, defaults to \"\"\n        globals: Additional global context for evaluation\n\n    See Also:\n        [Python eval documentation](https://docs.python.org/3/library/functions.html#eval)\n    \"\"\"\n\n    prefix = EXPR_KEY\n    run_eval = run_eval\n\n    def __init__(\n        self,\n        config: Any,\n        id: str = \"\",\n        globals: dict | None = None,\n        source_location: SourceLocation | None = None,\n    ) -&gt; None:\n        super().__init__(config=config, id=id, source_location=source_location)\n        self.globals = globals if globals is not None else {}\n\n    def _parse_import_string(self, import_string: str) -&gt; Any | None:\n        \"\"\"parse single import statement such as \"from pathlib import Path\" \"\"\"\n        node = first(ast.iter_child_nodes(ast.parse(import_string)))\n        if not isinstance(node, (ast.Import, ast.ImportFrom)):\n            return None\n        if len(node.names) &lt; 1:\n            return None\n        if len(node.names) &gt; 1:\n            warnings.warn(f\"ignoring multiple import alias '{import_string}'.\", stacklevel=2)\n        name, asname = f\"{node.names[0].name}\", node.names[0].asname\n        asname = name if asname is None else f\"{asname}\"\n        if isinstance(node, ast.ImportFrom):\n            self.globals[asname], _ = optional_import(f\"{node.module}\", name=f\"{name}\")\n            return self.globals[asname]\n        if isinstance(node, ast.Import):\n            self.globals[asname], _ = optional_import(f\"{name}\")\n            return self.globals[asname]\n        return None\n\n    def evaluate(self, globals: dict | None = None, locals: dict | None = None) -&gt; str | Any | None:\n        \"\"\"Evaluate the expression and return the result.\n\n        Uses Python's `eval()` to execute the expression string.\n\n        Args:\n            globals: Additional global symbols for evaluation\n            locals: Additional local symbols for evaluation\n\n        Returns:\n            Evaluation result, or None if not an expression\n\n        Raises:\n            RuntimeError: If evaluation fails\n        \"\"\"\n        value = self.get_config()\n        if not Expression.is_expression(value):\n            return None\n        optional_module = self._parse_import_string(value[len(self.prefix) :])\n        if optional_module is not None:\n            return optional_module\n        if not self.run_eval:\n            return f\"{value[len(self.prefix) :]}\"\n        globals_ = dict(self.globals)\n        if globals is not None:\n            for k, v in globals.items():\n                if k in globals_:\n                    warnings.warn(f\"the new global variable `{k}` conflicts with `self.globals`, override it.\", stacklevel=2)\n                globals_[k] = v\n        if not run_debug:\n            try:\n                return eval(value[len(self.prefix) :], globals_, locals)\n            except Exception as e:\n                raise EvaluationError(\n                    f\"Failed to evaluate expression: '{value[len(self.prefix) :]}'\",\n                    source_location=self.source_location,\n                ) from e\n        warnings.warn(\n            f\"\\n\\npdb: value={value}\\nSee also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n            stacklevel=2,\n        )\n        import pdb  # noqa: T100\n\n        pdb.run(value[len(self.prefix) :], globals_, locals)\n        return None\n\n    @classmethod\n    def is_expression(cls, config: dict | list | str) -&gt; bool:\n        \"\"\"\n        Check whether the config is an executable expression string.\n        Currently, a string starts with ``\"$\"`` character is interpreted as an expression.\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        return isinstance(config, str) and config.startswith(cls.prefix)\n\n    @classmethod\n    def is_import_statement(cls, config: dict | list | str) -&gt; bool:\n        \"\"\"\n        Check whether the config is an import statement (a special case of expression).\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        if not cls.is_expression(config):\n            return False\n        if \"import\" not in config:\n            return False\n        return isinstance(first(ast.iter_child_nodes(ast.parse(f\"{config[len(cls.prefix) :]}\"))), (ast.Import, ast.ImportFrom))\n</code></pre>"},{"location":"reference/#sparkwheel.Expression._parse_import_string","title":"<code>_parse_import_string(import_string)</code>","text":"<p>parse single import statement such as \"from pathlib import Path\"</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def _parse_import_string(self, import_string: str) -&gt; Any | None:\n    \"\"\"parse single import statement such as \"from pathlib import Path\" \"\"\"\n    node = first(ast.iter_child_nodes(ast.parse(import_string)))\n    if not isinstance(node, (ast.Import, ast.ImportFrom)):\n        return None\n    if len(node.names) &lt; 1:\n        return None\n    if len(node.names) &gt; 1:\n        warnings.warn(f\"ignoring multiple import alias '{import_string}'.\", stacklevel=2)\n    name, asname = f\"{node.names[0].name}\", node.names[0].asname\n    asname = name if asname is None else f\"{asname}\"\n    if isinstance(node, ast.ImportFrom):\n        self.globals[asname], _ = optional_import(f\"{node.module}\", name=f\"{name}\")\n        return self.globals[asname]\n    if isinstance(node, ast.Import):\n        self.globals[asname], _ = optional_import(f\"{name}\")\n        return self.globals[asname]\n    return None\n</code></pre>"},{"location":"reference/#sparkwheel.Expression.evaluate","title":"<code>evaluate(globals=None, locals=None)</code>","text":"<p>Evaluate the expression and return the result.</p> <p>Uses Python's <code>eval()</code> to execute the expression string.</p> <p>Parameters:</p> Name Type Description Default <code>globals</code> <code>dict | None</code> <p>Additional global symbols for evaluation</p> <code>None</code> <code>locals</code> <code>dict | None</code> <p>Additional local symbols for evaluation</p> <code>None</code> <p>Returns:</p> Type Description <code>str | Any | None</code> <p>Evaluation result, or None if not an expression</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If evaluation fails</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def evaluate(self, globals: dict | None = None, locals: dict | None = None) -&gt; str | Any | None:\n    \"\"\"Evaluate the expression and return the result.\n\n    Uses Python's `eval()` to execute the expression string.\n\n    Args:\n        globals: Additional global symbols for evaluation\n        locals: Additional local symbols for evaluation\n\n    Returns:\n        Evaluation result, or None if not an expression\n\n    Raises:\n        RuntimeError: If evaluation fails\n    \"\"\"\n    value = self.get_config()\n    if not Expression.is_expression(value):\n        return None\n    optional_module = self._parse_import_string(value[len(self.prefix) :])\n    if optional_module is not None:\n        return optional_module\n    if not self.run_eval:\n        return f\"{value[len(self.prefix) :]}\"\n    globals_ = dict(self.globals)\n    if globals is not None:\n        for k, v in globals.items():\n            if k in globals_:\n                warnings.warn(f\"the new global variable `{k}` conflicts with `self.globals`, override it.\", stacklevel=2)\n            globals_[k] = v\n    if not run_debug:\n        try:\n            return eval(value[len(self.prefix) :], globals_, locals)\n        except Exception as e:\n            raise EvaluationError(\n                f\"Failed to evaluate expression: '{value[len(self.prefix) :]}'\",\n                source_location=self.source_location,\n            ) from e\n    warnings.warn(\n        f\"\\n\\npdb: value={value}\\nSee also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n        stacklevel=2,\n    )\n    import pdb  # noqa: T100\n\n    pdb.run(value[len(self.prefix) :], globals_, locals)\n    return None\n</code></pre>"},{"location":"reference/#sparkwheel.Expression.is_expression","title":"<code>is_expression(config)</code>  <code>classmethod</code>","text":"<p>Check whether the config is an executable expression string. Currently, a string starts with <code>\"$\"</code> character is interpreted as an expression.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | list | str</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@classmethod\ndef is_expression(cls, config: dict | list | str) -&gt; bool:\n    \"\"\"\n    Check whether the config is an executable expression string.\n    Currently, a string starts with ``\"$\"`` character is interpreted as an expression.\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    return isinstance(config, str) and config.startswith(cls.prefix)\n</code></pre>"},{"location":"reference/#sparkwheel.Expression.is_import_statement","title":"<code>is_import_statement(config)</code>  <code>classmethod</code>","text":"<p>Check whether the config is an import statement (a special case of expression).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | list | str</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@classmethod\ndef is_import_statement(cls, config: dict | list | str) -&gt; bool:\n    \"\"\"\n    Check whether the config is an import statement (a special case of expression).\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    if not cls.is_expression(config):\n        return False\n    if \"import\" not in config:\n        return False\n    return isinstance(first(ast.iter_child_nodes(ast.parse(f\"{config[len(cls.prefix) :]}\"))), (ast.Import, ast.ImportFrom))\n</code></pre>"},{"location":"reference/#sparkwheel.Instantiable","title":"<code>Instantiable</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for an instantiable object.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Instantiable(ABC):\n    \"\"\"\n    Base class for an instantiable object.\n    \"\"\"\n\n    @abstractmethod\n    def is_disabled(self, *args: Any, **kwargs: Any) -&gt; bool:\n        \"\"\"\n        Return a boolean flag to indicate whether the object should be instantiated.\n        \"\"\"\n        raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n\n    @abstractmethod\n    def instantiate(self, *args: Any, **kwargs: Any) -&gt; object:\n        \"\"\"\n        Instantiate the target component and return the instance.\n        \"\"\"\n        raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/#sparkwheel.Instantiable.instantiate","title":"<code>instantiate(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Instantiate the target component and return the instance.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>@abstractmethod\ndef instantiate(self, *args: Any, **kwargs: Any) -&gt; object:\n    \"\"\"\n    Instantiate the target component and return the instance.\n    \"\"\"\n    raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/#sparkwheel.Instantiable.is_disabled","title":"<code>is_disabled(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return a boolean flag to indicate whether the object should be instantiated.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>@abstractmethod\ndef is_disabled(self, *args: Any, **kwargs: Any) -&gt; bool:\n    \"\"\"\n    Return a boolean flag to indicate whether the object should be instantiated.\n    \"\"\"\n    raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/#sparkwheel.InstantiationError","title":"<code>InstantiationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when instantiating a component fails.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class InstantiationError(BaseError):\n    \"\"\"Raised when instantiating a component fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#sparkwheel.Item","title":"<code>Item</code>","text":"<p>Basic data structure to represent a configuration item.</p> <p>A <code>Item</code> instance can optionally have a string id, so that other items can refer to it. It has a build-in <code>config</code> property to store the configuration object.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>content of a config item, can be objects of any types, a configuration resolver may interpret the content to generate a configuration object.</p> required <code>id</code> <code>str</code> <p>name of the current config item, defaults to empty string.</p> <code>''</code> <code>source_location</code> <code>SourceLocation | None</code> <p>optional location in source file where this config item was defined.</p> <code>None</code> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Item:\n    \"\"\"\n    Basic data structure to represent a configuration item.\n\n    A `Item` instance can optionally have a string id, so that other items can refer to it.\n    It has a build-in `config` property to store the configuration object.\n\n    Args:\n        config: content of a config item, can be objects of any types,\n            a configuration resolver may interpret the content to generate a configuration object.\n        id: name of the current config item, defaults to empty string.\n        source_location: optional location in source file where this config item was defined.\n    \"\"\"\n\n    def __init__(self, config: Any, id: str = \"\", source_location: SourceLocation | None = None) -&gt; None:\n        self.config = config\n        self.id = id\n        self.source_location = source_location\n\n    def get_id(self) -&gt; str:\n        \"\"\"\n        Get the ID name of current config item, useful to identify config items during parsing.\n        \"\"\"\n        return self.id\n\n    def update_config(self, config: Any) -&gt; None:\n        \"\"\"\n        Replace the content of `self.config` with new `config`.\n        A typical usage is to modify the initial config content at runtime.\n\n        Args:\n            config: content of a `Item`.\n        \"\"\"\n        self.config = config\n\n    def get_config(self):\n        \"\"\"\n        Get the config content of current config item.\n        \"\"\"\n        return self.config\n\n    def __repr__(self) -&gt; str:\n        return f\"{type(self).__name__}: \\n{pformat(self.config)}\"\n</code></pre>"},{"location":"reference/#sparkwheel.Item.get_config","title":"<code>get_config()</code>","text":"<p>Get the config content of current config item.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def get_config(self):\n    \"\"\"\n    Get the config content of current config item.\n    \"\"\"\n    return self.config\n</code></pre>"},{"location":"reference/#sparkwheel.Item.get_id","title":"<code>get_id()</code>","text":"<p>Get the ID name of current config item, useful to identify config items during parsing.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def get_id(self) -&gt; str:\n    \"\"\"\n    Get the ID name of current config item, useful to identify config items during parsing.\n    \"\"\"\n    return self.id\n</code></pre>"},{"location":"reference/#sparkwheel.Item.update_config","title":"<code>update_config(config)</code>","text":"<p>Replace the content of <code>self.config</code> with new <code>config</code>. A typical usage is to modify the initial config content at runtime.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>content of a <code>Item</code>.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>def update_config(self, config: Any) -&gt; None:\n    \"\"\"\n    Replace the content of `self.config` with new `config`.\n    A typical usage is to modify the initial config content at runtime.\n\n    Args:\n        config: content of a `Item`.\n    \"\"\"\n    self.config = config\n</code></pre>"},{"location":"reference/#sparkwheel.ModuleNotFoundError","title":"<code>ModuleNotFoundError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when a target module/class/function cannot be located.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ModuleNotFoundError(BaseError):\n    \"\"\"Raised when a _target_ module/class/function cannot be located.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver","title":"<code>Resolver</code>","text":"<p>Resolve references between Items.</p> <p>Manages Items and resolves resolved reference strings (starting with @) by substituting them with their corresponding resolved values (instantiated objects, evaluated expressions, etc.).</p> Example <pre><code>from sparkwheel import Item, Component, Resolver\n\nresolver = Resolver()\n\n# Add items\nresolver.add_item(Item(config=0.001, id=\"lr\"))\nresolver.add_item(Item(config={\"lr\": \"@lr\"}, id=\"config\"))\n\n# Resolve\nresult = resolver.resolve(\"config\")\nprint(result)  # {\"lr\": 0.001}\n</code></pre> <p>Resolved references can use :: separator for nested access: - Dictionary keys: @config::subkey - List indices: @list::0::subitem</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>class Resolver:\n    \"\"\"Resolve references between Items.\n\n    Manages Items and resolves resolved reference strings (starting with @) by\n    substituting them with their corresponding resolved values (instantiated objects,\n    evaluated expressions, etc.).\n\n    Example:\n        ```python\n        from sparkwheel import Item, Component, Resolver\n\n        resolver = Resolver()\n\n        # Add items\n        resolver.add_item(Item(config=0.001, id=\"lr\"))\n        resolver.add_item(Item(config={\"lr\": \"@lr\"}, id=\"config\"))\n\n        # Resolve\n        result = resolver.resolve(\"config\")\n        print(result)  # {\"lr\": 0.001}\n        ```\n\n    Resolved references can use :: separator for nested access:\n    - Dictionary keys: @config::key::subkey\n    - List indices: @list::0::subitem\n    \"\"\"\n\n    _vars = \"__local_refs\"  # Variable name for resolved refs in expression evaluation\n    sep = ID_SEP_KEY  # Separator for nested key access\n    ref = RESOLVED_REF_KEY  # Resolved reference prefix (@)\n    allow_missing_reference = allow_missing_reference\n    max_resolution_depth = 100  # Prevent DoS from deeply nested references\n\n    def __init__(self, items: list[Item] | None = None):\n        \"\"\"Initialize resolver with optional items.\n\n        Args:\n            items: Optional list of Items to add during initialization\n        \"\"\"\n        self._items: dict[str, Item] = {}\n        self._resolved: dict[str, Any] = {}\n\n        if items:\n            for item in items:\n                self.add_item(item)\n\n    def reset(self) -&gt; None:\n        \"\"\"Clear all items and resolved content.\"\"\"\n        self._items = {}\n        self._resolved = {}\n\n    def is_resolved(self) -&gt; bool:\n        \"\"\"Check if any items have been resolved.\"\"\"\n        return bool(self._resolved)\n\n    def add_item(self, item: Item) -&gt; None:\n        \"\"\"Add a Item to resolve.\n\n        Args:\n            item: Item to add\n        \"\"\"\n        id = item.get_id()\n        if id in self._items:\n            warnings.warn(\n                f\"Duplicate config item ID '{id}' detected. \"\n                f\"The new item will be ignored and the existing item will be kept. \"\n                f\"This may indicate a configuration error.\",\n                UserWarning,\n                stacklevel=2,\n            )\n            return\n        self._items[id] = item\n\n    def add_items(self, items: list[Item]) -&gt; None:\n        \"\"\"Add multiple Items at once.\n\n        Args:\n            items: List of Items to add\n        \"\"\"\n        for item in items:\n            self.add_item(item)\n\n    def get_item(self, id: str, resolve: bool = False, **kwargs: Any) -&gt; Item | None:\n        \"\"\"Get Item by id, optionally resolved.\n\n        Args:\n            id: ID of the config item\n            resolve: Whether to resolve the item (default: False)\n            **kwargs: Additional arguments for resolution\n\n        Returns:\n            Item if found, None otherwise (or resolved value if resolve=True)\n        \"\"\"\n        id = self.normalize_id(id)\n        if resolve and id not in self._resolved:\n            self._resolve_one_item(id=id, **kwargs)\n        return self._items.get(id)\n\n    def resolve(\n        self,\n        id: str = \"\",\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Resolve a config item and return the result.\n\n        Resolves all references, instantiates components (if requested), and\n        evaluates expressions (if requested). Results are cached for efficiency.\n\n        Args:\n            id: ID of item to resolve (empty string for root)\n            instantiate: Whether to instantiate components with _target_\n            eval_expr: Whether to evaluate expressions starting with $\n            default: Default value if id not found\n\n        Returns:\n            Resolved value (instantiated object, evaluated result, or raw value)\n\n        Raises:\n            ConfigKeyError: If id not found and no default provided\n            CircularReferenceError: If circular reference detected\n        \"\"\"\n        return self._resolve_one_item(id=id, instantiate=instantiate, eval_expr=eval_expr, default=default)\n\n    def _resolve_one_item(\n        self,\n        id: str,\n        waiting_list: set[str] | None = None,\n        _depth: int = 0,\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Internal recursive resolution implementation.\n\n        Args:\n            id: ID to resolve\n            waiting_list: Set of IDs currently being resolved (for cycle detection)\n            _depth: Current recursion depth (for DoS prevention)\n            instantiate: Whether to instantiate components\n            eval_expr: Whether to evaluate expressions\n            default: Default value if not found\n\n        Returns:\n            Resolved value\n\n        Raises:\n            RecursionError: If max depth exceeded\n            CircularReferenceError: If circular reference detected\n            ConfigKeyError: If reference not found\n        \"\"\"\n        # Prevent stack overflow attacks\n        if _depth &gt;= self.max_resolution_depth:\n            raise RecursionError(\n                f\"Maximum reference resolution depth ({self.max_resolution_depth}) exceeded while resolving '{id}'. \"\n                f\"This may indicate an overly complex configuration or a potential DoS attack.\"\n            )\n\n        id = self.normalize_id(id)\n\n        # Return cached result if available\n        if id in self._resolved:\n            return self._resolved[id]\n\n        # Look up the item\n        try:\n            item = look_up_option(id, self._items, print_all_options=False, default=default or \"no_default\")\n        except ValueError as err:\n            # Provide helpful error with suggestions\n            source_location = None\n            for config_item in self._items.values():\n                if hasattr(config_item, \"source_location\") and config_item.source_location:\n                    source_location = config_item.source_location\n                    break\n\n            available_keys = list(self._items.keys())\n            config_context = None\n\n            # For nested IDs, try to get parent context to show available keys\n            if ID_SEP_KEY in id:\n                parent_id = ID_SEP_KEY.join(id.split(ID_SEP_KEY)[:-1])\n                try:\n                    parent_item = self.get_item(parent_id)\n                    if parent_item and isinstance(parent_item.get_config(), dict):\n                        config_context = parent_item.get_config()\n                except (ValueError, KeyError):\n                    pass\n\n            raise ConfigKeyError(\n                f\"Config ID '{id}' not found in the configuration\",\n                source_location=source_location,\n                missing_key=id,\n                available_keys=available_keys,\n                config_context=config_context,\n            ) from err\n\n        # If default was returned, just return it\n        if not isinstance(item, Item):\n            return item\n\n        item_config = item.get_config()\n\n        # Initialize waiting list for circular reference detection\n        if waiting_list is None:\n            waiting_list = set()\n        waiting_list.add(id)\n\n        # First, resolve any import expressions (they need to run first)\n        for t, v in self._items.items():\n            if t not in self._resolved and isinstance(v, Expression) and v.is_import_statement(v.get_config()):\n                self._resolved[t] = v.evaluate() if eval_expr else v\n\n        # Find all references in this item's config\n        refs = self.find_refs_in_config(config=item_config, id=id)\n\n        # Resolve dependencies first\n        for dep_id in refs.keys():\n            # Check for circular references\n            if dep_id in waiting_list:\n                raise CircularReferenceError(\n                    f\"Circular reference detected: '{dep_id}' references back to '{id}'\",\n                    source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                )\n\n            # Resolve dependency if not already resolved\n            if dep_id not in self._resolved:\n                try:\n                    look_up_option(dep_id, self._items, print_all_options=False)\n                except ValueError as err:\n                    msg = f\"the referring item `@{dep_id}` is not defined in the config content.\"\n                    if not self.allow_missing_reference:\n                        available_keys = list(self._items.keys())\n                        raise ConfigKeyError(\n                            f\"Reference '@{dep_id}' not found in configuration\",\n                            source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                            missing_key=dep_id,\n                            available_keys=available_keys,\n                        ) from err\n                    warnings.warn(msg, stacklevel=2)\n                    continue\n\n                # Recursively resolve dependency\n                self._resolve_one_item(\n                    id=dep_id,\n                    waiting_list=waiting_list,\n                    _depth=_depth + 1,\n                    instantiate=instantiate,\n                    eval_expr=eval_expr,\n                )\n                waiting_list.discard(dep_id)\n\n        # All dependencies resolved, now resolve this item\n        new_config = self.update_config_with_refs(config=item_config, id=id, refs=self._resolved)\n        item.update_config(config=new_config)\n\n        # Generate final resolved value based on item type\n        if isinstance(item, Component):\n            self._resolved[id] = item.instantiate() if instantiate else item\n        elif isinstance(item, Expression):\n            self._resolved[id] = item.evaluate(globals={f\"{self._vars}\": self._resolved}) if eval_expr else item\n        else:\n            self._resolved[id] = new_config\n\n        return self._resolved[id]\n\n    @classmethod\n    def normalize_id(cls, id: str | int) -&gt; str:\n        \"\"\"Normalize ID to string format.\n\n        Args:\n            id: ID to normalize\n\n        Returns:\n            String ID\n        \"\"\"\n        return str(id)\n\n    @classmethod\n    def split_id(cls, id: str | int, last: bool = False) -&gt; list[str]:\n        \"\"\"Split ID string by separator.\n\n        Args:\n            id: ID to split\n            last: If True, only split rightmost part\n\n        Returns:\n            List of ID components\n        \"\"\"\n        if not last:\n            return cls.normalize_id(id).split(cls.sep)\n        res = cls.normalize_id(id).rsplit(cls.sep, 1)\n        return [\"\".join(res[:-1]), res[-1]]\n\n    @classmethod\n    def iter_subconfigs(cls, id: str, config: Any) -&gt; Iterator[tuple[str, str, Any]]:\n        \"\"\"Iterate over sub-configs with IDs.\n\n        Args:\n            id: Current ID path\n            config: Config to iterate (dict or list)\n\n        Yields:\n            Tuples of (key, sub_id, value)\n        \"\"\"\n        for k, v in config.items() if isinstance(config, dict) else enumerate(config):\n            sub_id = f\"{id}{cls.sep}{k}\" if id != \"\" else f\"{k}\"\n            yield k, sub_id, v\n\n    @classmethod\n    def match_refs_pattern(cls, value: str) -&gt; dict[str, int]:\n        \"\"\"Find reference patterns in a string.\n\n        Args:\n            value: String to search for references\n\n        Returns:\n            Dict mapping reference IDs to occurrence counts\n        \"\"\"\n        value = normalize_id(value)\n        return scan_references(value)\n\n    @classmethod\n    def update_refs_pattern(cls, value: str, refs: dict) -&gt; str:\n        \"\"\"Replace reference patterns with resolved values.\n\n        Args:\n            value: String containing references\n            refs: Dict of resolved references\n\n        Returns:\n            String with references replaced\n        \"\"\"\n        value = normalize_id(value)\n\n        try:\n            return replace_references(value, refs, cls._vars)\n        except KeyError as e:\n            # Extract reference ID from error message\n            # The error message format is: \"Reference '@ref_id' not found in resolved references\"\n            ref_id = str(e).split(\"'\")[1].lstrip(\"@\")\n            msg = f\"can not find expected ID '{ref_id}' in the references.\"\n            if not cls.allow_missing_reference:\n                raise KeyError(msg) from e\n            warnings.warn(msg, stacklevel=2)\n            return value\n\n    @classmethod\n    def find_refs_in_config(cls, config: Any, id: str, refs: dict[str, int] | None = None) -&gt; dict[str, int]:\n        \"\"\"Recursively find all references in config.\n\n        Args:\n            config: Config to search\n            id: Current ID path\n            refs: Accumulated references dict\n\n        Returns:\n            Dict of reference IDs to counts\n        \"\"\"\n        refs_ = refs or {}\n\n        # Check string values for reference patterns\n        if isinstance(config, str):\n            for ref_id, count in cls.match_refs_pattern(value=config).items():\n                refs_[ref_id] = refs_.get(ref_id, 0) + count\n\n        # Recursively search nested structures\n        if isinstance(config, (list, dict)):\n            for _, sub_id, v in cls.iter_subconfigs(id, config):\n                # Instantiable and expression items are also dependencies\n                if (Component.is_instantiable(v) or Expression.is_expression(v)) and sub_id not in refs_:\n                    refs_[sub_id] = 1\n                refs_ = cls.find_refs_in_config(v, sub_id, refs_)\n\n        return refs_\n\n    @classmethod\n    def update_config_with_refs(cls, config: Any, id: str, refs: dict | None = None) -&gt; Any:\n        \"\"\"Update config by replacing references with resolved values.\n\n        Args:\n            config: Config to update\n            id: Current ID path\n            refs: Dict of resolved references\n\n        Returns:\n            Config with references replaced\n        \"\"\"\n        refs_ = refs or {}\n\n        # Replace references in strings\n        if isinstance(config, str):\n            return cls.update_refs_pattern(config, refs_)\n\n        # Return non-container types as-is\n        if not isinstance(config, (list, dict)):\n            return config\n\n        # Recursively update nested structures\n        ret = type(config)()\n        for idx, sub_id, v in cls.iter_subconfigs(id, config):\n            if Component.is_instantiable(v) or Expression.is_expression(v):\n                updated = refs_[sub_id]\n                # Skip disabled components\n                if Component.is_instantiable(v) and updated is None:\n                    continue\n            else:\n                updated = cls.update_config_with_refs(v, sub_id, refs_)\n\n            if isinstance(ret, dict):\n                ret[idx] = updated\n            else:\n                ret.append(updated)\n\n        return ret\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.__init__","title":"<code>__init__(items=None)</code>","text":"<p>Initialize resolver with optional items.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[Item] | None</code> <p>Optional list of Items to add during initialization</p> <code>None</code> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def __init__(self, items: list[Item] | None = None):\n    \"\"\"Initialize resolver with optional items.\n\n    Args:\n        items: Optional list of Items to add during initialization\n    \"\"\"\n    self._items: dict[str, Item] = {}\n    self._resolved: dict[str, Any] = {}\n\n    if items:\n        for item in items:\n            self.add_item(item)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver._resolve_one_item","title":"<code>_resolve_one_item(id, waiting_list=None, _depth=0, instantiate=True, eval_expr=True, default=None)</code>","text":"<p>Internal recursive resolution implementation.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID to resolve</p> required <code>waiting_list</code> <code>set[str] | None</code> <p>Set of IDs currently being resolved (for cycle detection)</p> <code>None</code> <code>_depth</code> <code>int</code> <p>Current recursion depth (for DoS prevention)</p> <code>0</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate expressions</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value</p> <p>Raises:</p> Type Description <code>RecursionError</code> <p>If max depth exceeded</p> <code>CircularReferenceError</code> <p>If circular reference detected</p> <code>ConfigKeyError</code> <p>If reference not found</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def _resolve_one_item(\n    self,\n    id: str,\n    waiting_list: set[str] | None = None,\n    _depth: int = 0,\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Internal recursive resolution implementation.\n\n    Args:\n        id: ID to resolve\n        waiting_list: Set of IDs currently being resolved (for cycle detection)\n        _depth: Current recursion depth (for DoS prevention)\n        instantiate: Whether to instantiate components\n        eval_expr: Whether to evaluate expressions\n        default: Default value if not found\n\n    Returns:\n        Resolved value\n\n    Raises:\n        RecursionError: If max depth exceeded\n        CircularReferenceError: If circular reference detected\n        ConfigKeyError: If reference not found\n    \"\"\"\n    # Prevent stack overflow attacks\n    if _depth &gt;= self.max_resolution_depth:\n        raise RecursionError(\n            f\"Maximum reference resolution depth ({self.max_resolution_depth}) exceeded while resolving '{id}'. \"\n            f\"This may indicate an overly complex configuration or a potential DoS attack.\"\n        )\n\n    id = self.normalize_id(id)\n\n    # Return cached result if available\n    if id in self._resolved:\n        return self._resolved[id]\n\n    # Look up the item\n    try:\n        item = look_up_option(id, self._items, print_all_options=False, default=default or \"no_default\")\n    except ValueError as err:\n        # Provide helpful error with suggestions\n        source_location = None\n        for config_item in self._items.values():\n            if hasattr(config_item, \"source_location\") and config_item.source_location:\n                source_location = config_item.source_location\n                break\n\n        available_keys = list(self._items.keys())\n        config_context = None\n\n        # For nested IDs, try to get parent context to show available keys\n        if ID_SEP_KEY in id:\n            parent_id = ID_SEP_KEY.join(id.split(ID_SEP_KEY)[:-1])\n            try:\n                parent_item = self.get_item(parent_id)\n                if parent_item and isinstance(parent_item.get_config(), dict):\n                    config_context = parent_item.get_config()\n            except (ValueError, KeyError):\n                pass\n\n        raise ConfigKeyError(\n            f\"Config ID '{id}' not found in the configuration\",\n            source_location=source_location,\n            missing_key=id,\n            available_keys=available_keys,\n            config_context=config_context,\n        ) from err\n\n    # If default was returned, just return it\n    if not isinstance(item, Item):\n        return item\n\n    item_config = item.get_config()\n\n    # Initialize waiting list for circular reference detection\n    if waiting_list is None:\n        waiting_list = set()\n    waiting_list.add(id)\n\n    # First, resolve any import expressions (they need to run first)\n    for t, v in self._items.items():\n        if t not in self._resolved and isinstance(v, Expression) and v.is_import_statement(v.get_config()):\n            self._resolved[t] = v.evaluate() if eval_expr else v\n\n    # Find all references in this item's config\n    refs = self.find_refs_in_config(config=item_config, id=id)\n\n    # Resolve dependencies first\n    for dep_id in refs.keys():\n        # Check for circular references\n        if dep_id in waiting_list:\n            raise CircularReferenceError(\n                f\"Circular reference detected: '{dep_id}' references back to '{id}'\",\n                source_location=item.source_location if hasattr(item, \"source_location\") else None,\n            )\n\n        # Resolve dependency if not already resolved\n        if dep_id not in self._resolved:\n            try:\n                look_up_option(dep_id, self._items, print_all_options=False)\n            except ValueError as err:\n                msg = f\"the referring item `@{dep_id}` is not defined in the config content.\"\n                if not self.allow_missing_reference:\n                    available_keys = list(self._items.keys())\n                    raise ConfigKeyError(\n                        f\"Reference '@{dep_id}' not found in configuration\",\n                        source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                        missing_key=dep_id,\n                        available_keys=available_keys,\n                    ) from err\n                warnings.warn(msg, stacklevel=2)\n                continue\n\n            # Recursively resolve dependency\n            self._resolve_one_item(\n                id=dep_id,\n                waiting_list=waiting_list,\n                _depth=_depth + 1,\n                instantiate=instantiate,\n                eval_expr=eval_expr,\n            )\n            waiting_list.discard(dep_id)\n\n    # All dependencies resolved, now resolve this item\n    new_config = self.update_config_with_refs(config=item_config, id=id, refs=self._resolved)\n    item.update_config(config=new_config)\n\n    # Generate final resolved value based on item type\n    if isinstance(item, Component):\n        self._resolved[id] = item.instantiate() if instantiate else item\n    elif isinstance(item, Expression):\n        self._resolved[id] = item.evaluate(globals={f\"{self._vars}\": self._resolved}) if eval_expr else item\n    else:\n        self._resolved[id] = new_config\n\n    return self._resolved[id]\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.add_item","title":"<code>add_item(item)</code>","text":"<p>Add a Item to resolve.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Item</code> <p>Item to add</p> required Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def add_item(self, item: Item) -&gt; None:\n    \"\"\"Add a Item to resolve.\n\n    Args:\n        item: Item to add\n    \"\"\"\n    id = item.get_id()\n    if id in self._items:\n        warnings.warn(\n            f\"Duplicate config item ID '{id}' detected. \"\n            f\"The new item will be ignored and the existing item will be kept. \"\n            f\"This may indicate a configuration error.\",\n            UserWarning,\n            stacklevel=2,\n        )\n        return\n    self._items[id] = item\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.add_items","title":"<code>add_items(items)</code>","text":"<p>Add multiple Items at once.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[Item]</code> <p>List of Items to add</p> required Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def add_items(self, items: list[Item]) -&gt; None:\n    \"\"\"Add multiple Items at once.\n\n    Args:\n        items: List of Items to add\n    \"\"\"\n    for item in items:\n        self.add_item(item)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.find_refs_in_config","title":"<code>find_refs_in_config(config, id, refs=None)</code>  <code>classmethod</code>","text":"<p>Recursively find all references in config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Config to search</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>refs</code> <code>dict[str, int] | None</code> <p>Accumulated references dict</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict of reference IDs to counts</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef find_refs_in_config(cls, config: Any, id: str, refs: dict[str, int] | None = None) -&gt; dict[str, int]:\n    \"\"\"Recursively find all references in config.\n\n    Args:\n        config: Config to search\n        id: Current ID path\n        refs: Accumulated references dict\n\n    Returns:\n        Dict of reference IDs to counts\n    \"\"\"\n    refs_ = refs or {}\n\n    # Check string values for reference patterns\n    if isinstance(config, str):\n        for ref_id, count in cls.match_refs_pattern(value=config).items():\n            refs_[ref_id] = refs_.get(ref_id, 0) + count\n\n    # Recursively search nested structures\n    if isinstance(config, (list, dict)):\n        for _, sub_id, v in cls.iter_subconfigs(id, config):\n            # Instantiable and expression items are also dependencies\n            if (Component.is_instantiable(v) or Expression.is_expression(v)) and sub_id not in refs_:\n                refs_[sub_id] = 1\n            refs_ = cls.find_refs_in_config(v, sub_id, refs_)\n\n    return refs_\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.get_item","title":"<code>get_item(id, resolve=False, **kwargs)</code>","text":"<p>Get Item by id, optionally resolved.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID of the config item</p> required <code>resolve</code> <code>bool</code> <p>Whether to resolve the item (default: False)</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for resolution</p> <code>{}</code> <p>Returns:</p> Type Description <code>Item | None</code> <p>Item if found, None otherwise (or resolved value if resolve=True)</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def get_item(self, id: str, resolve: bool = False, **kwargs: Any) -&gt; Item | None:\n    \"\"\"Get Item by id, optionally resolved.\n\n    Args:\n        id: ID of the config item\n        resolve: Whether to resolve the item (default: False)\n        **kwargs: Additional arguments for resolution\n\n    Returns:\n        Item if found, None otherwise (or resolved value if resolve=True)\n    \"\"\"\n    id = self.normalize_id(id)\n    if resolve and id not in self._resolved:\n        self._resolve_one_item(id=id, **kwargs)\n    return self._items.get(id)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.is_resolved","title":"<code>is_resolved()</code>","text":"<p>Check if any items have been resolved.</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def is_resolved(self) -&gt; bool:\n    \"\"\"Check if any items have been resolved.\"\"\"\n    return bool(self._resolved)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.iter_subconfigs","title":"<code>iter_subconfigs(id, config)</code>  <code>classmethod</code>","text":"<p>Iterate over sub-configs with IDs.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Current ID path</p> required <code>config</code> <code>Any</code> <p>Config to iterate (dict or list)</p> required <p>Yields:</p> Type Description <code>tuple[str, str, Any]</code> <p>Tuples of (key, sub_id, value)</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef iter_subconfigs(cls, id: str, config: Any) -&gt; Iterator[tuple[str, str, Any]]:\n    \"\"\"Iterate over sub-configs with IDs.\n\n    Args:\n        id: Current ID path\n        config: Config to iterate (dict or list)\n\n    Yields:\n        Tuples of (key, sub_id, value)\n    \"\"\"\n    for k, v in config.items() if isinstance(config, dict) else enumerate(config):\n        sub_id = f\"{id}{cls.sep}{k}\" if id != \"\" else f\"{k}\"\n        yield k, sub_id, v\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.match_refs_pattern","title":"<code>match_refs_pattern(value)</code>  <code>classmethod</code>","text":"<p>Find reference patterns in a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>String to search for references</p> required <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping reference IDs to occurrence counts</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef match_refs_pattern(cls, value: str) -&gt; dict[str, int]:\n    \"\"\"Find reference patterns in a string.\n\n    Args:\n        value: String to search for references\n\n    Returns:\n        Dict mapping reference IDs to occurrence counts\n    \"\"\"\n    value = normalize_id(value)\n    return scan_references(value)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.normalize_id","title":"<code>normalize_id(id)</code>  <code>classmethod</code>","text":"<p>Normalize ID to string format.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>ID to normalize</p> required <p>Returns:</p> Type Description <code>str</code> <p>String ID</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef normalize_id(cls, id: str | int) -&gt; str:\n    \"\"\"Normalize ID to string format.\n\n    Args:\n        id: ID to normalize\n\n    Returns:\n        String ID\n    \"\"\"\n    return str(id)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.reset","title":"<code>reset()</code>","text":"<p>Clear all items and resolved content.</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Clear all items and resolved content.\"\"\"\n    self._items = {}\n    self._resolved = {}\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.resolve","title":"<code>resolve(id='', instantiate=True, eval_expr=True, default=None)</code>","text":"<p>Resolve a config item and return the result.</p> <p>Resolves all references, instantiates components (if requested), and evaluates expressions (if requested). Results are cached for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID of item to resolve (empty string for root)</p> <code>''</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components with target</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate expressions starting with $</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if id not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value (instantiated object, evaluated result, or raw value)</p> <p>Raises:</p> Type Description <code>ConfigKeyError</code> <p>If id not found and no default provided</p> <code>CircularReferenceError</code> <p>If circular reference detected</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def resolve(\n    self,\n    id: str = \"\",\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Resolve a config item and return the result.\n\n    Resolves all references, instantiates components (if requested), and\n    evaluates expressions (if requested). Results are cached for efficiency.\n\n    Args:\n        id: ID of item to resolve (empty string for root)\n        instantiate: Whether to instantiate components with _target_\n        eval_expr: Whether to evaluate expressions starting with $\n        default: Default value if id not found\n\n    Returns:\n        Resolved value (instantiated object, evaluated result, or raw value)\n\n    Raises:\n        ConfigKeyError: If id not found and no default provided\n        CircularReferenceError: If circular reference detected\n    \"\"\"\n    return self._resolve_one_item(id=id, instantiate=instantiate, eval_expr=eval_expr, default=default)\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.split_id","title":"<code>split_id(id, last=False)</code>  <code>classmethod</code>","text":"<p>Split ID string by separator.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>ID to split</p> required <code>last</code> <code>bool</code> <p>If True, only split rightmost part</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of ID components</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef split_id(cls, id: str | int, last: bool = False) -&gt; list[str]:\n    \"\"\"Split ID string by separator.\n\n    Args:\n        id: ID to split\n        last: If True, only split rightmost part\n\n    Returns:\n        List of ID components\n    \"\"\"\n    if not last:\n        return cls.normalize_id(id).split(cls.sep)\n    res = cls.normalize_id(id).rsplit(cls.sep, 1)\n    return [\"\".join(res[:-1]), res[-1]]\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.update_config_with_refs","title":"<code>update_config_with_refs(config, id, refs=None)</code>  <code>classmethod</code>","text":"<p>Update config by replacing references with resolved values.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Config to update</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>refs</code> <code>dict | None</code> <p>Dict of resolved references</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Config with references replaced</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef update_config_with_refs(cls, config: Any, id: str, refs: dict | None = None) -&gt; Any:\n    \"\"\"Update config by replacing references with resolved values.\n\n    Args:\n        config: Config to update\n        id: Current ID path\n        refs: Dict of resolved references\n\n    Returns:\n        Config with references replaced\n    \"\"\"\n    refs_ = refs or {}\n\n    # Replace references in strings\n    if isinstance(config, str):\n        return cls.update_refs_pattern(config, refs_)\n\n    # Return non-container types as-is\n    if not isinstance(config, (list, dict)):\n        return config\n\n    # Recursively update nested structures\n    ret = type(config)()\n    for idx, sub_id, v in cls.iter_subconfigs(id, config):\n        if Component.is_instantiable(v) or Expression.is_expression(v):\n            updated = refs_[sub_id]\n            # Skip disabled components\n            if Component.is_instantiable(v) and updated is None:\n                continue\n        else:\n            updated = cls.update_config_with_refs(v, sub_id, refs_)\n\n        if isinstance(ret, dict):\n            ret[idx] = updated\n        else:\n            ret.append(updated)\n\n    return ret\n</code></pre>"},{"location":"reference/#sparkwheel.Resolver.update_refs_pattern","title":"<code>update_refs_pattern(value, refs)</code>  <code>classmethod</code>","text":"<p>Replace reference patterns with resolved values.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>String containing references</p> required <code>refs</code> <code>dict</code> <p>Dict of resolved references</p> required <p>Returns:</p> Type Description <code>str</code> <p>String with references replaced</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef update_refs_pattern(cls, value: str, refs: dict) -&gt; str:\n    \"\"\"Replace reference patterns with resolved values.\n\n    Args:\n        value: String containing references\n        refs: Dict of resolved references\n\n    Returns:\n        String with references replaced\n    \"\"\"\n    value = normalize_id(value)\n\n    try:\n        return replace_references(value, refs, cls._vars)\n    except KeyError as e:\n        # Extract reference ID from error message\n        # The error message format is: \"Reference '@ref_id' not found in resolved references\"\n        ref_id = str(e).split(\"'\")[1].lstrip(\"@\")\n        msg = f\"can not find expected ID '{ref_id}' in the references.\"\n        if not cls.allow_missing_reference:\n            raise KeyError(msg) from e\n        warnings.warn(msg, stacklevel=2)\n        return value\n</code></pre>"},{"location":"reference/#sparkwheel.SourceLocation","title":"<code>SourceLocation</code>  <code>dataclass</code>","text":"<p>Tracks the source location of a config item.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>@dataclass\nclass SourceLocation:\n    \"\"\"Tracks the source location of a config item.\"\"\"\n\n    filepath: str\n    line: int\n    column: int = 0\n    id: str = \"\"\n\n    def __str__(self) -&gt; str:\n        return f\"{self.filepath}:{self.line}\"\n</code></pre>"},{"location":"reference/#sparkwheel.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when configuration validation fails.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Error description</p> <code>field_path</code> <p>Dot-separated path to the invalid field (e.g., \"model.optimizer.lr\")</p> <code>expected_type</code> <p>The type that was expected</p> <code>actual_value</code> <p>The value that failed validation</p> <code>source_location</code> <p>Optional location in source file where error occurred</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>class ValidationError(BaseError):\n    \"\"\"Raised when configuration validation fails.\n\n    Attributes:\n        message: Error description\n        field_path: Dot-separated path to the invalid field (e.g., \"model.optimizer.lr\")\n        expected_type: The type that was expected\n        actual_value: The value that failed validation\n        source_location: Optional location in source file where error occurred\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        field_path: str = \"\",\n        expected_type: type | None = None,\n        actual_value: Any = None,\n        source_location: SourceLocation | None = None,\n    ):\n        \"\"\"Initialize validation error.\n\n        Args:\n            message: Human-readable error message\n            field_path: Dot-separated path to invalid field\n            expected_type: Expected type for the field\n            actual_value: The actual value that failed validation\n            source_location: Source location where the invalid value was defined\n        \"\"\"\n        self.field_path = field_path\n        self.expected_type = expected_type\n        self.actual_value = actual_value\n\n        # Build detailed message\n        full_message = message\n        if field_path:\n            full_message = f\"Validation error at '{field_path}': {message}\"\n        if expected_type is not None:\n            type_name = getattr(expected_type, \"__name__\", str(expected_type))\n            full_message += f\"\\n  Expected type: {type_name}\"\n        if actual_value is not None:\n            actual_type = type(actual_value).__name__\n            full_message += f\"\\n  Actual type: {actual_type}\"\n            full_message += f\"\\n  Actual value: {actual_value!r}\"\n\n        super().__init__(full_message, source_location=source_location)\n</code></pre>"},{"location":"reference/#sparkwheel.ValidationError.__init__","title":"<code>__init__(message, field_path='', expected_type=None, actual_value=None, source_location=None)</code>","text":"<p>Initialize validation error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message</p> required <code>field_path</code> <code>str</code> <p>Dot-separated path to invalid field</p> <code>''</code> <code>expected_type</code> <code>type | None</code> <p>Expected type for the field</p> <code>None</code> <code>actual_value</code> <code>Any</code> <p>The actual value that failed validation</p> <code>None</code> <code>source_location</code> <code>SourceLocation | None</code> <p>Source location where the invalid value was defined</p> <code>None</code> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    field_path: str = \"\",\n    expected_type: type | None = None,\n    actual_value: Any = None,\n    source_location: SourceLocation | None = None,\n):\n    \"\"\"Initialize validation error.\n\n    Args:\n        message: Human-readable error message\n        field_path: Dot-separated path to invalid field\n        expected_type: Expected type for the field\n        actual_value: The actual value that failed validation\n        source_location: Source location where the invalid value was defined\n    \"\"\"\n    self.field_path = field_path\n    self.expected_type = expected_type\n    self.actual_value = actual_value\n\n    # Build detailed message\n    full_message = message\n    if field_path:\n        full_message = f\"Validation error at '{field_path}': {message}\"\n    if expected_type is not None:\n        type_name = getattr(expected_type, \"__name__\", str(expected_type))\n        full_message += f\"\\n  Expected type: {type_name}\"\n    if actual_value is not None:\n        actual_type = type(actual_value).__name__\n        full_message += f\"\\n  Actual type: {actual_type}\"\n        full_message += f\"\\n  Actual value: {actual_value!r}\"\n\n    super().__init__(full_message, source_location=source_location)\n</code></pre>"},{"location":"reference/#sparkwheel.apply_operators","title":"<code>apply_operators(base, override)</code>","text":"<p>Apply configuration changes with composition-by-default semantics.</p> <p>Default behavior: Compose (merge dicts, extend lists) Operators:     =key: value   - Replace operator: completely replace value (override default)     ~key: null    - Remove operator: delete key or list items (idempotent)     key: value    - Compose (default): merge dict or extend list</p> Composition-by-Default Philosophy <ul> <li>Dicts merge recursively by default (preserves existing keys)</li> <li>Lists extend by default (append new items)</li> <li>Only scalars and type mismatches replace</li> <li>Use = to explicitly replace entire dicts or lists</li> <li>Use ~ to delete keys (idempotent - no error if missing)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>dict</code> <p>Base configuration dict</p> required <code>override</code> <code>dict</code> <p>Override configuration dict with optional =/~ operators</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Merged configuration dict</p> <p>Raises:</p> Type Description <code>ConfigMergeError</code> <p>If operators are used incorrectly</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Default: Dicts merge\n&gt;&gt;&gt; base = {\"a\": 1, \"b\": {\"x\": 1, \"y\": 2}}\n&gt;&gt;&gt; override = {\"b\": {\"x\": 10}}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"a\": 1, \"b\": {\"x\": 10, \"y\": 2}}\n</code></pre> <pre><code>&gt;&gt;&gt; # Default: Lists extend\n&gt;&gt;&gt; base = {\"plugins\": [\"logger\", \"metrics\"]}\n&gt;&gt;&gt; override = {\"plugins\": [\"cache\"]}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"plugins\": [\"logger\", \"metrics\", \"cache\"]}\n</code></pre> <pre><code>&gt;&gt;&gt; # Replace operator: explicit override\n&gt;&gt;&gt; base = {\"model\": {\"lr\": 0.001, \"dropout\": 0.1}}\n&gt;&gt;&gt; override = {\"=model\": {\"lr\": 0.01}}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"model\": {\"lr\": 0.01}}\n</code></pre> <pre><code>&gt;&gt;&gt; # Remove operator: delete key (idempotent)\n&gt;&gt;&gt; base = {\"a\": 1, \"b\": 2, \"c\": 3}\n&gt;&gt;&gt; override = {\"b\": 5, \"~c\": None}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"a\": 1, \"b\": 5}\n</code></pre> Source code in <code>src/sparkwheel/operators.py</code> <pre><code>def apply_operators(base: dict, override: dict) -&gt; dict:\n    \"\"\"Apply configuration changes with composition-by-default semantics.\n\n    Default behavior: Compose (merge dicts, extend lists)\n    Operators:\n        =key: value   - Replace operator: completely replace value (override default)\n        ~key: null    - Remove operator: delete key or list items (idempotent)\n        key: value    - Compose (default): merge dict or extend list\n\n    Composition-by-Default Philosophy:\n        - Dicts merge recursively by default (preserves existing keys)\n        - Lists extend by default (append new items)\n        - Only scalars and type mismatches replace\n        - Use = to explicitly replace entire dicts or lists\n        - Use ~ to delete keys (idempotent - no error if missing)\n\n    Args:\n        base: Base configuration dict\n        override: Override configuration dict with optional =/~ operators\n\n    Returns:\n        Merged configuration dict\n\n    Raises:\n        ConfigMergeError: If operators are used incorrectly\n\n    Examples:\n        &gt;&gt;&gt; # Default: Dicts merge\n        &gt;&gt;&gt; base = {\"a\": 1, \"b\": {\"x\": 1, \"y\": 2}}\n        &gt;&gt;&gt; override = {\"b\": {\"x\": 10}}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"a\": 1, \"b\": {\"x\": 10, \"y\": 2}}\n\n        &gt;&gt;&gt; # Default: Lists extend\n        &gt;&gt;&gt; base = {\"plugins\": [\"logger\", \"metrics\"]}\n        &gt;&gt;&gt; override = {\"plugins\": [\"cache\"]}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"plugins\": [\"logger\", \"metrics\", \"cache\"]}\n\n        &gt;&gt;&gt; # Replace operator: explicit override\n        &gt;&gt;&gt; base = {\"model\": {\"lr\": 0.001, \"dropout\": 0.1}}\n        &gt;&gt;&gt; override = {\"=model\": {\"lr\": 0.01}}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"model\": {\"lr\": 0.01}}\n\n        &gt;&gt;&gt; # Remove operator: delete key (idempotent)\n        &gt;&gt;&gt; base = {\"a\": 1, \"b\": 2, \"c\": 3}\n        &gt;&gt;&gt; override = {\"b\": 5, \"~c\": None}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"a\": 1, \"b\": 5}\n    \"\"\"\n    if not isinstance(base, dict) or not isinstance(override, dict):\n        return deepcopy(override)\n\n    result = deepcopy(base)\n\n    for key, value in override.items():\n        if not isinstance(key, str):\n            result[key] = deepcopy(value)\n            continue\n\n        # Process replace operator (=key)\n        if key.startswith(REPLACE_KEY):\n            actual_key = key[1:]\n            result[actual_key] = deepcopy(value)\n            continue\n\n        # Process remove operator (~key)\n        if key.startswith(REMOVE_KEY):\n            actual_key = key[1:]\n            _validate_delete_operator(actual_key, value)\n\n            # Idempotent: no error if key doesn't exist\n            if actual_key not in result:\n                continue  # Silently skip\n\n            # Handle remove entire key (null or empty value)\n            if value is None or value == \"\":\n                del result[actual_key]\n                continue\n\n            # Handle remove specific items from list or dict (list value)\n            if isinstance(value, list):\n                base_val = result[actual_key]\n\n                # Remove from list by indices\n                if isinstance(base_val, list):\n                    list_len = len(base_val)\n\n                    # Validate all items are integers and normalize negative indices\n                    normalized_indices = []\n                    for idx in value:\n                        if not isinstance(idx, int):\n                            raise ConfigMergeError(\n                                f\"Cannot remove from list '{actual_key}': index must be integer, got {type(idx).__name__}\",\n                                suggestion=f\"When removing from a list, provide integer indices.\\n\\n\"\n                                f\"Example:\\n\"\n                                f\"  ~{actual_key}: [0, 2, 4]  # Remove items at indices 0, 2, 4\\n\"\n                                f\"  ~{actual_key}: [-1]       # Remove last item\",\n                            )\n\n                        # Validate index is in bounds\n                        if idx &gt;= list_len or idx &lt; -list_len:\n                            raise ConfigMergeError(\n                                f\"Cannot remove from list '{actual_key}': index {idx} out of range (list has {list_len} items)\",\n                                suggestion=f\"Valid indices are 0 to {list_len - 1}, or -{list_len} to -1.\\n\"\n                                f\"Use null to remove the entire list:\\n\"\n                                f\"  ~{actual_key}: null\",\n                            )\n\n                        # Normalize negative indices to positive\n                        normalized_idx = idx if idx &gt;= 0 else list_len + idx\n                        normalized_indices.append(normalized_idx)\n\n                    # Sort indices in descending order and remove duplicates\n                    sorted_indices = sorted(set(normalized_indices), reverse=True)\n\n                    # Remove in descending order to avoid shifting issues\n                    for idx in sorted_indices:\n                        del base_val[idx]\n\n                # Remove from dict by keys\n                elif isinstance(base_val, dict):\n                    for del_key in value:\n                        if del_key not in base_val:\n                            raise ConfigMergeError(\n                                f\"Cannot remove non-existent key '{del_key}' from '{actual_key}'\",\n                                suggestion=f\"The key '{del_key}' does not exist in '{actual_key}'.\\n\"\n                                f\"Available keys: {list(base_val.keys())}\",\n                            )\n                        del base_val[del_key]\n\n                else:\n                    raise ConfigMergeError(\n                        f\"Cannot remove items from '{actual_key}': expected list or dict, got {type(base_val).__name__}\",\n                        suggestion=f\"Item removal with '~{actual_key}: [...]' only works for lists and dicts.\\n\"\n                        f\"To remove the entire key:\\n\"\n                        f\"  ~{actual_key}: null\",\n                    )\n\n                continue\n\n        # No operator - COMPOSITION-BY-DEFAULT behavior\n        if key in result:\n            base_val = result[key]\n\n            # For dicts: MERGE (composition)\n            if isinstance(base_val, dict) and isinstance(value, dict):\n                result[key] = apply_operators(base_val, value)\n                continue\n\n            # For lists: EXTEND (composition)\n            if isinstance(base_val, list) and isinstance(value, list):\n                result[key] = base_val + value\n                continue\n\n            # For scalars: REPLACE\n            # For type mismatches: REPLACE\n\n        # Set/replace (for new keys or non-matching types)\n        result[key] = deepcopy(value)\n\n    return result\n</code></pre>"},{"location":"reference/#sparkwheel.enable_colors","title":"<code>enable_colors(enabled=None)</code>","text":"<p>Enable or disable color output.</p> <p>Parameters:</p> Name Type Description Default <code>enabled</code> <code>bool | None</code> <p>True to enable, False to disable, None for auto-detection</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Current color enable status</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; enable_colors(False)  # Disable colors\nFalse\n&gt;&gt;&gt; enable_colors(True)   # Force enable colors\nTrue\n&gt;&gt;&gt; enable_colors()       # Auto-detect\nTrue  # (if terminal supports it)\n</code></pre> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def enable_colors(enabled: bool | None = None) -&gt; bool:\n    \"\"\"Enable or disable color output.\n\n    Args:\n        enabled: True to enable, False to disable, None for auto-detection\n\n    Returns:\n        Current color enable status\n\n    Examples:\n        &gt;&gt;&gt; enable_colors(False)  # Disable colors\n        False\n        &gt;&gt;&gt; enable_colors(True)   # Force enable colors\n        True\n        &gt;&gt;&gt; enable_colors()       # Auto-detect\n        True  # (if terminal supports it)\n    \"\"\"\n    global _COLORS_ENABLED\n\n    if enabled is None:\n        _COLORS_ENABLED = _supports_color()\n    else:\n        _COLORS_ENABLED = enabled\n\n    return _COLORS_ENABLED\n</code></pre>"},{"location":"reference/#sparkwheel.parse_override","title":"<code>parse_override(arg)</code>","text":"<p>Parse a single CLI override argument.</p> <p>Parses command-line overrides in the format \"key::path=value\" where: - key::path uses Sparkwheel's path separator (::) - value is automatically parsed as Python literal when possible</p> <p>Parameters:</p> Name Type Description Default <code>arg</code> <code>str</code> <p>Override string in format \"key::path=value\"</p> required <p>Returns:</p> Type Description <code>str</code> <p>Tuple of (key, parsed_value) where value has been converted to</p> <code>Any</code> <p>appropriate Python type (int, float, list, dict, bool, None, or str)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the argument format is invalid (no '=' sign)</p> <p>Examples:</p> <p>Parse integers:     &gt;&gt;&gt; parse_override(\"trainer::max_epochs=100\")     ('trainer::max_epochs', 100)</p> <p>Parse floats:     &gt;&gt;&gt; parse_override(\"model::lr=0.001\")     ('model::lr', 0.001)</p> <p>Parse lists:     &gt;&gt;&gt; parse_override(\"trainer::devices=[0,1,2]\")     ('trainer::devices', [0, 1, 2])</p> <p>Parse booleans:     &gt;&gt;&gt; parse_override(\"trainer::fast_dev_run=True\")     ('trainer::fast_dev_run', True)</p> <p>Parse None:     &gt;&gt;&gt; parse_override(\"model::scheduler=None\")     ('model::scheduler', None)</p> <p>Parse dicts:     &gt;&gt;&gt; parse_override(\"model::config={'a':1,'b':2}\")     ('model::config', {'a': 1, 'b': 2})</p> <p>Parse strings (when literal_eval fails):     &gt;&gt;&gt; parse_override(\"model::name=resnet50\")     ('model::name', 'resnet50')</p> <p>Nested paths:     &gt;&gt;&gt; parse_override(\"system::model::optimizer::lr=0.001\")     ('system::model::optimizer::lr', 0.001)</p> Source code in <code>src/sparkwheel/cli.py</code> <pre><code>def parse_override(arg: str) -&gt; tuple[str, Any]:\n    \"\"\"\n    Parse a single CLI override argument.\n\n    Parses command-line overrides in the format \"key::path=value\" where:\n    - key::path uses Sparkwheel's path separator (::)\n    - value is automatically parsed as Python literal when possible\n\n    Args:\n        arg: Override string in format \"key::path=value\"\n\n    Returns:\n        Tuple of (key, parsed_value) where value has been converted to\n        appropriate Python type (int, float, list, dict, bool, None, or str)\n\n    Raises:\n        ValueError: If the argument format is invalid (no '=' sign)\n\n    Examples:\n        Parse integers:\n            &gt;&gt;&gt; parse_override(\"trainer::max_epochs=100\")\n            ('trainer::max_epochs', 100)\n\n        Parse floats:\n            &gt;&gt;&gt; parse_override(\"model::lr=0.001\")\n            ('model::lr', 0.001)\n\n        Parse lists:\n            &gt;&gt;&gt; parse_override(\"trainer::devices=[0,1,2]\")\n            ('trainer::devices', [0, 1, 2])\n\n        Parse booleans:\n            &gt;&gt;&gt; parse_override(\"trainer::fast_dev_run=True\")\n            ('trainer::fast_dev_run', True)\n\n        Parse None:\n            &gt;&gt;&gt; parse_override(\"model::scheduler=None\")\n            ('model::scheduler', None)\n\n        Parse dicts:\n            &gt;&gt;&gt; parse_override(\"model::config={'a':1,'b':2}\")\n            ('model::config', {'a': 1, 'b': 2})\n\n        Parse strings (when literal_eval fails):\n            &gt;&gt;&gt; parse_override(\"model::name=resnet50\")\n            ('model::name', 'resnet50')\n\n        Nested paths:\n            &gt;&gt;&gt; parse_override(\"system::model::optimizer::lr=0.001\")\n            ('system::model::optimizer::lr', 0.001)\n    \"\"\"\n    if \"=\" not in arg:\n        raise ValueError(f\"Invalid override format: '{arg}'. Expected format: 'key::path=value'\")\n\n    # Split on first = only (value might contain =)\n    key, value_str = arg.split(\"=\", 1)\n\n    # Try to parse value as Python literal\n    # This handles: int, float, list, dict, tuple, bool, None\n    try:\n        value = ast.literal_eval(value_str)\n    except (ValueError, SyntaxError):\n        # If parsing fails, keep as string\n        # This handles strings that don't need quotes on CLI\n        value = value_str\n\n    return key, value\n</code></pre>"},{"location":"reference/#sparkwheel.parse_overrides","title":"<code>parse_overrides(args)</code>","text":"<p>Parse multiple CLI override arguments.</p> <p>Convenience function to parse a list of override strings into a dictionary suitable for passing to Config.set() or Config.update().</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>list[str]</code> <p>List of override strings in format \"key::path=value\"</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping configuration keys to parsed values</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any argument has invalid format</p> <p>Examples:</p> <p>Basic usage:     &gt;&gt;&gt; parse_overrides([     ...     \"model::lr=0.001\",     ...     \"trainer::max_epochs=100\"     ... ])</p> <p>Mixed types:     &gt;&gt;&gt; parse_overrides([     ...     \"model::name=resnet50\",     ...     \"model::layers=[64,128,256]\",     ...     \"trainer::devices=[0,1]\",     ...     \"debug=True\"     ... ])     {         'model::name': 'resnet50',         'model::layers': [64, 128, 256],         'trainer::devices': [0, 1],         'debug': True     }</p> <p>Empty list:     &gt;&gt;&gt; parse_overrides([])     {}</p> <p>With Config:     &gt;&gt;&gt; from sparkwheel import Config     &gt;&gt;&gt; config = Config.load(\"config.yaml\")     &gt;&gt;&gt; overrides = parse_overrides([\"model::lr=0.01\"])     &gt;&gt;&gt; for key, value in overrides.items():     ...     config.set(key, value)</p> Source code in <code>src/sparkwheel/cli.py</code> <pre><code>def parse_overrides(args: list[str]) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse multiple CLI override arguments.\n\n    Convenience function to parse a list of override strings into\n    a dictionary suitable for passing to Config.set() or Config.update().\n\n    Args:\n        args: List of override strings in format \"key::path=value\"\n\n    Returns:\n        Dictionary mapping configuration keys to parsed values\n\n    Raises:\n        ValueError: If any argument has invalid format\n\n    Examples:\n        Basic usage:\n            &gt;&gt;&gt; parse_overrides([\n            ...     \"model::lr=0.001\",\n            ...     \"trainer::max_epochs=100\"\n            ... ])\n            {'model::lr': 0.001, 'trainer::max_epochs': 100}\n\n        Mixed types:\n            &gt;&gt;&gt; parse_overrides([\n            ...     \"model::name=resnet50\",\n            ...     \"model::layers=[64,128,256]\",\n            ...     \"trainer::devices=[0,1]\",\n            ...     \"debug=True\"\n            ... ])\n            {\n                'model::name': 'resnet50',\n                'model::layers': [64, 128, 256],\n                'trainer::devices': [0, 1],\n                'debug': True\n            }\n\n        Empty list:\n            &gt;&gt;&gt; parse_overrides([])\n            {}\n\n        With Config:\n            &gt;&gt;&gt; from sparkwheel import Config\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n            &gt;&gt;&gt; overrides = parse_overrides([\"model::lr=0.01\"])\n            &gt;&gt;&gt; for key, value in overrides.items():\n            ...     config.set(key, value)\n    \"\"\"\n    if not args:\n        return {}\n\n    return dict(parse_override(arg) for arg in args)\n</code></pre>"},{"location":"reference/#sparkwheel.validate","title":"<code>validate(config, schema, field_path='', metadata=None)</code>","text":"<p>Validate configuration against a dataclass schema.</p> <p>Performs recursive type checking to ensure the configuration matches the structure and types defined in the dataclass schema.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>Configuration dictionary to validate</p> required <code>schema</code> <code>type</code> <p>Dataclass type defining the expected structure</p> required <code>field_path</code> <code>str</code> <p>Internal parameter for tracking nested field paths</p> <code>''</code> <code>metadata</code> <code>Any</code> <p>Optional metadata registry for source locations</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails</p> <code>TypeError</code> <p>If schema is not a dataclass</p> Example <pre><code>from dataclasses import dataclass\nfrom sparkwheel import Config\nfrom sparkwheel.schema import validate\n\n@dataclass\nclass AppConfig:\n    name: str\n    port: int\n    debug: bool = False\n\nconfig = Config.load(\"app.yaml\")\nvalidate(config.get(), AppConfig)\n</code></pre> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def validate(\n    config: dict[str, Any],\n    schema: type,\n    field_path: str = \"\",\n    metadata: Any = None,\n) -&gt; None:\n    \"\"\"Validate configuration against a dataclass schema.\n\n    Performs recursive type checking to ensure the configuration matches\n    the structure and types defined in the dataclass schema.\n\n    Args:\n        config: Configuration dictionary to validate\n        schema: Dataclass type defining the expected structure\n        field_path: Internal parameter for tracking nested field paths\n        metadata: Optional metadata registry for source locations\n\n    Raises:\n        ValidationError: If validation fails\n        TypeError: If schema is not a dataclass\n\n    Example:\n        ```python\n        from dataclasses import dataclass\n        from sparkwheel import Config\n        from sparkwheel.schema import validate\n\n        @dataclass\n        class AppConfig:\n            name: str\n            port: int\n            debug: bool = False\n\n        config = Config.load(\"app.yaml\")\n        validate(config.get(), AppConfig)\n        ```\n    \"\"\"\n    if not dataclasses.is_dataclass(schema):\n        raise TypeError(f\"Schema must be a dataclass, got {type(schema).__name__}\")\n\n    if not isinstance(config, dict):\n        source_loc = _get_source_location(metadata, field_path) if metadata else None\n        raise ValidationError(\n            f\"Expected dict for dataclass {schema.__name__}\",\n            field_path=field_path,\n            expected_type=dict,\n            actual_value=config,\n            source_location=source_loc,\n        )\n\n    # Get all fields from the dataclass\n    schema_fields = {f.name: f for f in dataclasses.fields(schema)}\n\n    # Check for required fields\n    for field_name, field_info in schema_fields.items():\n        current_path = f\"{field_path}.{field_name}\" if field_path else field_name\n\n        # Check if field is missing\n        if field_name not in config:\n            # Field has default or default_factory -&gt; optional\n            if field_info.default is not dataclasses.MISSING or field_info.default_factory is not dataclasses.MISSING:  # type: ignore[comparison-overlap]\n                continue\n            # No default -&gt; required\n            source_loc = _get_source_location(metadata, field_path) if metadata else None\n            raise ValidationError(\n                f\"Missing required field '{field_name}'\",\n                field_path=current_path,\n                expected_type=field_info.type,\n                source_location=source_loc,\n            )\n\n        # Validate the field value\n        _validate_field(\n            config[field_name],\n            field_info.type,\n            current_path,\n            metadata,\n        )\n\n    # Check for unexpected fields\n    unexpected_fields = set(config.keys()) - set(schema_fields.keys())\n    # Filter out sparkwheel special keys\n    special_keys = {\"_target_\", \"_disabled_\", \"_requires_\", \"_mode_\"}\n    unexpected_fields = unexpected_fields - special_keys\n\n    if unexpected_fields:\n        first_unexpected = sorted(unexpected_fields)[0]\n        current_path = f\"{field_path}.{first_unexpected}\" if field_path else first_unexpected\n        source_loc = _get_source_location(metadata, current_path) if metadata else None\n        raise ValidationError(\n            f\"Unexpected field '{first_unexpected}' not in schema {schema.__name__}\",\n            field_path=current_path,\n            source_location=source_loc,\n        )\n\n    # Run custom validators\n    _run_validators(config, schema, field_path, metadata)\n</code></pre>"},{"location":"reference/#sparkwheel.validate_operators","title":"<code>validate_operators(config, parent_key='')</code>","text":"<p>Validate operator usage in config tree.</p> <p>With composition-by-default, validation is simpler: 1. Remove operators always work (idempotent delete) 2. Replace operators work on any type 3. No parent context requirements</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dict to validate</p> required <code>parent_key</code> <code>str</code> <p>Parent key path (for error messages)</p> <code>''</code> <p>Raises:</p> Type Description <code>ConfigMergeError</code> <p>If operator usage is invalid</p> Source code in <code>src/sparkwheel/operators.py</code> <pre><code>def validate_operators(config: dict, parent_key: str = \"\") -&gt; None:\n    \"\"\"Validate operator usage in config tree.\n\n    With composition-by-default, validation is simpler:\n    1. Remove operators always work (idempotent delete)\n    2. Replace operators work on any type\n    3. No parent context requirements\n\n    Args:\n        config: Configuration dict to validate\n        parent_key: Parent key path (for error messages)\n\n    Raises:\n        ConfigMergeError: If operator usage is invalid\n    \"\"\"\n    if not isinstance(config, dict):\n        return\n\n    for key, value in config.items():\n        if not isinstance(key, str):\n            continue\n\n        actual_key = key\n        operator = None\n\n        # Detect operator\n        if key.startswith(REPLACE_KEY):\n            actual_key = key[1:]\n            operator = \"replace\"\n        elif key.startswith(REMOVE_KEY):\n            actual_key = key[1:]\n            operator = \"remove\"\n\n        full_key = f\"{parent_key}::{actual_key}\" if parent_key else actual_key\n\n        # Validate remove operator\n        if operator == \"remove\":\n            _validate_delete_operator(actual_key, value)\n\n        # Recurse into nested dicts\n        if isinstance(value, dict) and operator != \"remove\":\n            validate_operators(value, full_key)\n</code></pre>"},{"location":"reference/#sparkwheel.validator","title":"<code>validator(func)</code>","text":"<p>Decorator to mark a method as a validator.</p> <p>Validators run after type checking and can validate single fields or relationships between fields. Raise ValueError on failure.</p> Example <p>@dataclass class Config:     lr: float     start: int     end: int</p> <pre><code>@validator\ndef check_lr(self):\n    if not (0 &lt; self.lr &lt; 1):\n        raise ValueError(\"lr must be between 0 and 1\")\n\n@validator\ndef check_range(self):\n    if self.end &lt;= self.start:\n        raise ValueError(\"end must be &gt; start\")\n</code></pre> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def validator(func):\n    \"\"\"Decorator to mark a method as a validator.\n\n    Validators run after type checking and can validate single fields\n    or relationships between fields. Raise ValueError on failure.\n\n    Example:\n        @dataclass\n        class Config:\n            lr: float\n            start: int\n            end: int\n\n            @validator\n            def check_lr(self):\n                if not (0 &lt; self.lr &lt; 1):\n                    raise ValueError(\"lr must be between 0 and 1\")\n\n            @validator\n            def check_range(self):\n                if self.end &lt;= self.start:\n                    raise ValueError(\"end must be &gt; start\")\n    \"\"\"\n    func.__is_validator__ = True\n    return func\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sparkwheel<ul> <li>cli</li> <li>config</li> <li>errors<ul> <li>context</li> <li>formatters</li> <li>suggestions</li> </ul> </li> <li>items</li> <li>loader</li> <li>metadata</li> <li>operators</li> <li>parser</li> <li>path_patterns</li> <li>path_utils</li> <li>preprocessor</li> <li>resolver</li> <li>schema</li> <li>utils<ul> <li>constants</li> <li>enums</li> <li>exceptions</li> <li>misc</li> <li>module</li> <li>types</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/cli/","title":"cli","text":"<p>CLI utilities for Sparkwheel configuration overrides.</p> <p>This module provides utilities for parsing command-line configuration overrides in the format \"key::path=value\". Designed to be reusable across any application using Sparkwheel for configuration management.</p> <p>Examples:</p> <p>Basic parsing:     &gt;&gt;&gt; from sparkwheel.cli import parse_override     &gt;&gt;&gt; key, value = parse_override(\"model::lr=0.001\")     &gt;&gt;&gt; print(key, value)     model::lr 0.001</p> <p>Multiple overrides:     &gt;&gt;&gt; from sparkwheel.cli import parse_overrides     &gt;&gt;&gt; overrides = parse_overrides([     ...     \"model::lr=0.001\",     ...     \"trainer::max_epochs=100\"     ... ])     &gt;&gt;&gt; print(overrides)</p> <p>Using with Config:     &gt;&gt;&gt; from sparkwheel import Config     &gt;&gt;&gt; config = Config.from_cli(     ...     \"config.yaml\",     ...     [\"model::lr=0.001\", \"trainer::devices=[0,1,2]\"]     ... )</p>"},{"location":"reference/cli/#sparkwheel.cli.parse_override","title":"<code>parse_override(arg)</code>","text":"<p>Parse a single CLI override argument.</p> <p>Parses command-line overrides in the format \"key::path=value\" where: - key::path uses Sparkwheel's path separator (::) - value is automatically parsed as Python literal when possible</p> <p>Parameters:</p> Name Type Description Default <code>arg</code> <code>str</code> <p>Override string in format \"key::path=value\"</p> required <p>Returns:</p> Type Description <code>str</code> <p>Tuple of (key, parsed_value) where value has been converted to</p> <code>Any</code> <p>appropriate Python type (int, float, list, dict, bool, None, or str)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the argument format is invalid (no '=' sign)</p> <p>Examples:</p> <p>Parse integers:     &gt;&gt;&gt; parse_override(\"trainer::max_epochs=100\")     ('trainer::max_epochs', 100)</p> <p>Parse floats:     &gt;&gt;&gt; parse_override(\"model::lr=0.001\")     ('model::lr', 0.001)</p> <p>Parse lists:     &gt;&gt;&gt; parse_override(\"trainer::devices=[0,1,2]\")     ('trainer::devices', [0, 1, 2])</p> <p>Parse booleans:     &gt;&gt;&gt; parse_override(\"trainer::fast_dev_run=True\")     ('trainer::fast_dev_run', True)</p> <p>Parse None:     &gt;&gt;&gt; parse_override(\"model::scheduler=None\")     ('model::scheduler', None)</p> <p>Parse dicts:     &gt;&gt;&gt; parse_override(\"model::config={'a':1,'b':2}\")     ('model::config', {'a': 1, 'b': 2})</p> <p>Parse strings (when literal_eval fails):     &gt;&gt;&gt; parse_override(\"model::name=resnet50\")     ('model::name', 'resnet50')</p> <p>Nested paths:     &gt;&gt;&gt; parse_override(\"system::model::optimizer::lr=0.001\")     ('system::model::optimizer::lr', 0.001)</p> Source code in <code>src/sparkwheel/cli.py</code> <pre><code>def parse_override(arg: str) -&gt; tuple[str, Any]:\n    \"\"\"\n    Parse a single CLI override argument.\n\n    Parses command-line overrides in the format \"key::path=value\" where:\n    - key::path uses Sparkwheel's path separator (::)\n    - value is automatically parsed as Python literal when possible\n\n    Args:\n        arg: Override string in format \"key::path=value\"\n\n    Returns:\n        Tuple of (key, parsed_value) where value has been converted to\n        appropriate Python type (int, float, list, dict, bool, None, or str)\n\n    Raises:\n        ValueError: If the argument format is invalid (no '=' sign)\n\n    Examples:\n        Parse integers:\n            &gt;&gt;&gt; parse_override(\"trainer::max_epochs=100\")\n            ('trainer::max_epochs', 100)\n\n        Parse floats:\n            &gt;&gt;&gt; parse_override(\"model::lr=0.001\")\n            ('model::lr', 0.001)\n\n        Parse lists:\n            &gt;&gt;&gt; parse_override(\"trainer::devices=[0,1,2]\")\n            ('trainer::devices', [0, 1, 2])\n\n        Parse booleans:\n            &gt;&gt;&gt; parse_override(\"trainer::fast_dev_run=True\")\n            ('trainer::fast_dev_run', True)\n\n        Parse None:\n            &gt;&gt;&gt; parse_override(\"model::scheduler=None\")\n            ('model::scheduler', None)\n\n        Parse dicts:\n            &gt;&gt;&gt; parse_override(\"model::config={'a':1,'b':2}\")\n            ('model::config', {'a': 1, 'b': 2})\n\n        Parse strings (when literal_eval fails):\n            &gt;&gt;&gt; parse_override(\"model::name=resnet50\")\n            ('model::name', 'resnet50')\n\n        Nested paths:\n            &gt;&gt;&gt; parse_override(\"system::model::optimizer::lr=0.001\")\n            ('system::model::optimizer::lr', 0.001)\n    \"\"\"\n    if \"=\" not in arg:\n        raise ValueError(f\"Invalid override format: '{arg}'. Expected format: 'key::path=value'\")\n\n    # Split on first = only (value might contain =)\n    key, value_str = arg.split(\"=\", 1)\n\n    # Try to parse value as Python literal\n    # This handles: int, float, list, dict, tuple, bool, None\n    try:\n        value = ast.literal_eval(value_str)\n    except (ValueError, SyntaxError):\n        # If parsing fails, keep as string\n        # This handles strings that don't need quotes on CLI\n        value = value_str\n\n    return key, value\n</code></pre>"},{"location":"reference/cli/#sparkwheel.cli.parse_overrides","title":"<code>parse_overrides(args)</code>","text":"<p>Parse multiple CLI override arguments.</p> <p>Convenience function to parse a list of override strings into a dictionary suitable for passing to Config.set() or Config.update().</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>list[str]</code> <p>List of override strings in format \"key::path=value\"</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping configuration keys to parsed values</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any argument has invalid format</p> <p>Examples:</p> <p>Basic usage:     &gt;&gt;&gt; parse_overrides([     ...     \"model::lr=0.001\",     ...     \"trainer::max_epochs=100\"     ... ])</p> <p>Mixed types:     &gt;&gt;&gt; parse_overrides([     ...     \"model::name=resnet50\",     ...     \"model::layers=[64,128,256]\",     ...     \"trainer::devices=[0,1]\",     ...     \"debug=True\"     ... ])     {         'model::name': 'resnet50',         'model::layers': [64, 128, 256],         'trainer::devices': [0, 1],         'debug': True     }</p> <p>Empty list:     &gt;&gt;&gt; parse_overrides([])     {}</p> <p>With Config:     &gt;&gt;&gt; from sparkwheel import Config     &gt;&gt;&gt; config = Config.load(\"config.yaml\")     &gt;&gt;&gt; overrides = parse_overrides([\"model::lr=0.01\"])     &gt;&gt;&gt; for key, value in overrides.items():     ...     config.set(key, value)</p> Source code in <code>src/sparkwheel/cli.py</code> <pre><code>def parse_overrides(args: list[str]) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse multiple CLI override arguments.\n\n    Convenience function to parse a list of override strings into\n    a dictionary suitable for passing to Config.set() or Config.update().\n\n    Args:\n        args: List of override strings in format \"key::path=value\"\n\n    Returns:\n        Dictionary mapping configuration keys to parsed values\n\n    Raises:\n        ValueError: If any argument has invalid format\n\n    Examples:\n        Basic usage:\n            &gt;&gt;&gt; parse_overrides([\n            ...     \"model::lr=0.001\",\n            ...     \"trainer::max_epochs=100\"\n            ... ])\n            {'model::lr': 0.001, 'trainer::max_epochs': 100}\n\n        Mixed types:\n            &gt;&gt;&gt; parse_overrides([\n            ...     \"model::name=resnet50\",\n            ...     \"model::layers=[64,128,256]\",\n            ...     \"trainer::devices=[0,1]\",\n            ...     \"debug=True\"\n            ... ])\n            {\n                'model::name': 'resnet50',\n                'model::layers': [64, 128, 256],\n                'trainer::devices': [0, 1],\n                'debug': True\n            }\n\n        Empty list:\n            &gt;&gt;&gt; parse_overrides([])\n            {}\n\n        With Config:\n            &gt;&gt;&gt; from sparkwheel import Config\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n            &gt;&gt;&gt; overrides = parse_overrides([\"model::lr=0.01\"])\n            &gt;&gt;&gt; for key, value in overrides.items():\n            ...     config.set(key, value)\n    \"\"\"\n    if not args:\n        return {}\n\n    return dict(parse_override(arg) for arg in args)\n</code></pre>"},{"location":"reference/config/","title":"config","text":"<p>Main configuration management API.</p>"},{"location":"reference/config/#sparkwheel.config.Config","title":"<code>Config</code>","text":"<p>Configuration management with resolved references, raw references, expressions, and instantiation.</p> <p>Main entry point for loading, managing, and resolving configurations. Supports YAML files with resolved references (@), raw references (%), expressions ($), and dynamic instantiation (target).</p> Example <pre><code>from sparkwheel import Config\n\n# Load from file\nconfig = Config.load(\"config.yaml\")\n\n# Load from dict\nconfig = Config.load({\"model\": {\"lr\": 0.001}})\n\n# Load multiple files (merged in order)\nconfig = Config.load([\"base.yaml\", \"override.yaml\"])\n\n# Access raw values\nlr = config.get(\"model::lr\")\n\n# Set values\nconfig.set(\"model::dropout\", 0.1)\n\n# Update with additional config\nconfig.update(\"experiment.yaml\")\nconfig.update({\"model::lr\": 0.01})\n\n# Resolve references and instantiate\nmodel = config.resolve(\"model\")\neverything = config.resolve()\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict | None</code> <p>Initial configuration data</p> <code>None</code> <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions (e.g., {\"torch\": \"torch\"})</p> <code>None</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>class Config:\n    \"\"\"Configuration management with resolved references, raw references, expressions, and instantiation.\n\n    Main entry point for loading, managing, and resolving configurations.\n    Supports YAML files with resolved references (@), raw references (%), expressions ($),\n    and dynamic instantiation (_target_).\n\n    Example:\n        ```python\n        from sparkwheel import Config\n\n        # Load from file\n        config = Config.load(\"config.yaml\")\n\n        # Load from dict\n        config = Config.load({\"model\": {\"lr\": 0.001}})\n\n        # Load multiple files (merged in order)\n        config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n        # Access raw values\n        lr = config.get(\"model::lr\")\n\n        # Set values\n        config.set(\"model::dropout\", 0.1)\n\n        # Update with additional config\n        config.update(\"experiment.yaml\")\n        config.update({\"model::lr\": 0.01})\n\n        # Resolve references and instantiate\n        model = config.resolve(\"model\")\n        everything = config.resolve()\n        ```\n\n    Args:\n        data: Initial configuration data\n        globals: Pre-imported packages for expressions (e.g., {\"torch\": \"torch\"})\n    \"\"\"\n\n    def __init__(self, data: dict | None = None, globals: dict[str, Any] | None = None):\n        \"\"\"Initialize Config (use Config.load() instead for most cases).\n\n        Args:\n            data: Initial configuration dictionary\n            globals: Global variables for expression evaluation\n        \"\"\"\n        self._data: dict = data or {}\n        self._metadata = MetadataRegistry()\n        self._resolver = Resolver()\n        self._is_parsed = False\n\n        # Process globals (import string module paths)\n        self._globals: dict[str, Any] = {}\n        if isinstance(globals, dict):\n            for k, v in globals.items():\n                self._globals[k] = optional_import(v)[0] if isinstance(v, str) else v\n\n        self._loader = Loader()\n        self._preprocessor = Preprocessor(self._loader, self._globals)\n\n    @classmethod\n    def load(\n        cls,\n        source: PathLike | Sequence[PathLike] | dict,\n        globals: dict[str, Any] | None = None,\n        schema: type | None = None,\n    ) -&gt; \"Config\":\n        \"\"\"Load configuration from file(s) or dict.\n\n        Primary method for creating Config instances.\n\n        Args:\n            source: File path, list of paths, or config dict\n            globals: Pre-imported packages for expressions\n            schema: Optional dataclass schema for validation\n\n        Returns:\n            New Config instance\n\n        Merge Behavior:\n            Files are merged in order (composition-by-default). Use operators to control merging:\n            - key: value   - Compose (default): merge dict or extend list\n            - =key: value  - Replace operator: completely replace value\n            - ~key: null   - Remove operator: delete key (idempotent)\n\n        Examples:\n            &gt;&gt;&gt; # Single file\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n\n            &gt;&gt;&gt; # Multiple files (merged)\n            &gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n            &gt;&gt;&gt; # From dict\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n\n            &gt;&gt;&gt; # With globals for expressions\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n\n            &gt;&gt;&gt; # With schema validation\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class MySchema:\n            ...     name: str\n            ...     value: int\n            &gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n        \"\"\"\n        config = cls(globals=globals)\n\n        # Handle dict input\n        if isinstance(source, dict):\n            config._data = source\n            if schema is not None:\n                config.validate(schema)\n            return config\n\n        # Handle file(s) input\n        file_list = ensure_tuple(source)\n        for filepath in file_list:\n            loaded_data, loaded_metadata = config._loader.load_file(filepath)\n            # Validate operators before applying\n            validate_operators(loaded_data)\n            # Merge data and metadata\n            config._data = apply_operators(config._data, loaded_data)\n            config._metadata.merge(loaded_metadata)\n\n        # Validate against schema if provided\n        if schema is not None:\n            config.validate(schema)\n\n        return config\n\n    @classmethod\n    def from_cli(\n        cls,\n        source: PathLike | Sequence[PathLike] | dict,\n        cli_overrides: list[str],\n        globals: dict[str, Any] | None = None,\n        schema: type | None = None,\n    ) -&gt; \"Config\":\n        \"\"\"Load configuration with CLI overrides applied.\n\n        Convenience method for loading configs with command-line overrides.\n        First loads the base config, then applies CLI overrides in the format\n        \"key::path=value\", and optionally validates against a schema.\n\n        Args:\n            source: File path, list of paths, or config dict\n            cli_overrides: List of override strings in format \"key::path=value\"\n            globals: Pre-imported packages for expressions\n            schema: Optional dataclass schema for validation\n\n        Returns:\n            New Config instance with CLI overrides applied\n\n        Examples:\n            &gt;&gt;&gt; # Load with CLI overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n            ... )\n\n            &gt;&gt;&gt; # Multiple files with overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     [\"base.yaml\", \"experiment.yaml\"],\n            ...     [\"model::lr=0.001\"]\n            ... )\n\n            &gt;&gt;&gt; # With schema validation\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class TrainingConfig:\n            ...     model: dict\n            ...     trainer: dict\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\"model::lr=0.001\"],\n            ...     schema=TrainingConfig\n            ... )\n\n            &gt;&gt;&gt; # Complex overrides\n            &gt;&gt;&gt; config = Config.from_cli(\n            ...     \"config.yaml\",\n            ...     [\n            ...         \"model::lr=0.001\",\n            ...         \"trainer::devices=[0,1,2]\",\n            ...         \"model::layers=[128,256,512]\",\n            ...         \"debug=True\"\n            ...     ]\n            ... )\n        \"\"\"\n        from .cli import parse_overrides\n\n        # Load base configuration\n        config = cls.load(source, globals=globals, schema=schema)\n\n        # Apply CLI overrides\n        if cli_overrides:\n            overrides = parse_overrides(cli_overrides)\n            for key, value in overrides.items():\n                config.set(key, value)\n\n            # Re-validate after overrides if schema provided\n            if schema is not None:\n                config.validate(schema)\n\n        return config\n\n    def get(self, id: str = \"\", default: Any = None) -&gt; Any:\n        \"\"\"Get raw config value (unresolved).\n\n        Args:\n            id: Configuration path (use :: for nesting, e.g., \"model::lr\")\n                Empty string returns entire config\n            default: Default value if id not found\n\n        Returns:\n            Raw configuration value (resolved references not resolved, raw references not expanded)\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}})\n            &gt;&gt;&gt; config.get(\"model::lr\")\n            0.001\n            &gt;&gt;&gt; config.get(\"model::ref\")\n            \"@model::lr\"  # Unresolved resolved reference\n        \"\"\"\n        try:\n            return self._get_by_id(id)\n        except (KeyError, IndexError, ValueError):\n            return default\n\n    def set(self, id: str, value: Any) -&gt; None:\n        \"\"\"Set config value, creating paths as needed.\n\n        Args:\n            id: Configuration path (use :: for nesting)\n            value: Value to set\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({})\n            &gt;&gt;&gt; config.set(\"model::lr\", 0.001)\n            &gt;&gt;&gt; config.get(\"model::lr\")\n            0.001\n        \"\"\"\n        if id == \"\":\n            self._data = value\n            self._invalidate_resolution()\n            return\n\n        keys = split_id(id)\n\n        # Ensure root is dict\n        if not isinstance(self._data, dict):\n            self._data = {}\n\n        # Create missing intermediate paths\n        current = self._data\n        for k in keys[:-1]:\n            if k not in current:\n                current[k] = {}\n            elif not isinstance(current[k], dict):\n                current[k] = {}\n            current = current[k]\n\n        # Set final value\n        current[keys[-1]] = value\n        self._invalidate_resolution()\n\n    def validate(self, schema: type) -&gt; None:\n        \"\"\"Validate configuration against a dataclass schema.\n\n        Args:\n            schema: Dataclass type defining the expected structure and types\n\n        Raises:\n            ValidationError: If configuration doesn't match schema\n            TypeError: If schema is not a dataclass\n\n        Example:\n            &gt;&gt;&gt; from dataclasses import dataclass\n            &gt;&gt;&gt; @dataclass\n            ... class ModelConfig:\n            ...     hidden_size: int\n            ...     dropout: float\n            &gt;&gt;&gt; config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1})\n            &gt;&gt;&gt; config.validate(ModelConfig)  # Passes\n            &gt;&gt;&gt; bad_config = Config.load({\"hidden_size\": \"not an int\"})\n            &gt;&gt;&gt; bad_config.validate(ModelConfig)  # Raises ValidationError\n        \"\"\"\n        from .schema import validate as validate_schema\n\n        validate_schema(self._data, schema, metadata=self._metadata)\n\n    def update(self, source: PathLike | dict | \"Config\") -&gt; None:\n        \"\"\"Update configuration with changes from another source.\n\n        Applies changes using operators for fine-grained control.\n        Supports nested paths (::) and compose/replace/delete operators.\n\n        Args:\n            source: File path, dict, or Config instance to update from\n\n        Operators:\n            - key: value   - Compose (default): merge dict or extend list\n            - =key: value  - Replace operator: completely replace value\n            - ~key: null   - Remove operator: delete key (idempotent)\n\n        Examples:\n            &gt;&gt;&gt; # Update from file\n            &gt;&gt;&gt; config.update(\"override.yaml\")\n\n            &gt;&gt;&gt; # Update from dict (merges by default)\n            &gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n\n            &gt;&gt;&gt; # Update from another Config instance\n            &gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n            &gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n            &gt;&gt;&gt; config1.update(config2)\n\n            &gt;&gt;&gt; # Nested path updates\n            &gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n        \"\"\"\n        if isinstance(source, Config):\n            self._update_from_config(source)\n        elif isinstance(source, dict):\n            if self._uses_nested_paths(source):\n                self._apply_path_updates(source)\n            else:\n                self._apply_structural_update(source)\n        else:\n            self._update_from_file(source)\n\n    def _update_from_config(self, source: \"Config\") -&gt; None:\n        \"\"\"Update from another Config instance.\"\"\"\n        self._data = apply_operators(self._data, source._data)\n        self._metadata.merge(source._metadata)\n        self._invalidate_resolution()\n\n    def _uses_nested_paths(self, source: dict) -&gt; bool:\n        \"\"\"Check if dict uses :: path syntax.\"\"\"\n        return any(ID_SEP_KEY in str(k).lstrip(REPLACE_KEY).lstrip(REMOVE_KEY) for k in source.keys())\n\n    def _apply_path_updates(self, source: dict) -&gt; None:\n        \"\"\"Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).\"\"\"\n        for key, value in source.items():\n            if not isinstance(key, str):\n                self.set(str(key), value)\n                continue\n\n            if key.startswith(REPLACE_KEY):\n                # Replace operator: =key (explicit override)\n                actual_key = key[1:]\n                self.set(actual_key, value)\n\n            elif key.startswith(REMOVE_KEY):\n                # Delete operator: ~key (idempotent)\n                actual_key = key[1:]\n                _validate_delete_operator(actual_key, value)\n\n                if actual_key in self:\n                    self._delete_nested_key(actual_key)\n\n            else:\n                # Default: compose (merge dict or extend list)\n                if key in self and isinstance(self[key], dict) and isinstance(value, dict):\n                    merged = apply_operators(self[key], value)\n                    self.set(key, merged)\n                elif key in self and isinstance(self[key], list) and isinstance(value, list):\n                    self.set(key, self[key] + value)\n                else:\n                    # Normal set (handles nested paths with ::)\n                    self.set(key, value)\n\n    def _delete_nested_key(self, key: str) -&gt; None:\n        \"\"\"Delete a key, supporting nested paths with ::.\"\"\"\n        if ID_SEP_KEY in key:\n            keys = split_id(key)\n            parent_id = ID_SEP_KEY.join(keys[:-1])\n            parent = self[parent_id] if parent_id else self._data\n            if isinstance(parent, dict) and keys[-1] in parent:\n                del parent[keys[-1]]\n        else:\n            # Top-level key\n            if isinstance(self._data, dict) and key in self._data:\n                del self._data[key]\n        self._invalidate_resolution()\n\n    def _apply_structural_update(self, source: dict) -&gt; None:\n        \"\"\"Apply structural update with operators.\"\"\"\n        validate_operators(source)\n        self._data = apply_operators(self._data, source)\n        self._invalidate_resolution()\n\n    def _update_from_file(self, source: PathLike) -&gt; None:\n        \"\"\"Load and update from a file.\"\"\"\n        new_data, new_metadata = self._loader.load_file(source)\n        validate_operators(new_data)\n        self._data = apply_operators(self._data, new_data)\n        self._metadata.merge(new_metadata)\n        self._invalidate_resolution()\n\n    def resolve(\n        self,\n        id: str = \"\",\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        lazy: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Resolve resolved references (@) and return parsed config.\n\n        Automatically parses config on first call. Resolves @ resolved references (follows\n        them to get instantiated/evaluated values), evaluates $ expressions, and\n        instantiates _target_ components. Note: % raw references are expanded during\n        preprocessing (before this stage).\n\n        Args:\n            id: Config path to resolve (empty string for entire config)\n            instantiate: Whether to instantiate components with _target_\n            eval_expr: Whether to evaluate $ expressions\n            lazy: Whether to use cached resolution\n            default: Default value if id not found (returns default.get_config() if Item)\n\n        Returns:\n            Resolved value (instantiated objects, evaluated expressions, etc.)\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\n            ...     \"lr\": 0.001,\n            ...     \"doubled\": \"$@lr * 2\",\n            ...     \"optimizer\": {\n            ...         \"_target_\": \"torch.optim.Adam\",\n            ...         \"lr\": \"@lr\"\n            ...     }\n            ... })\n            &gt;&gt;&gt; config.resolve(\"lr\")\n            0.001\n            &gt;&gt;&gt; config.resolve(\"doubled\")\n            0.002\n            &gt;&gt;&gt; optimizer = config.resolve(\"optimizer\")\n            &gt;&gt;&gt; type(optimizer).__name__\n            'Adam'\n        \"\"\"\n        # Parse if needed\n        if not self._is_parsed or not lazy:\n            self._parse()\n\n        # Resolve and return\n        try:\n            return self._resolver.resolve(id=id, instantiate=instantiate, eval_expr=eval_expr)\n        except (KeyError, ConfigKeyError):\n            if default is not None:\n                # If default is an Item, return its config\n                from .items import Item\n\n                if isinstance(default, Item):\n                    return default.get_config()\n                return default\n            raise\n\n    def _parse(self, reset: bool = True) -&gt; None:\n        \"\"\"Parse config tree and prepare for resolution.\n\n        Internal method called automatically by resolve().\n\n        Args:\n            reset: Whether to reset the resolver before parsing (default: True)\n        \"\"\"\n        # Reset resolver if requested\n        if reset:\n            self._resolver.reset()\n\n        # Stage 1: Preprocess (% raw references, @:: relative resolved IDs)\n        self._data = self._preprocessor.process(self._data, self._data, id=\"\")\n\n        # Stage 2: Parse config tree to create Items\n        parser = Parser(globals=self._globals, metadata=self._metadata)\n        items = parser.parse(self._data)\n\n        # Stage 3: Add items to resolver\n        self._resolver.add_items(items)\n\n        self._is_parsed = True\n\n    def _get_by_id(self, id: str) -&gt; Any:\n        \"\"\"Get config value by ID path.\n\n        Args:\n            id: ID path (e.g., \"model::lr\")\n\n        Returns:\n            Config value at that path\n\n        Raises:\n            KeyError: If path not found\n        \"\"\"\n        if id == \"\":\n            return self._data\n\n        config = self._data\n        for k in split_id(id):\n            if not isinstance(config, (dict, list)):\n                raise ValueError(f\"Config must be dict or list for key `{k}`, but got {type(config)}: {config}\")\n            try:\n                config = look_up_option(k, config, print_all_options=False) if isinstance(config, dict) else config[int(k)]\n            except ValueError as e:\n                raise KeyError(f\"Key not found: {k}\") from e\n\n        return config\n\n    def _invalidate_resolution(self) -&gt; None:\n        \"\"\"Invalidate cached resolution (called when config changes).\"\"\"\n        self._is_parsed = False\n        self._resolver.reset()\n\n    def __getitem__(self, id: str) -&gt; Any:\n        \"\"\"Get config value by ID (subscript access).\n\n        Args:\n            id: Configuration path\n\n        Returns:\n            Config value at that path\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n            &gt;&gt;&gt; config[\"model::lr\"]\n            0.001\n        \"\"\"\n        return self._get_by_id(id)\n\n    def __setitem__(self, id: str, value: Any) -&gt; None:\n        \"\"\"Set config value by ID (subscript access).\n\n        Args:\n            id: Configuration path\n            value: Value to set\n\n        Example:\n            &gt;&gt;&gt; config = Config.load({})\n            &gt;&gt;&gt; config[\"model::lr\"] = 0.001\n        \"\"\"\n        self.set(id, value)\n\n    def __contains__(self, id: str) -&gt; bool:\n        \"\"\"Check if ID exists in config.\n\n        Args:\n            id: ID path to check\n\n        Returns:\n            True if exists, False otherwise\n        \"\"\"\n        try:\n            self._get_by_id(id)\n            return True\n        except (KeyError, IndexError, ValueError):\n            return False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of config.\"\"\"\n        return f\"Config({self._data})\"\n\n    @staticmethod\n    def export_config_file(config: dict, filepath: PathLike, **kwargs: Any) -&gt; None:\n        \"\"\"Export config to YAML file.\n\n        Args:\n            config: Config dict to export\n            filepath: Target file path\n            kwargs: Additional arguments for yaml.safe_dump\n        \"\"\"\n        import yaml\n\n        filepath_str = str(Path(filepath))\n        with open(filepath_str, \"w\") as f:\n            yaml.safe_dump(config, f, **kwargs)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.__contains__","title":"<code>__contains__(id)</code>","text":"<p>Check if ID exists in config.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID path to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if exists, False otherwise</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __contains__(self, id: str) -&gt; bool:\n    \"\"\"Check if ID exists in config.\n\n    Args:\n        id: ID path to check\n\n    Returns:\n        True if exists, False otherwise\n    \"\"\"\n    try:\n        self._get_by_id(id)\n        return True\n    except (KeyError, IndexError, ValueError):\n        return False\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.__getitem__","title":"<code>__getitem__(id)</code>","text":"<p>Get config value by ID (subscript access).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Config value at that path</p> Example <p>config = Config.load({\"model\": {\"lr\": 0.001}}) config[\"model::lr\"] 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __getitem__(self, id: str) -&gt; Any:\n    \"\"\"Get config value by ID (subscript access).\n\n    Args:\n        id: Configuration path\n\n    Returns:\n        Config value at that path\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n        &gt;&gt;&gt; config[\"model::lr\"]\n        0.001\n    \"\"\"\n    return self._get_by_id(id)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.__init__","title":"<code>__init__(data=None, globals=None)</code>","text":"<p>Initialize Config (use Config.load() instead for most cases).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict | None</code> <p>Initial configuration dictionary</p> <code>None</code> <code>globals</code> <code>dict[str, Any] | None</code> <p>Global variables for expression evaluation</p> <code>None</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __init__(self, data: dict | None = None, globals: dict[str, Any] | None = None):\n    \"\"\"Initialize Config (use Config.load() instead for most cases).\n\n    Args:\n        data: Initial configuration dictionary\n        globals: Global variables for expression evaluation\n    \"\"\"\n    self._data: dict = data or {}\n    self._metadata = MetadataRegistry()\n    self._resolver = Resolver()\n    self._is_parsed = False\n\n    # Process globals (import string module paths)\n    self._globals: dict[str, Any] = {}\n    if isinstance(globals, dict):\n        for k, v in globals.items():\n            self._globals[k] = optional_import(v)[0] if isinstance(v, str) else v\n\n    self._loader = Loader()\n    self._preprocessor = Preprocessor(self._loader, self._globals)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of config.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of config.\"\"\"\n    return f\"Config({self._data})\"\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.__setitem__","title":"<code>__setitem__(id, value)</code>","text":"<p>Set config value by ID (subscript access).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required Example <p>config = Config.load({}) config[\"model::lr\"] = 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def __setitem__(self, id: str, value: Any) -&gt; None:\n    \"\"\"Set config value by ID (subscript access).\n\n    Args:\n        id: Configuration path\n        value: Value to set\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({})\n        &gt;&gt;&gt; config[\"model::lr\"] = 0.001\n    \"\"\"\n    self.set(id, value)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._apply_path_updates","title":"<code>_apply_path_updates(source)</code>","text":"<p>Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _apply_path_updates(self, source: dict) -&gt; None:\n    \"\"\"Apply nested path updates (e.g., model::lr=value, =model=replace, ~old::param=null).\"\"\"\n    for key, value in source.items():\n        if not isinstance(key, str):\n            self.set(str(key), value)\n            continue\n\n        if key.startswith(REPLACE_KEY):\n            # Replace operator: =key (explicit override)\n            actual_key = key[1:]\n            self.set(actual_key, value)\n\n        elif key.startswith(REMOVE_KEY):\n            # Delete operator: ~key (idempotent)\n            actual_key = key[1:]\n            _validate_delete_operator(actual_key, value)\n\n            if actual_key in self:\n                self._delete_nested_key(actual_key)\n\n        else:\n            # Default: compose (merge dict or extend list)\n            if key in self and isinstance(self[key], dict) and isinstance(value, dict):\n                merged = apply_operators(self[key], value)\n                self.set(key, merged)\n            elif key in self and isinstance(self[key], list) and isinstance(value, list):\n                self.set(key, self[key] + value)\n            else:\n                # Normal set (handles nested paths with ::)\n                self.set(key, value)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._apply_structural_update","title":"<code>_apply_structural_update(source)</code>","text":"<p>Apply structural update with operators.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _apply_structural_update(self, source: dict) -&gt; None:\n    \"\"\"Apply structural update with operators.\"\"\"\n    validate_operators(source)\n    self._data = apply_operators(self._data, source)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._delete_nested_key","title":"<code>_delete_nested_key(key)</code>","text":"<p>Delete a key, supporting nested paths with ::.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _delete_nested_key(self, key: str) -&gt; None:\n    \"\"\"Delete a key, supporting nested paths with ::.\"\"\"\n    if ID_SEP_KEY in key:\n        keys = split_id(key)\n        parent_id = ID_SEP_KEY.join(keys[:-1])\n        parent = self[parent_id] if parent_id else self._data\n        if isinstance(parent, dict) and keys[-1] in parent:\n            del parent[keys[-1]]\n    else:\n        # Top-level key\n        if isinstance(self._data, dict) and key in self._data:\n            del self._data[key]\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._get_by_id","title":"<code>_get_by_id(id)</code>","text":"<p>Get config value by ID path.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID path (e.g., \"model::lr\")</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Config value at that path</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If path not found</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _get_by_id(self, id: str) -&gt; Any:\n    \"\"\"Get config value by ID path.\n\n    Args:\n        id: ID path (e.g., \"model::lr\")\n\n    Returns:\n        Config value at that path\n\n    Raises:\n        KeyError: If path not found\n    \"\"\"\n    if id == \"\":\n        return self._data\n\n    config = self._data\n    for k in split_id(id):\n        if not isinstance(config, (dict, list)):\n            raise ValueError(f\"Config must be dict or list for key `{k}`, but got {type(config)}: {config}\")\n        try:\n            config = look_up_option(k, config, print_all_options=False) if isinstance(config, dict) else config[int(k)]\n        except ValueError as e:\n            raise KeyError(f\"Key not found: {k}\") from e\n\n    return config\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._invalidate_resolution","title":"<code>_invalidate_resolution()</code>","text":"<p>Invalidate cached resolution (called when config changes).</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _invalidate_resolution(self) -&gt; None:\n    \"\"\"Invalidate cached resolution (called when config changes).\"\"\"\n    self._is_parsed = False\n    self._resolver.reset()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._parse","title":"<code>_parse(reset=True)</code>","text":"<p>Parse config tree and prepare for resolution.</p> <p>Internal method called automatically by resolve().</p> <p>Parameters:</p> Name Type Description Default <code>reset</code> <code>bool</code> <p>Whether to reset the resolver before parsing (default: True)</p> <code>True</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _parse(self, reset: bool = True) -&gt; None:\n    \"\"\"Parse config tree and prepare for resolution.\n\n    Internal method called automatically by resolve().\n\n    Args:\n        reset: Whether to reset the resolver before parsing (default: True)\n    \"\"\"\n    # Reset resolver if requested\n    if reset:\n        self._resolver.reset()\n\n    # Stage 1: Preprocess (% raw references, @:: relative resolved IDs)\n    self._data = self._preprocessor.process(self._data, self._data, id=\"\")\n\n    # Stage 2: Parse config tree to create Items\n    parser = Parser(globals=self._globals, metadata=self._metadata)\n    items = parser.parse(self._data)\n\n    # Stage 3: Add items to resolver\n    self._resolver.add_items(items)\n\n    self._is_parsed = True\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._update_from_config","title":"<code>_update_from_config(source)</code>","text":"<p>Update from another Config instance.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _update_from_config(self, source: \"Config\") -&gt; None:\n    \"\"\"Update from another Config instance.\"\"\"\n    self._data = apply_operators(self._data, source._data)\n    self._metadata.merge(source._metadata)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._update_from_file","title":"<code>_update_from_file(source)</code>","text":"<p>Load and update from a file.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _update_from_file(self, source: PathLike) -&gt; None:\n    \"\"\"Load and update from a file.\"\"\"\n    new_data, new_metadata = self._loader.load_file(source)\n    validate_operators(new_data)\n    self._data = apply_operators(self._data, new_data)\n    self._metadata.merge(new_metadata)\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config._uses_nested_paths","title":"<code>_uses_nested_paths(source)</code>","text":"<p>Check if dict uses :: path syntax.</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def _uses_nested_paths(self, source: dict) -&gt; bool:\n    \"\"\"Check if dict uses :: path syntax.\"\"\"\n    return any(ID_SEP_KEY in str(k).lstrip(REPLACE_KEY).lstrip(REMOVE_KEY) for k in source.keys())\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.export_config_file","title":"<code>export_config_file(config, filepath, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Export config to YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Config dict to export</p> required <code>filepath</code> <code>PathLike</code> <p>Target file path</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments for yaml.safe_dump</p> <code>{}</code> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@staticmethod\ndef export_config_file(config: dict, filepath: PathLike, **kwargs: Any) -&gt; None:\n    \"\"\"Export config to YAML file.\n\n    Args:\n        config: Config dict to export\n        filepath: Target file path\n        kwargs: Additional arguments for yaml.safe_dump\n    \"\"\"\n    import yaml\n\n    filepath_str = str(Path(filepath))\n    with open(filepath_str, \"w\") as f:\n        yaml.safe_dump(config, f, **kwargs)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.from_cli","title":"<code>from_cli(source, cli_overrides, globals=None, schema=None)</code>  <code>classmethod</code>","text":"<p>Load configuration with CLI overrides applied.</p> <p>Convenience method for loading configs with command-line overrides. First loads the base config, then applies CLI overrides in the format \"key::path=value\", and optionally validates against a schema.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | Sequence[PathLike] | dict</code> <p>File path, list of paths, or config dict</p> required <code>cli_overrides</code> <code>list[str]</code> <p>List of override strings in format \"key::path=value\"</p> required <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions</p> <code>None</code> <code>schema</code> <code>type | None</code> <p>Optional dataclass schema for validation</p> <code>None</code> <p>Returns:</p> Type Description <code>Config</code> <p>New Config instance with CLI overrides applied</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load with CLI overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple files with overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     [\"base.yaml\", \"experiment.yaml\"],\n...     [\"model::lr=0.001\"]\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # With schema validation\n&gt;&gt;&gt; from dataclasses import dataclass\n&gt;&gt;&gt; @dataclass\n... class TrainingConfig:\n...     model: dict\n...     trainer: dict\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\"model::lr=0.001\"],\n...     schema=TrainingConfig\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; # Complex overrides\n&gt;&gt;&gt; config = Config.from_cli(\n...     \"config.yaml\",\n...     [\n...         \"model::lr=0.001\",\n...         \"trainer::devices=[0,1,2]\",\n...         \"model::layers=[128,256,512]\",\n...         \"debug=True\"\n...     ]\n... )\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@classmethod\ndef from_cli(\n    cls,\n    source: PathLike | Sequence[PathLike] | dict,\n    cli_overrides: list[str],\n    globals: dict[str, Any] | None = None,\n    schema: type | None = None,\n) -&gt; \"Config\":\n    \"\"\"Load configuration with CLI overrides applied.\n\n    Convenience method for loading configs with command-line overrides.\n    First loads the base config, then applies CLI overrides in the format\n    \"key::path=value\", and optionally validates against a schema.\n\n    Args:\n        source: File path, list of paths, or config dict\n        cli_overrides: List of override strings in format \"key::path=value\"\n        globals: Pre-imported packages for expressions\n        schema: Optional dataclass schema for validation\n\n    Returns:\n        New Config instance with CLI overrides applied\n\n    Examples:\n        &gt;&gt;&gt; # Load with CLI overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n        ... )\n\n        &gt;&gt;&gt; # Multiple files with overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     [\"base.yaml\", \"experiment.yaml\"],\n        ...     [\"model::lr=0.001\"]\n        ... )\n\n        &gt;&gt;&gt; # With schema validation\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class TrainingConfig:\n        ...     model: dict\n        ...     trainer: dict\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\"model::lr=0.001\"],\n        ...     schema=TrainingConfig\n        ... )\n\n        &gt;&gt;&gt; # Complex overrides\n        &gt;&gt;&gt; config = Config.from_cli(\n        ...     \"config.yaml\",\n        ...     [\n        ...         \"model::lr=0.001\",\n        ...         \"trainer::devices=[0,1,2]\",\n        ...         \"model::layers=[128,256,512]\",\n        ...         \"debug=True\"\n        ...     ]\n        ... )\n    \"\"\"\n    from .cli import parse_overrides\n\n    # Load base configuration\n    config = cls.load(source, globals=globals, schema=schema)\n\n    # Apply CLI overrides\n    if cli_overrides:\n        overrides = parse_overrides(cli_overrides)\n        for key, value in overrides.items():\n            config.set(key, value)\n\n        # Re-validate after overrides if schema provided\n        if schema is not None:\n            config.validate(schema)\n\n    return config\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.get","title":"<code>get(id='', default=None)</code>","text":"<p>Get raw config value (unresolved).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path (use :: for nesting, e.g., \"model::lr\") Empty string returns entire config</p> <code>''</code> <code>default</code> <code>Any</code> <p>Default value if id not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Raw configuration value (resolved references not resolved, raw references not expanded)</p> Example <p>config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}}) config.get(\"model::lr\") 0.001 config.get(\"model::ref\") \"@model::lr\"  # Unresolved resolved reference</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def get(self, id: str = \"\", default: Any = None) -&gt; Any:\n    \"\"\"Get raw config value (unresolved).\n\n    Args:\n        id: Configuration path (use :: for nesting, e.g., \"model::lr\")\n            Empty string returns entire config\n        default: Default value if id not found\n\n    Returns:\n        Raw configuration value (resolved references not resolved, raw references not expanded)\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001, \"ref\": \"@model::lr\"}})\n        &gt;&gt;&gt; config.get(\"model::lr\")\n        0.001\n        &gt;&gt;&gt; config.get(\"model::ref\")\n        \"@model::lr\"  # Unresolved resolved reference\n    \"\"\"\n    try:\n        return self._get_by_id(id)\n    except (KeyError, IndexError, ValueError):\n        return default\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.load","title":"<code>load(source, globals=None, schema=None)</code>  <code>classmethod</code>","text":"<p>Load configuration from file(s) or dict.</p> <p>Primary method for creating Config instances.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | Sequence[PathLike] | dict</code> <p>File path, list of paths, or config dict</p> required <code>globals</code> <code>dict[str, Any] | None</code> <p>Pre-imported packages for expressions</p> <code>None</code> <code>schema</code> <code>type | None</code> <p>Optional dataclass schema for validation</p> <code>None</code> <p>Returns:</p> Type Description <code>Config</code> <p>New Config instance</p> Merge Behavior <p>Files are merged in order (composition-by-default). Use operators to control merging: - key: value   - Compose (default): merge dict or extend list - =key: value  - Replace operator: completely replace value - ~key: null   - Remove operator: delete key (idempotent)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Single file\n&gt;&gt;&gt; config = Config.load(\"config.yaml\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Multiple files (merged)\n&gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n</code></pre> <pre><code>&gt;&gt;&gt; # From dict\n&gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n</code></pre> <pre><code>&gt;&gt;&gt; # With globals for expressions\n&gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n</code></pre> <pre><code>&gt;&gt;&gt; # With schema validation\n&gt;&gt;&gt; from dataclasses import dataclass\n&gt;&gt;&gt; @dataclass\n... class MySchema:\n...     name: str\n...     value: int\n&gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>@classmethod\ndef load(\n    cls,\n    source: PathLike | Sequence[PathLike] | dict,\n    globals: dict[str, Any] | None = None,\n    schema: type | None = None,\n) -&gt; \"Config\":\n    \"\"\"Load configuration from file(s) or dict.\n\n    Primary method for creating Config instances.\n\n    Args:\n        source: File path, list of paths, or config dict\n        globals: Pre-imported packages for expressions\n        schema: Optional dataclass schema for validation\n\n    Returns:\n        New Config instance\n\n    Merge Behavior:\n        Files are merged in order (composition-by-default). Use operators to control merging:\n        - key: value   - Compose (default): merge dict or extend list\n        - =key: value  - Replace operator: completely replace value\n        - ~key: null   - Remove operator: delete key (idempotent)\n\n    Examples:\n        &gt;&gt;&gt; # Single file\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\")\n\n        &gt;&gt;&gt; # Multiple files (merged)\n        &gt;&gt;&gt; config = Config.load([\"base.yaml\", \"override.yaml\"])\n\n        &gt;&gt;&gt; # From dict\n        &gt;&gt;&gt; config = Config.load({\"model\": {\"lr\": 0.001}})\n\n        &gt;&gt;&gt; # With globals for expressions\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\", globals={\"torch\": \"torch\"})\n\n        &gt;&gt;&gt; # With schema validation\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class MySchema:\n        ...     name: str\n        ...     value: int\n        &gt;&gt;&gt; config = Config.load(\"config.yaml\", schema=MySchema)\n    \"\"\"\n    config = cls(globals=globals)\n\n    # Handle dict input\n    if isinstance(source, dict):\n        config._data = source\n        if schema is not None:\n            config.validate(schema)\n        return config\n\n    # Handle file(s) input\n    file_list = ensure_tuple(source)\n    for filepath in file_list:\n        loaded_data, loaded_metadata = config._loader.load_file(filepath)\n        # Validate operators before applying\n        validate_operators(loaded_data)\n        # Merge data and metadata\n        config._data = apply_operators(config._data, loaded_data)\n        config._metadata.merge(loaded_metadata)\n\n    # Validate against schema if provided\n    if schema is not None:\n        config.validate(schema)\n\n    return config\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.resolve","title":"<code>resolve(id='', instantiate=True, eval_expr=True, lazy=True, default=None)</code>","text":"<p>Resolve resolved references (@) and return parsed config.</p> <p>Automatically parses config on first call. Resolves @ resolved references (follows them to get instantiated/evaluated values), evaluates $ expressions, and instantiates target components. Note: % raw references are expanded during preprocessing (before this stage).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Config path to resolve (empty string for entire config)</p> <code>''</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components with target</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate $ expressions</p> <code>True</code> <code>lazy</code> <code>bool</code> <p>Whether to use cached resolution</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if id not found (returns default.get_config() if Item)</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value (instantiated objects, evaluated expressions, etc.)</p> Example <p>config = Config.load({ ...     \"lr\": 0.001, ...     \"doubled\": \"$@lr * 2\", ...     \"optimizer\": { ...         \"target\": \"torch.optim.Adam\", ...         \"lr\": \"@lr\" ...     } ... }) config.resolve(\"lr\") 0.001 config.resolve(\"doubled\") 0.002 optimizer = config.resolve(\"optimizer\") type(optimizer).name 'Adam'</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def resolve(\n    self,\n    id: str = \"\",\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    lazy: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Resolve resolved references (@) and return parsed config.\n\n    Automatically parses config on first call. Resolves @ resolved references (follows\n    them to get instantiated/evaluated values), evaluates $ expressions, and\n    instantiates _target_ components. Note: % raw references are expanded during\n    preprocessing (before this stage).\n\n    Args:\n        id: Config path to resolve (empty string for entire config)\n        instantiate: Whether to instantiate components with _target_\n        eval_expr: Whether to evaluate $ expressions\n        lazy: Whether to use cached resolution\n        default: Default value if id not found (returns default.get_config() if Item)\n\n    Returns:\n        Resolved value (instantiated objects, evaluated expressions, etc.)\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({\n        ...     \"lr\": 0.001,\n        ...     \"doubled\": \"$@lr * 2\",\n        ...     \"optimizer\": {\n        ...         \"_target_\": \"torch.optim.Adam\",\n        ...         \"lr\": \"@lr\"\n        ...     }\n        ... })\n        &gt;&gt;&gt; config.resolve(\"lr\")\n        0.001\n        &gt;&gt;&gt; config.resolve(\"doubled\")\n        0.002\n        &gt;&gt;&gt; optimizer = config.resolve(\"optimizer\")\n        &gt;&gt;&gt; type(optimizer).__name__\n        'Adam'\n    \"\"\"\n    # Parse if needed\n    if not self._is_parsed or not lazy:\n        self._parse()\n\n    # Resolve and return\n    try:\n        return self._resolver.resolve(id=id, instantiate=instantiate, eval_expr=eval_expr)\n    except (KeyError, ConfigKeyError):\n        if default is not None:\n            # If default is an Item, return its config\n            from .items import Item\n\n            if isinstance(default, Item):\n                return default.get_config()\n            return default\n        raise\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.set","title":"<code>set(id, value)</code>","text":"<p>Set config value, creating paths as needed.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Configuration path (use :: for nesting)</p> required <code>value</code> <code>Any</code> <p>Value to set</p> required Example <p>config = Config.load({}) config.set(\"model::lr\", 0.001) config.get(\"model::lr\") 0.001</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def set(self, id: str, value: Any) -&gt; None:\n    \"\"\"Set config value, creating paths as needed.\n\n    Args:\n        id: Configuration path (use :: for nesting)\n        value: Value to set\n\n    Example:\n        &gt;&gt;&gt; config = Config.load({})\n        &gt;&gt;&gt; config.set(\"model::lr\", 0.001)\n        &gt;&gt;&gt; config.get(\"model::lr\")\n        0.001\n    \"\"\"\n    if id == \"\":\n        self._data = value\n        self._invalidate_resolution()\n        return\n\n    keys = split_id(id)\n\n    # Ensure root is dict\n    if not isinstance(self._data, dict):\n        self._data = {}\n\n    # Create missing intermediate paths\n    current = self._data\n    for k in keys[:-1]:\n        if k not in current:\n            current[k] = {}\n        elif not isinstance(current[k], dict):\n            current[k] = {}\n        current = current[k]\n\n    # Set final value\n    current[keys[-1]] = value\n    self._invalidate_resolution()\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.update","title":"<code>update(source)</code>","text":"<p>Update configuration with changes from another source.</p> <p>Applies changes using operators for fine-grained control. Supports nested paths (::) and compose/replace/delete operators.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>PathLike | dict | Config</code> <p>File path, dict, or Config instance to update from</p> required Operators <ul> <li>key: value   - Compose (default): merge dict or extend list</li> <li>=key: value  - Replace operator: completely replace value</li> <li>~key: null   - Remove operator: delete key (idempotent)</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Update from file\n&gt;&gt;&gt; config.update(\"override.yaml\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Update from dict (merges by default)\n&gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n</code></pre> <pre><code>&gt;&gt;&gt; # Update from another Config instance\n&gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n&gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n&gt;&gt;&gt; config1.update(config2)\n</code></pre> <pre><code>&gt;&gt;&gt; # Nested path updates\n&gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n</code></pre> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def update(self, source: PathLike | dict | \"Config\") -&gt; None:\n    \"\"\"Update configuration with changes from another source.\n\n    Applies changes using operators for fine-grained control.\n    Supports nested paths (::) and compose/replace/delete operators.\n\n    Args:\n        source: File path, dict, or Config instance to update from\n\n    Operators:\n        - key: value   - Compose (default): merge dict or extend list\n        - =key: value  - Replace operator: completely replace value\n        - ~key: null   - Remove operator: delete key (idempotent)\n\n    Examples:\n        &gt;&gt;&gt; # Update from file\n        &gt;&gt;&gt; config.update(\"override.yaml\")\n\n        &gt;&gt;&gt; # Update from dict (merges by default)\n        &gt;&gt;&gt; config.update({\"model\": {\"dropout\": 0.1}})\n\n        &gt;&gt;&gt; # Update from another Config instance\n        &gt;&gt;&gt; config1 = Config.load(\"base.yaml\")\n        &gt;&gt;&gt; config2 = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\n        &gt;&gt;&gt; config1.update(config2)\n\n        &gt;&gt;&gt; # Nested path updates\n        &gt;&gt;&gt; config.update({\"model::lr\": 0.001, \"~old_param\": None})\n    \"\"\"\n    if isinstance(source, Config):\n        self._update_from_config(source)\n    elif isinstance(source, dict):\n        if self._uses_nested_paths(source):\n            self._apply_path_updates(source)\n        else:\n            self._apply_structural_update(source)\n    else:\n        self._update_from_file(source)\n</code></pre>"},{"location":"reference/config/#sparkwheel.config.Config.validate","title":"<code>validate(schema)</code>","text":"<p>Validate configuration against a dataclass schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>type</code> <p>Dataclass type defining the expected structure and types</p> required <p>Raises:</p> Type Description <code>ValidationError</code> <p>If configuration doesn't match schema</p> <code>TypeError</code> <p>If schema is not a dataclass</p> Example <p>from dataclasses import dataclass @dataclass ... class ModelConfig: ...     hidden_size: int ...     dropout: float config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1}) config.validate(ModelConfig)  # Passes bad_config = Config.load({\"hidden_size\": \"not an int\"}) bad_config.validate(ModelConfig)  # Raises ValidationError</p> Source code in <code>src/sparkwheel/config.py</code> <pre><code>def validate(self, schema: type) -&gt; None:\n    \"\"\"Validate configuration against a dataclass schema.\n\n    Args:\n        schema: Dataclass type defining the expected structure and types\n\n    Raises:\n        ValidationError: If configuration doesn't match schema\n        TypeError: If schema is not a dataclass\n\n    Example:\n        &gt;&gt;&gt; from dataclasses import dataclass\n        &gt;&gt;&gt; @dataclass\n        ... class ModelConfig:\n        ...     hidden_size: int\n        ...     dropout: float\n        &gt;&gt;&gt; config = Config.load({\"hidden_size\": 512, \"dropout\": 0.1})\n        &gt;&gt;&gt; config.validate(ModelConfig)  # Passes\n        &gt;&gt;&gt; bad_config = Config.load({\"hidden_size\": \"not an int\"})\n        &gt;&gt;&gt; bad_config.validate(ModelConfig)  # Raises ValidationError\n    \"\"\"\n    from .schema import validate as validate_schema\n\n    validate_schema(self._data, schema, metadata=self._metadata)\n</code></pre>"},{"location":"reference/items/","title":"items","text":""},{"location":"reference/items/#sparkwheel.items.Component","title":"<code>Component</code>","text":"<p>               Bases: <code>Item</code>, <code>Instantiable</code></p> <p>Component that can be instantiated from configuration.</p> <p>Uses a dictionary with string keys to represent a Python class or function that can be dynamically instantiated. Other keys are passed as arguments to the target component.</p> Example <pre><code>from sparkwheel import Component\nfrom collections import Counter\n\nconfig = {\n    \"_target_\": \"collections.Counter\",\n    \"iterable\": [1, 2, 2, 3, 3, 3]\n}\n\ncomponent = Component(config, id=\"counter\")\ncounter = component.instantiate()\nprint(counter)  # Counter({3: 3, 2: 2, 1: 1})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Configuration content</p> required <code>id</code> <code>str</code> <p>Identifier for this config item, defaults to \"\"</p> <code>''</code> Note <p>Special configuration keys:</p> <ul> <li><code>_target_</code>: Full module path (e.g., \"collections.Counter\")</li> <li><code>_requires_</code>: Dependencies to evaluate/instantiate first</li> <li><code>_disabled_</code>: Skip instantiation if True</li> <li><code>_mode_</code>: Instantiation mode:<ul> <li><code>\"default\"</code>: Returns component(**kwargs)</li> <li><code>\"callable\"</code>: Returns functools.partial(component, **kwargs)</li> <li><code>\"debug\"</code>: Returns pdb.runcall(component, **kwargs)</li> </ul> </li> </ul> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Component(Item, Instantiable):\n    \"\"\"Component that can be instantiated from configuration.\n\n    Uses a dictionary with string keys to represent a Python class or function\n    that can be dynamically instantiated. Other keys are passed as arguments\n    to the target component.\n\n    Example:\n        ```python\n        from sparkwheel import Component\n        from collections import Counter\n\n        config = {\n            \"_target_\": \"collections.Counter\",\n            \"iterable\": [1, 2, 2, 3, 3, 3]\n        }\n\n        component = Component(config, id=\"counter\")\n        counter = component.instantiate()\n        print(counter)  # Counter({3: 3, 2: 2, 1: 1})\n        ```\n\n    Args:\n        config: Configuration content\n        id: Identifier for this config item, defaults to \"\"\n\n    Note:\n        Special configuration keys:\n\n        - `_target_`: Full module path (e.g., \"collections.Counter\")\n        - `_requires_`: Dependencies to evaluate/instantiate first\n        - `_disabled_`: Skip instantiation if True\n        - `_mode_`: Instantiation mode:\n            - `\"default\"`: Returns component(**kwargs)\n            - `\"callable\"`: Returns functools.partial(component, **kwargs)\n            - `\"debug\"`: Returns pdb.runcall(component, **kwargs)\n    \"\"\"\n\n    non_arg_keys = {\"_target_\", \"_disabled_\", \"_requires_\", \"_mode_\"}\n\n    def __init__(self, config: Any, id: str = \"\", source_location: SourceLocation | None = None) -&gt; None:\n        super().__init__(config=config, id=id, source_location=source_location)\n\n    @staticmethod\n    def is_instantiable(config: Any) -&gt; bool:\n        \"\"\"\n        Check whether this config represents a `class` or `function` that is to be instantiated.\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        return isinstance(config, Mapping) and \"_target_\" in config\n\n    def resolve_module_name(self):\n        \"\"\"Resolve the target module name from configuration.\n\n        Requires full module path (e.g., \"collections.Counter\").\n        No automatic module discovery is performed.\n\n        Returns:\n            str or callable: The module path or callable from _target_\n        \"\"\"\n        config = dict(self.get_config())\n        target = config.get(\"_target_\")\n        if not isinstance(target, str):\n            return target  # for cases where _target_ is already a callable\n\n        # No ComponentLocator - just return the target as-is (must be full path)\n        return target\n\n    def resolve_args(self):\n        \"\"\"\n        Utility function used in `instantiate()` to resolve the arguments from current config content.\n        \"\"\"\n        config = self.get_config()\n        if not isinstance(config, Mapping):\n            raise TypeError(\n                f\"Expected config to be a Mapping (dict-like), but got {type(config).__name__}. \"\n                f\"Cannot resolve arguments from non-mapping config.\"\n            )\n        return {k: v for k, v in config.items() if k not in self.non_arg_keys}\n\n    def is_disabled(self) -&gt; bool:\n        \"\"\"\n        Utility function used in `instantiate()` to check whether to skip the instantiation.\n        \"\"\"\n        _is_disabled = self.get_config().get(\"_disabled_\", False)\n        return _is_disabled.lower().strip() == \"true\" if isinstance(_is_disabled, str) else bool(_is_disabled)\n\n    def instantiate(self, **kwargs: Any) -&gt; object:\n        \"\"\"\n        Instantiate component based on ``self.config`` content.\n        The target component must be a `class` or a `function`, otherwise, return `None`.\n\n        Args:\n            kwargs: args to override / add the config args when instantiation.\n        \"\"\"\n        if not self.is_instantiable(self.get_config()) or self.is_disabled():\n            # if not a class or function or marked as `disabled`, skip parsing and return `None`\n            return None\n\n        modname = self.resolve_module_name()\n        mode = self.get_config().get(\"_mode_\", CompInitMode.DEFAULT)\n        args = self.resolve_args()\n        args.update(kwargs)\n\n        try:\n            return instantiate(modname, mode, **args)\n        except ModuleNotFoundError as e:\n            # Re-raise with source location and suggestions\n            suggestion = self._suggest_similar_modules(modname) if isinstance(modname, str) else None\n            raise ModuleNotFoundError(\n                f\"Cannot locate class or function: '{modname}'\",\n                source_location=self.source_location,\n                suggestion=suggestion,\n            ) from e\n        except Exception as e:\n            # Wrap other errors with location context (points to _target_ line)\n            raise InstantiationError(\n                f\"Failed to instantiate '{modname}': {type(e).__name__}: {e}\",\n                source_location=self.source_location,\n            ) from e\n\n    def _suggest_similar_modules(self, target: str) -&gt; str | None:\n        \"\"\"Suggest similar valid module names using fuzzy matching.\n\n        Args:\n            target: The module path that couldn't be found (e.g., 'torch.optim.Adamfad')\n\n        Returns:\n            A helpful suggestion string, or None if no good suggestions found.\n        \"\"\"\n        if not isinstance(target, str) or \".\" not in target:\n            return None\n\n        try:\n            from pydoc import locate\n\n            from .utils import damerau_levenshtein_distance\n\n            # Split into module path and attribute name\n            parts = target.rsplit(\".\", 1)\n            base_module, attr_name = parts[0], parts[1]\n\n            # Try to import the base module\n            base = locate(base_module)\n            if base is None:\n                return None\n\n            # Find similar attribute names in the module\n            similar = []\n            for name in dir(base):\n                if name.startswith(\"_\"):\n                    continue\n                distance = damerau_levenshtein_distance(name, attr_name)\n                if distance &lt;= 2:  # Allow up to 2 character edits\n                    similar.append((distance, name))\n\n            if similar:\n                # Sort by distance and return the closest match\n                similar.sort(key=lambda x: x[0])\n                closest = similar[0][1]\n                return f\"Did you mean '{base_module}.{closest}'?\"\n        except Exception:\n            # If anything fails during suggestion generation, just skip it\n            pass\n\n        return None\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component._suggest_similar_modules","title":"<code>_suggest_similar_modules(target)</code>","text":"<p>Suggest similar valid module names using fuzzy matching.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>The module path that couldn't be found (e.g., 'torch.optim.Adamfad')</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>A helpful suggestion string, or None if no good suggestions found.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def _suggest_similar_modules(self, target: str) -&gt; str | None:\n    \"\"\"Suggest similar valid module names using fuzzy matching.\n\n    Args:\n        target: The module path that couldn't be found (e.g., 'torch.optim.Adamfad')\n\n    Returns:\n        A helpful suggestion string, or None if no good suggestions found.\n    \"\"\"\n    if not isinstance(target, str) or \".\" not in target:\n        return None\n\n    try:\n        from pydoc import locate\n\n        from .utils import damerau_levenshtein_distance\n\n        # Split into module path and attribute name\n        parts = target.rsplit(\".\", 1)\n        base_module, attr_name = parts[0], parts[1]\n\n        # Try to import the base module\n        base = locate(base_module)\n        if base is None:\n            return None\n\n        # Find similar attribute names in the module\n        similar = []\n        for name in dir(base):\n            if name.startswith(\"_\"):\n                continue\n            distance = damerau_levenshtein_distance(name, attr_name)\n            if distance &lt;= 2:  # Allow up to 2 character edits\n                similar.append((distance, name))\n\n        if similar:\n            # Sort by distance and return the closest match\n            similar.sort(key=lambda x: x[0])\n            closest = similar[0][1]\n            return f\"Did you mean '{base_module}.{closest}'?\"\n    except Exception:\n        # If anything fails during suggestion generation, just skip it\n        pass\n\n    return None\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component.instantiate","title":"<code>instantiate(**kwargs)</code>","text":"<p>Instantiate component based on <code>self.config</code> content. The target component must be a <code>class</code> or a <code>function</code>, otherwise, return <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Any</code> <p>args to override / add the config args when instantiation.</p> <code>{}</code> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def instantiate(self, **kwargs: Any) -&gt; object:\n    \"\"\"\n    Instantiate component based on ``self.config`` content.\n    The target component must be a `class` or a `function`, otherwise, return `None`.\n\n    Args:\n        kwargs: args to override / add the config args when instantiation.\n    \"\"\"\n    if not self.is_instantiable(self.get_config()) or self.is_disabled():\n        # if not a class or function or marked as `disabled`, skip parsing and return `None`\n        return None\n\n    modname = self.resolve_module_name()\n    mode = self.get_config().get(\"_mode_\", CompInitMode.DEFAULT)\n    args = self.resolve_args()\n    args.update(kwargs)\n\n    try:\n        return instantiate(modname, mode, **args)\n    except ModuleNotFoundError as e:\n        # Re-raise with source location and suggestions\n        suggestion = self._suggest_similar_modules(modname) if isinstance(modname, str) else None\n        raise ModuleNotFoundError(\n            f\"Cannot locate class or function: '{modname}'\",\n            source_location=self.source_location,\n            suggestion=suggestion,\n        ) from e\n    except Exception as e:\n        # Wrap other errors with location context (points to _target_ line)\n        raise InstantiationError(\n            f\"Failed to instantiate '{modname}': {type(e).__name__}: {e}\",\n            source_location=self.source_location,\n        ) from e\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component.is_disabled","title":"<code>is_disabled()</code>","text":"<p>Utility function used in <code>instantiate()</code> to check whether to skip the instantiation.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def is_disabled(self) -&gt; bool:\n    \"\"\"\n    Utility function used in `instantiate()` to check whether to skip the instantiation.\n    \"\"\"\n    _is_disabled = self.get_config().get(\"_disabled_\", False)\n    return _is_disabled.lower().strip() == \"true\" if isinstance(_is_disabled, str) else bool(_is_disabled)\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component.is_instantiable","title":"<code>is_instantiable(config)</code>  <code>staticmethod</code>","text":"<p>Check whether this config represents a <code>class</code> or <code>function</code> that is to be instantiated.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@staticmethod\ndef is_instantiable(config: Any) -&gt; bool:\n    \"\"\"\n    Check whether this config represents a `class` or `function` that is to be instantiated.\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    return isinstance(config, Mapping) and \"_target_\" in config\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component.resolve_args","title":"<code>resolve_args()</code>","text":"<p>Utility function used in <code>instantiate()</code> to resolve the arguments from current config content.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def resolve_args(self):\n    \"\"\"\n    Utility function used in `instantiate()` to resolve the arguments from current config content.\n    \"\"\"\n    config = self.get_config()\n    if not isinstance(config, Mapping):\n        raise TypeError(\n            f\"Expected config to be a Mapping (dict-like), but got {type(config).__name__}. \"\n            f\"Cannot resolve arguments from non-mapping config.\"\n        )\n    return {k: v for k, v in config.items() if k not in self.non_arg_keys}\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Component.resolve_module_name","title":"<code>resolve_module_name()</code>","text":"<p>Resolve the target module name from configuration.</p> <p>Requires full module path (e.g., \"collections.Counter\"). No automatic module discovery is performed.</p> <p>Returns:</p> Type Description <p>str or callable: The module path or callable from target</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def resolve_module_name(self):\n    \"\"\"Resolve the target module name from configuration.\n\n    Requires full module path (e.g., \"collections.Counter\").\n    No automatic module discovery is performed.\n\n    Returns:\n        str or callable: The module path or callable from _target_\n    \"\"\"\n    config = dict(self.get_config())\n    target = config.get(\"_target_\")\n    if not isinstance(target, str):\n        return target  # for cases where _target_ is already a callable\n\n    # No ComponentLocator - just return the target as-is (must be full path)\n    return target\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Expression","title":"<code>Expression</code>","text":"<p>               Bases: <code>Item</code></p> <p>Executable expression that evaluates Python code.</p> <p>Expressions start with <code>$</code> and are evaluated using Python's <code>eval()</code>, or imported if they're import statements.</p> Example <pre><code>from sparkwheel import Expression\n\nconfig = \"$len([1, 2, 3])\"\nexpression = Expression(config, id=\"test\", globals={\"len\": len})\nprint(expression.evaluate())  # 3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Expression string starting with <code>$</code></p> required <code>id</code> <code>str</code> <p>Identifier for this config item, defaults to \"\"</p> <code>''</code> <code>globals</code> <code>dict | None</code> <p>Additional global context for evaluation</p> <code>None</code> See Also <p>Python eval documentation</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Expression(Item):\n    \"\"\"Executable expression that evaluates Python code.\n\n    Expressions start with `$` and are evaluated using Python's `eval()`,\n    or imported if they're import statements.\n\n    Example:\n        ```python\n        from sparkwheel import Expression\n\n        config = \"$len([1, 2, 3])\"\n        expression = Expression(config, id=\"test\", globals={\"len\": len})\n        print(expression.evaluate())  # 3\n        ```\n\n    Args:\n        config: Expression string starting with `$`\n        id: Identifier for this config item, defaults to \"\"\n        globals: Additional global context for evaluation\n\n    See Also:\n        [Python eval documentation](https://docs.python.org/3/library/functions.html#eval)\n    \"\"\"\n\n    prefix = EXPR_KEY\n    run_eval = run_eval\n\n    def __init__(\n        self,\n        config: Any,\n        id: str = \"\",\n        globals: dict | None = None,\n        source_location: SourceLocation | None = None,\n    ) -&gt; None:\n        super().__init__(config=config, id=id, source_location=source_location)\n        self.globals = globals if globals is not None else {}\n\n    def _parse_import_string(self, import_string: str) -&gt; Any | None:\n        \"\"\"parse single import statement such as \"from pathlib import Path\" \"\"\"\n        node = first(ast.iter_child_nodes(ast.parse(import_string)))\n        if not isinstance(node, (ast.Import, ast.ImportFrom)):\n            return None\n        if len(node.names) &lt; 1:\n            return None\n        if len(node.names) &gt; 1:\n            warnings.warn(f\"ignoring multiple import alias '{import_string}'.\", stacklevel=2)\n        name, asname = f\"{node.names[0].name}\", node.names[0].asname\n        asname = name if asname is None else f\"{asname}\"\n        if isinstance(node, ast.ImportFrom):\n            self.globals[asname], _ = optional_import(f\"{node.module}\", name=f\"{name}\")\n            return self.globals[asname]\n        if isinstance(node, ast.Import):\n            self.globals[asname], _ = optional_import(f\"{name}\")\n            return self.globals[asname]\n        return None\n\n    def evaluate(self, globals: dict | None = None, locals: dict | None = None) -&gt; str | Any | None:\n        \"\"\"Evaluate the expression and return the result.\n\n        Uses Python's `eval()` to execute the expression string.\n\n        Args:\n            globals: Additional global symbols for evaluation\n            locals: Additional local symbols for evaluation\n\n        Returns:\n            Evaluation result, or None if not an expression\n\n        Raises:\n            RuntimeError: If evaluation fails\n        \"\"\"\n        value = self.get_config()\n        if not Expression.is_expression(value):\n            return None\n        optional_module = self._parse_import_string(value[len(self.prefix) :])\n        if optional_module is not None:\n            return optional_module\n        if not self.run_eval:\n            return f\"{value[len(self.prefix) :]}\"\n        globals_ = dict(self.globals)\n        if globals is not None:\n            for k, v in globals.items():\n                if k in globals_:\n                    warnings.warn(f\"the new global variable `{k}` conflicts with `self.globals`, override it.\", stacklevel=2)\n                globals_[k] = v\n        if not run_debug:\n            try:\n                return eval(value[len(self.prefix) :], globals_, locals)\n            except Exception as e:\n                raise EvaluationError(\n                    f\"Failed to evaluate expression: '{value[len(self.prefix) :]}'\",\n                    source_location=self.source_location,\n                ) from e\n        warnings.warn(\n            f\"\\n\\npdb: value={value}\\nSee also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n            stacklevel=2,\n        )\n        import pdb  # noqa: T100\n\n        pdb.run(value[len(self.prefix) :], globals_, locals)\n        return None\n\n    @classmethod\n    def is_expression(cls, config: dict | list | str) -&gt; bool:\n        \"\"\"\n        Check whether the config is an executable expression string.\n        Currently, a string starts with ``\"$\"`` character is interpreted as an expression.\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        return isinstance(config, str) and config.startswith(cls.prefix)\n\n    @classmethod\n    def is_import_statement(cls, config: dict | list | str) -&gt; bool:\n        \"\"\"\n        Check whether the config is an import statement (a special case of expression).\n\n        Args:\n            config: input config content to check.\n        \"\"\"\n        if not cls.is_expression(config):\n            return False\n        if \"import\" not in config:\n            return False\n        return isinstance(first(ast.iter_child_nodes(ast.parse(f\"{config[len(cls.prefix) :]}\"))), (ast.Import, ast.ImportFrom))\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Expression._parse_import_string","title":"<code>_parse_import_string(import_string)</code>","text":"<p>parse single import statement such as \"from pathlib import Path\"</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def _parse_import_string(self, import_string: str) -&gt; Any | None:\n    \"\"\"parse single import statement such as \"from pathlib import Path\" \"\"\"\n    node = first(ast.iter_child_nodes(ast.parse(import_string)))\n    if not isinstance(node, (ast.Import, ast.ImportFrom)):\n        return None\n    if len(node.names) &lt; 1:\n        return None\n    if len(node.names) &gt; 1:\n        warnings.warn(f\"ignoring multiple import alias '{import_string}'.\", stacklevel=2)\n    name, asname = f\"{node.names[0].name}\", node.names[0].asname\n    asname = name if asname is None else f\"{asname}\"\n    if isinstance(node, ast.ImportFrom):\n        self.globals[asname], _ = optional_import(f\"{node.module}\", name=f\"{name}\")\n        return self.globals[asname]\n    if isinstance(node, ast.Import):\n        self.globals[asname], _ = optional_import(f\"{name}\")\n        return self.globals[asname]\n    return None\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Expression.evaluate","title":"<code>evaluate(globals=None, locals=None)</code>","text":"<p>Evaluate the expression and return the result.</p> <p>Uses Python's <code>eval()</code> to execute the expression string.</p> <p>Parameters:</p> Name Type Description Default <code>globals</code> <code>dict | None</code> <p>Additional global symbols for evaluation</p> <code>None</code> <code>locals</code> <code>dict | None</code> <p>Additional local symbols for evaluation</p> <code>None</code> <p>Returns:</p> Type Description <code>str | Any | None</code> <p>Evaluation result, or None if not an expression</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If evaluation fails</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def evaluate(self, globals: dict | None = None, locals: dict | None = None) -&gt; str | Any | None:\n    \"\"\"Evaluate the expression and return the result.\n\n    Uses Python's `eval()` to execute the expression string.\n\n    Args:\n        globals: Additional global symbols for evaluation\n        locals: Additional local symbols for evaluation\n\n    Returns:\n        Evaluation result, or None if not an expression\n\n    Raises:\n        RuntimeError: If evaluation fails\n    \"\"\"\n    value = self.get_config()\n    if not Expression.is_expression(value):\n        return None\n    optional_module = self._parse_import_string(value[len(self.prefix) :])\n    if optional_module is not None:\n        return optional_module\n    if not self.run_eval:\n        return f\"{value[len(self.prefix) :]}\"\n    globals_ = dict(self.globals)\n    if globals is not None:\n        for k, v in globals.items():\n            if k in globals_:\n                warnings.warn(f\"the new global variable `{k}` conflicts with `self.globals`, override it.\", stacklevel=2)\n            globals_[k] = v\n    if not run_debug:\n        try:\n            return eval(value[len(self.prefix) :], globals_, locals)\n        except Exception as e:\n            raise EvaluationError(\n                f\"Failed to evaluate expression: '{value[len(self.prefix) :]}'\",\n                source_location=self.source_location,\n            ) from e\n    warnings.warn(\n        f\"\\n\\npdb: value={value}\\nSee also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n        stacklevel=2,\n    )\n    import pdb  # noqa: T100\n\n    pdb.run(value[len(self.prefix) :], globals_, locals)\n    return None\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Expression.is_expression","title":"<code>is_expression(config)</code>  <code>classmethod</code>","text":"<p>Check whether the config is an executable expression string. Currently, a string starts with <code>\"$\"</code> character is interpreted as an expression.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | list | str</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@classmethod\ndef is_expression(cls, config: dict | list | str) -&gt; bool:\n    \"\"\"\n    Check whether the config is an executable expression string.\n    Currently, a string starts with ``\"$\"`` character is interpreted as an expression.\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    return isinstance(config, str) and config.startswith(cls.prefix)\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Expression.is_import_statement","title":"<code>is_import_statement(config)</code>  <code>classmethod</code>","text":"<p>Check whether the config is an import statement (a special case of expression).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | list | str</code> <p>input config content to check.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>@classmethod\ndef is_import_statement(cls, config: dict | list | str) -&gt; bool:\n    \"\"\"\n    Check whether the config is an import statement (a special case of expression).\n\n    Args:\n        config: input config content to check.\n    \"\"\"\n    if not cls.is_expression(config):\n        return False\n    if \"import\" not in config:\n        return False\n    return isinstance(first(ast.iter_child_nodes(ast.parse(f\"{config[len(cls.prefix) :]}\"))), (ast.Import, ast.ImportFrom))\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Instantiable","title":"<code>Instantiable</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for an instantiable object.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Instantiable(ABC):\n    \"\"\"\n    Base class for an instantiable object.\n    \"\"\"\n\n    @abstractmethod\n    def is_disabled(self, *args: Any, **kwargs: Any) -&gt; bool:\n        \"\"\"\n        Return a boolean flag to indicate whether the object should be instantiated.\n        \"\"\"\n        raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n\n    @abstractmethod\n    def instantiate(self, *args: Any, **kwargs: Any) -&gt; object:\n        \"\"\"\n        Instantiate the target component and return the instance.\n        \"\"\"\n        raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Instantiable.instantiate","title":"<code>instantiate(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Instantiate the target component and return the instance.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>@abstractmethod\ndef instantiate(self, *args: Any, **kwargs: Any) -&gt; object:\n    \"\"\"\n    Instantiate the target component and return the instance.\n    \"\"\"\n    raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Instantiable.is_disabled","title":"<code>is_disabled(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return a boolean flag to indicate whether the object should be instantiated.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>@abstractmethod\ndef is_disabled(self, *args: Any, **kwargs: Any) -&gt; bool:\n    \"\"\"\n    Return a boolean flag to indicate whether the object should be instantiated.\n    \"\"\"\n    raise NotImplementedError(f\"subclass {self.__class__.__name__} must implement this method.\")\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Item","title":"<code>Item</code>","text":"<p>Basic data structure to represent a configuration item.</p> <p>A <code>Item</code> instance can optionally have a string id, so that other items can refer to it. It has a build-in <code>config</code> property to store the configuration object.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>content of a config item, can be objects of any types, a configuration resolver may interpret the content to generate a configuration object.</p> required <code>id</code> <code>str</code> <p>name of the current config item, defaults to empty string.</p> <code>''</code> <code>source_location</code> <code>SourceLocation | None</code> <p>optional location in source file where this config item was defined.</p> <code>None</code> Source code in <code>src/sparkwheel/items.py</code> <pre><code>class Item:\n    \"\"\"\n    Basic data structure to represent a configuration item.\n\n    A `Item` instance can optionally have a string id, so that other items can refer to it.\n    It has a build-in `config` property to store the configuration object.\n\n    Args:\n        config: content of a config item, can be objects of any types,\n            a configuration resolver may interpret the content to generate a configuration object.\n        id: name of the current config item, defaults to empty string.\n        source_location: optional location in source file where this config item was defined.\n    \"\"\"\n\n    def __init__(self, config: Any, id: str = \"\", source_location: SourceLocation | None = None) -&gt; None:\n        self.config = config\n        self.id = id\n        self.source_location = source_location\n\n    def get_id(self) -&gt; str:\n        \"\"\"\n        Get the ID name of current config item, useful to identify config items during parsing.\n        \"\"\"\n        return self.id\n\n    def update_config(self, config: Any) -&gt; None:\n        \"\"\"\n        Replace the content of `self.config` with new `config`.\n        A typical usage is to modify the initial config content at runtime.\n\n        Args:\n            config: content of a `Item`.\n        \"\"\"\n        self.config = config\n\n    def get_config(self):\n        \"\"\"\n        Get the config content of current config item.\n        \"\"\"\n        return self.config\n\n    def __repr__(self) -&gt; str:\n        return f\"{type(self).__name__}: \\n{pformat(self.config)}\"\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Item.get_config","title":"<code>get_config()</code>","text":"<p>Get the config content of current config item.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def get_config(self):\n    \"\"\"\n    Get the config content of current config item.\n    \"\"\"\n    return self.config\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Item.get_id","title":"<code>get_id()</code>","text":"<p>Get the ID name of current config item, useful to identify config items during parsing.</p> Source code in <code>src/sparkwheel/items.py</code> <pre><code>def get_id(self) -&gt; str:\n    \"\"\"\n    Get the ID name of current config item, useful to identify config items during parsing.\n    \"\"\"\n    return self.id\n</code></pre>"},{"location":"reference/items/#sparkwheel.items.Item.update_config","title":"<code>update_config(config)</code>","text":"<p>Replace the content of <code>self.config</code> with new <code>config</code>. A typical usage is to modify the initial config content at runtime.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>content of a <code>Item</code>.</p> required Source code in <code>src/sparkwheel/items.py</code> <pre><code>def update_config(self, config: Any) -&gt; None:\n    \"\"\"\n    Replace the content of `self.config` with new `config`.\n    A typical usage is to modify the initial config content at runtime.\n\n    Args:\n        config: content of a `Item`.\n    \"\"\"\n    self.config = config\n</code></pre>"},{"location":"reference/loader/","title":"loader","text":"<p>YAML configuration loading with source location tracking.</p>"},{"location":"reference/loader/#sparkwheel.loader.Loader","title":"<code>Loader</code>","text":"<p>Load YAML configuration files with source location tracking.</p> <p>Handles loading YAML files and tracking where each config item came from, without polluting the config dictionaries with metadata keys.</p> Example <pre><code>loader = Loader()\nconfig, metadata = loader.load_file(\"config.yaml\")\n\n# config is clean dict with no metadata pollution\nprint(config[\"model\"][\"lr\"])  # 0.001\n\n# metadata tracked separately\nlocation = metadata.get(\"model::lr\")\nprint(f\"Defined at {location.filepath}:{location.line}\")\n</code></pre> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>class Loader:\n    \"\"\"Load YAML configuration files with source location tracking.\n\n    Handles loading YAML files and tracking where each config item came from,\n    without polluting the config dictionaries with metadata keys.\n\n    Example:\n        ```python\n        loader = Loader()\n        config, metadata = loader.load_file(\"config.yaml\")\n\n        # config is clean dict with no metadata pollution\n        print(config[\"model\"][\"lr\"])  # 0.001\n\n        # metadata tracked separately\n        location = metadata.get(\"model::lr\")\n        print(f\"Defined at {location.filepath}:{location.line}\")\n        ```\n    \"\"\"\n\n    def load_file(self, filepath: PathLike) -&gt; tuple[dict, MetadataRegistry]:\n        \"\"\"Load a single YAML file with metadata tracking.\n\n        Args:\n            filepath: Path to YAML file\n\n        Returns:\n            Tuple of (config_dict, metadata_registry)\n\n        Raises:\n            ValueError: If file is not a YAML file\n        \"\"\"\n        if not filepath:\n            return {}, MetadataRegistry()\n\n        filepath_str = str(Path(filepath))\n\n        # Validate YAML extension\n        if not is_yaml_file(filepath_str):\n            raise ValueError(f'Unknown file input: \"{filepath}\", must be a YAML file (.yaml or .yml)')\n\n        # Resolve path (detect potential path traversal)\n        resolved_path = Path(filepath_str).resolve()\n        if \"..\" in str(filepath):\n            warnings.warn(\n                f\"Config file path contains '..' (parent directory reference): {filepath}\\n\"\n                f\"Resolved to: {resolved_path}\\n\"\n                f\"This is allowed but ensure the path is from a trusted source to prevent path traversal attacks.\",\n                UserWarning,\n                stacklevel=2,\n            )\n\n        # Load YAML with metadata tracking\n        registry = MetadataRegistry()\n        with open(resolved_path) as f:\n            config = self._load_yaml_with_metadata(f, str(resolved_path), registry)\n\n        # Strip metadata keys from config (they're now in registry)\n        config = self._strip_metadata(config)\n\n        return config, registry\n\n    def _load_yaml_with_metadata(self, stream, filepath: str, registry: MetadataRegistry) -&gt; dict:\n        \"\"\"Load YAML and populate metadata registry during construction.\n\n        Args:\n            stream: File stream to load from\n            filepath: Path string for error messages\n            registry: MetadataRegistry to populate\n\n        Returns:\n            Config dictionary (clean, no metadata keys)\n        \"\"\"\n\n        # Create custom loader class with metadata tracking\n        class TrackerLoader(MetadataTrackingYamlLoader):\n            pass\n\n        # Bind the filepath and registry to this specific loader instance\n        def loader_init(self, stream_arg):\n            MetadataTrackingYamlLoader.__init__(self, stream_arg, filepath, registry)\n\n        TrackerLoader.__init__ = loader_init\n\n        # Load and return clean config\n        config = yaml.load(stream, TrackerLoader)\n        return config if config is not None else {}\n\n    @staticmethod\n    def _strip_metadata(config: Any) -&gt; Any:\n        \"\"\"Remove __sparkwheel_metadata__ keys from config.\n\n        Args:\n            config: Config structure potentially containing metadata keys\n\n        Returns:\n            Config with metadata keys removed\n        \"\"\"\n        if isinstance(config, dict):\n            return {k: Loader._strip_metadata(v) for k, v in config.items() if k != \"__sparkwheel_metadata__\"}\n        elif isinstance(config, list):\n            return [Loader._strip_metadata(item) for item in config]\n        else:\n            return config\n\n    def load_files(self, filepaths: Sequence[PathLike]) -&gt; tuple[dict, MetadataRegistry]:\n        \"\"\"Load multiple YAML files sequentially.\n\n        Files are loaded in order and merged using simple dict update\n        (not the merge_configs logic - that happens at a higher level).\n\n        Args:\n            filepaths: Sequence of file paths to load\n\n        Returns:\n            Tuple of (merged_config_dict, merged_metadata_registry)\n        \"\"\"\n        combined_config = {}\n        combined_registry = MetadataRegistry()\n\n        for filepath in filepaths:\n            config, registry = self.load_file(filepath)\n            combined_config.update(config)\n            combined_registry.merge(registry)\n\n        return combined_config, combined_registry\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.Loader._load_yaml_with_metadata","title":"<code>_load_yaml_with_metadata(stream, filepath, registry)</code>","text":"<p>Load YAML and populate metadata registry during construction.</p> <p>Parameters:</p> Name Type Description Default <code>stream</code> <p>File stream to load from</p> required <code>filepath</code> <code>str</code> <p>Path string for error messages</p> required <code>registry</code> <code>MetadataRegistry</code> <p>MetadataRegistry to populate</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Config dictionary (clean, no metadata keys)</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>def _load_yaml_with_metadata(self, stream, filepath: str, registry: MetadataRegistry) -&gt; dict:\n    \"\"\"Load YAML and populate metadata registry during construction.\n\n    Args:\n        stream: File stream to load from\n        filepath: Path string for error messages\n        registry: MetadataRegistry to populate\n\n    Returns:\n        Config dictionary (clean, no metadata keys)\n    \"\"\"\n\n    # Create custom loader class with metadata tracking\n    class TrackerLoader(MetadataTrackingYamlLoader):\n        pass\n\n    # Bind the filepath and registry to this specific loader instance\n    def loader_init(self, stream_arg):\n        MetadataTrackingYamlLoader.__init__(self, stream_arg, filepath, registry)\n\n    TrackerLoader.__init__ = loader_init\n\n    # Load and return clean config\n    config = yaml.load(stream, TrackerLoader)\n    return config if config is not None else {}\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.Loader._strip_metadata","title":"<code>_strip_metadata(config)</code>  <code>staticmethod</code>","text":"<p>Remove sparkwheel_metadata keys from config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Config structure potentially containing metadata keys</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Config with metadata keys removed</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>@staticmethod\ndef _strip_metadata(config: Any) -&gt; Any:\n    \"\"\"Remove __sparkwheel_metadata__ keys from config.\n\n    Args:\n        config: Config structure potentially containing metadata keys\n\n    Returns:\n        Config with metadata keys removed\n    \"\"\"\n    if isinstance(config, dict):\n        return {k: Loader._strip_metadata(v) for k, v in config.items() if k != \"__sparkwheel_metadata__\"}\n    elif isinstance(config, list):\n        return [Loader._strip_metadata(item) for item in config]\n    else:\n        return config\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.Loader.load_file","title":"<code>load_file(filepath)</code>","text":"<p>Load a single YAML file with metadata tracking.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>PathLike</code> <p>Path to YAML file</p> required <p>Returns:</p> Type Description <code>tuple[dict, MetadataRegistry]</code> <p>Tuple of (config_dict, metadata_registry)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If file is not a YAML file</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>def load_file(self, filepath: PathLike) -&gt; tuple[dict, MetadataRegistry]:\n    \"\"\"Load a single YAML file with metadata tracking.\n\n    Args:\n        filepath: Path to YAML file\n\n    Returns:\n        Tuple of (config_dict, metadata_registry)\n\n    Raises:\n        ValueError: If file is not a YAML file\n    \"\"\"\n    if not filepath:\n        return {}, MetadataRegistry()\n\n    filepath_str = str(Path(filepath))\n\n    # Validate YAML extension\n    if not is_yaml_file(filepath_str):\n        raise ValueError(f'Unknown file input: \"{filepath}\", must be a YAML file (.yaml or .yml)')\n\n    # Resolve path (detect potential path traversal)\n    resolved_path = Path(filepath_str).resolve()\n    if \"..\" in str(filepath):\n        warnings.warn(\n            f\"Config file path contains '..' (parent directory reference): {filepath}\\n\"\n            f\"Resolved to: {resolved_path}\\n\"\n            f\"This is allowed but ensure the path is from a trusted source to prevent path traversal attacks.\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n    # Load YAML with metadata tracking\n    registry = MetadataRegistry()\n    with open(resolved_path) as f:\n        config = self._load_yaml_with_metadata(f, str(resolved_path), registry)\n\n    # Strip metadata keys from config (they're now in registry)\n    config = self._strip_metadata(config)\n\n    return config, registry\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.Loader.load_files","title":"<code>load_files(filepaths)</code>","text":"<p>Load multiple YAML files sequentially.</p> <p>Files are loaded in order and merged using simple dict update (not the merge_configs logic - that happens at a higher level).</p> <p>Parameters:</p> Name Type Description Default <code>filepaths</code> <code>Sequence[PathLike]</code> <p>Sequence of file paths to load</p> required <p>Returns:</p> Type Description <code>tuple[dict, MetadataRegistry]</code> <p>Tuple of (merged_config_dict, merged_metadata_registry)</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>def load_files(self, filepaths: Sequence[PathLike]) -&gt; tuple[dict, MetadataRegistry]:\n    \"\"\"Load multiple YAML files sequentially.\n\n    Files are loaded in order and merged using simple dict update\n    (not the merge_configs logic - that happens at a higher level).\n\n    Args:\n        filepaths: Sequence of file paths to load\n\n    Returns:\n        Tuple of (merged_config_dict, merged_metadata_registry)\n    \"\"\"\n    combined_config = {}\n    combined_registry = MetadataRegistry()\n\n    for filepath in filepaths:\n        config, registry = self.load_file(filepath)\n        combined_config.update(config)\n        combined_registry.merge(registry)\n\n    return combined_config, combined_registry\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.MetadataTrackingYamlLoader","title":"<code>MetadataTrackingYamlLoader</code>","text":"<p>               Bases: <code>CheckKeyDuplicatesYamlLoader</code></p> <p>YAML loader that tracks source locations into MetadataRegistry.</p> <p>Unlike the old approach that added sparkwheel_metadata keys to dicts, this loader populates a separate MetadataRegistry during loading.</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>class MetadataTrackingYamlLoader(CheckKeyDuplicatesYamlLoader):\n    \"\"\"YAML loader that tracks source locations into MetadataRegistry.\n\n    Unlike the old approach that added __sparkwheel_metadata__ keys to dicts,\n    this loader populates a separate MetadataRegistry during loading.\n    \"\"\"\n\n    def __init__(self, stream, filepath: str, registry: MetadataRegistry):\n        super().__init__(stream)\n        self.filepath = filepath\n        self.registry = registry\n        self.id_path_stack: list[str] = []  # Track current path during construction\n\n    def construct_mapping(self, node, deep=False):\n        \"\"\"Override to track source locations for dict nodes.\"\"\"\n        # Register source location for this dict node\n        current_id = ID_SEP_KEY.join(self.id_path_stack) if self.id_path_stack else \"\"\n\n        if node.start_mark:\n            location = SourceLocation(\n                filepath=self.filepath,\n                line=node.start_mark.line + 1,\n                column=node.start_mark.column + 1,\n                id=current_id,\n            )\n            self.registry.register(current_id, location)\n\n        # For non-deep construction, we construct children manually to track paths\n        if not deep:\n            mapping = {}\n            for key_node, value_node in node.value:\n                # Construct key\n                key = self.construct_object(key_node, deep=False)\n\n                # Push key onto path stack before constructing value\n                self.id_path_stack.append(str(key))\n\n                # Construct value with updated path\n                value = self.construct_object(value_node, deep=True)\n\n                # Pop key from path stack\n                self.id_path_stack.pop()\n\n                mapping[key] = value\n\n            return mapping\n        else:\n            # Use parent's deep construction\n            return super().construct_mapping(node, deep=True)\n\n    def construct_sequence(self, node, deep=False):\n        \"\"\"Override to track source locations for list nodes.\"\"\"\n        # Register source location for this list node\n        current_id = ID_SEP_KEY.join(self.id_path_stack) if self.id_path_stack else \"\"\n\n        if node.start_mark:\n            location = SourceLocation(\n                filepath=self.filepath,\n                line=node.start_mark.line + 1,\n                column=node.start_mark.column + 1,\n                id=current_id,\n            )\n            self.registry.register(current_id, location)\n\n        # For non-deep construction, construct children manually to track paths\n        if not deep:\n            sequence = []\n            for idx, child_node in enumerate(node.value):\n                # Push index onto path stack\n                self.id_path_stack.append(str(idx))\n\n                # Construct child with updated path\n                value = self.construct_object(child_node, deep=True)\n\n                # Pop index from path stack\n                self.id_path_stack.pop()\n\n                sequence.append(value)\n\n            return sequence\n        else:\n            # Use parent's deep construction\n            return super().construct_sequence(node, deep=True)\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.MetadataTrackingYamlLoader.construct_mapping","title":"<code>construct_mapping(node, deep=False)</code>","text":"<p>Override to track source locations for dict nodes.</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>def construct_mapping(self, node, deep=False):\n    \"\"\"Override to track source locations for dict nodes.\"\"\"\n    # Register source location for this dict node\n    current_id = ID_SEP_KEY.join(self.id_path_stack) if self.id_path_stack else \"\"\n\n    if node.start_mark:\n        location = SourceLocation(\n            filepath=self.filepath,\n            line=node.start_mark.line + 1,\n            column=node.start_mark.column + 1,\n            id=current_id,\n        )\n        self.registry.register(current_id, location)\n\n    # For non-deep construction, we construct children manually to track paths\n    if not deep:\n        mapping = {}\n        for key_node, value_node in node.value:\n            # Construct key\n            key = self.construct_object(key_node, deep=False)\n\n            # Push key onto path stack before constructing value\n            self.id_path_stack.append(str(key))\n\n            # Construct value with updated path\n            value = self.construct_object(value_node, deep=True)\n\n            # Pop key from path stack\n            self.id_path_stack.pop()\n\n            mapping[key] = value\n\n        return mapping\n    else:\n        # Use parent's deep construction\n        return super().construct_mapping(node, deep=True)\n</code></pre>"},{"location":"reference/loader/#sparkwheel.loader.MetadataTrackingYamlLoader.construct_sequence","title":"<code>construct_sequence(node, deep=False)</code>","text":"<p>Override to track source locations for list nodes.</p> Source code in <code>src/sparkwheel/loader.py</code> <pre><code>def construct_sequence(self, node, deep=False):\n    \"\"\"Override to track source locations for list nodes.\"\"\"\n    # Register source location for this list node\n    current_id = ID_SEP_KEY.join(self.id_path_stack) if self.id_path_stack else \"\"\n\n    if node.start_mark:\n        location = SourceLocation(\n            filepath=self.filepath,\n            line=node.start_mark.line + 1,\n            column=node.start_mark.column + 1,\n            id=current_id,\n        )\n        self.registry.register(current_id, location)\n\n    # For non-deep construction, construct children manually to track paths\n    if not deep:\n        sequence = []\n        for idx, child_node in enumerate(node.value):\n            # Push index onto path stack\n            self.id_path_stack.append(str(idx))\n\n            # Construct child with updated path\n            value = self.construct_object(child_node, deep=True)\n\n            # Pop index from path stack\n            self.id_path_stack.pop()\n\n            sequence.append(value)\n\n        return sequence\n    else:\n        # Use parent's deep construction\n        return super().construct_sequence(node, deep=True)\n</code></pre>"},{"location":"reference/metadata/","title":"metadata","text":"<p>Source location metadata tracking.</p>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry","title":"<code>MetadataRegistry</code>","text":"<p>Track source locations for config items.</p> <p>Maintains a clean separation between config data and metadata about where config items came from. This avoids polluting config dictionaries with metadata keys.</p> Example <pre><code>registry = MetadataRegistry()\nregistry.register(\"model::lr\", SourceLocation(\"config.yaml\", 10, 2, \"model::lr\"))\n\nlocation = registry.get(\"model::lr\")\nprint(location.filepath)  # \"config.yaml\"\nprint(location.line)      # 10\n</code></pre> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>class MetadataRegistry:\n    \"\"\"Track source locations for config items.\n\n    Maintains a clean separation between config data and metadata about where\n    config items came from. This avoids polluting config dictionaries with\n    metadata keys.\n\n    Example:\n        ```python\n        registry = MetadataRegistry()\n        registry.register(\"model::lr\", SourceLocation(\"config.yaml\", 10, 2, \"model::lr\"))\n\n        location = registry.get(\"model::lr\")\n        print(location.filepath)  # \"config.yaml\"\n        print(location.line)      # 10\n        ```\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize empty metadata registry.\"\"\"\n        self._locations: dict[str, SourceLocation] = {}\n\n    def register(self, id_path: str, location: SourceLocation) -&gt; None:\n        \"\"\"Register source location for a config path.\n\n        Args:\n            id_path: Configuration path (e.g., \"model::lr\", \"optimizer::params::0\")\n            location: Source location information\n        \"\"\"\n        self._locations[id_path] = location\n\n    def get(self, id_path: str) -&gt; SourceLocation | None:\n        \"\"\"Get source location for a config path.\n\n        Args:\n            id_path: Configuration path to look up\n\n        Returns:\n            SourceLocation if registered, None otherwise\n        \"\"\"\n        return self._locations.get(id_path)\n\n    def merge(self, other: \"MetadataRegistry\") -&gt; None:\n        \"\"\"Merge another registry into this one.\n\n        Args:\n            other: MetadataRegistry to merge from\n        \"\"\"\n        self._locations.update(other._locations)\n\n    def copy(self) -&gt; \"MetadataRegistry\":\n        \"\"\"Create a copy of this registry.\n\n        Returns:\n            New MetadataRegistry with same data\n        \"\"\"\n        new_registry = MetadataRegistry()\n        new_registry._locations = self._locations.copy()\n        return new_registry\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of registered locations.\"\"\"\n        return len(self._locations)\n\n    def __contains__(self, id_path: str) -&gt; bool:\n        \"\"\"Check if id_path has registered location.\"\"\"\n        return id_path in self._locations\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.__contains__","title":"<code>__contains__(id_path)</code>","text":"<p>Check if id_path has registered location.</p> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def __contains__(self, id_path: str) -&gt; bool:\n    \"\"\"Check if id_path has registered location.\"\"\"\n    return id_path in self._locations\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.__init__","title":"<code>__init__()</code>","text":"<p>Initialize empty metadata registry.</p> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize empty metadata registry.\"\"\"\n    self._locations: dict[str, SourceLocation] = {}\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.__len__","title":"<code>__len__()</code>","text":"<p>Return number of registered locations.</p> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of registered locations.\"\"\"\n    return len(self._locations)\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.copy","title":"<code>copy()</code>","text":"<p>Create a copy of this registry.</p> <p>Returns:</p> Type Description <code>MetadataRegistry</code> <p>New MetadataRegistry with same data</p> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def copy(self) -&gt; \"MetadataRegistry\":\n    \"\"\"Create a copy of this registry.\n\n    Returns:\n        New MetadataRegistry with same data\n    \"\"\"\n    new_registry = MetadataRegistry()\n    new_registry._locations = self._locations.copy()\n    return new_registry\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.get","title":"<code>get(id_path)</code>","text":"<p>Get source location for a config path.</p> <p>Parameters:</p> Name Type Description Default <code>id_path</code> <code>str</code> <p>Configuration path to look up</p> required <p>Returns:</p> Type Description <code>SourceLocation | None</code> <p>SourceLocation if registered, None otherwise</p> Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def get(self, id_path: str) -&gt; SourceLocation | None:\n    \"\"\"Get source location for a config path.\n\n    Args:\n        id_path: Configuration path to look up\n\n    Returns:\n        SourceLocation if registered, None otherwise\n    \"\"\"\n    return self._locations.get(id_path)\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.merge","title":"<code>merge(other)</code>","text":"<p>Merge another registry into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>MetadataRegistry</code> <p>MetadataRegistry to merge from</p> required Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def merge(self, other: \"MetadataRegistry\") -&gt; None:\n    \"\"\"Merge another registry into this one.\n\n    Args:\n        other: MetadataRegistry to merge from\n    \"\"\"\n    self._locations.update(other._locations)\n</code></pre>"},{"location":"reference/metadata/#sparkwheel.metadata.MetadataRegistry.register","title":"<code>register(id_path, location)</code>","text":"<p>Register source location for a config path.</p> <p>Parameters:</p> Name Type Description Default <code>id_path</code> <code>str</code> <p>Configuration path (e.g., \"model::lr\", \"optimizer::params::0\")</p> required <code>location</code> <code>SourceLocation</code> <p>Source location information</p> required Source code in <code>src/sparkwheel/metadata.py</code> <pre><code>def register(self, id_path: str, location: SourceLocation) -&gt; None:\n    \"\"\"Register source location for a config path.\n\n    Args:\n        id_path: Configuration path (e.g., \"model::lr\", \"optimizer::params::0\")\n        location: Source location information\n    \"\"\"\n    self._locations[id_path] = location\n</code></pre>"},{"location":"reference/operators/","title":"operators","text":"<p>Configuration merging with composition-by-default and operators (=, ~).</p>"},{"location":"reference/operators/#sparkwheel.operators._validate_delete_operator","title":"<code>_validate_delete_operator(key, value)</code>","text":"<p>Validate remove operator value.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key name (without ~ prefix)</p> required <code>value</code> <code>Any</code> <p>The value provided with ~key</p> required <p>Raises:</p> Type Description <code>ConfigMergeError</code> <p>If value is not null, empty, or a list</p> Source code in <code>src/sparkwheel/operators.py</code> <pre><code>def _validate_delete_operator(key: str, value: Any) -&gt; None:\n    \"\"\"Validate remove operator value.\n\n    Args:\n        key: The key name (without ~ prefix)\n        value: The value provided with ~key\n\n    Raises:\n        ConfigMergeError: If value is not null, empty, or a list\n    \"\"\"\n    # Allow null, empty string, or list\n    if value is not None and value != \"\" and not isinstance(value, list):\n        raise ConfigMergeError(\n            f\"Remove operator '~{key}' must have null, empty, or list value\",\n            suggestion=f\"The '~' prefix removes keys/items and accepts:\\n\"\n            f\"- null or empty: remove the entire key\\n\"\n            f\"- list: remove specific items (indices for lists, keys for dicts)\\n\\n\"\n            f\"To remove the entire '{key}':\\n\"\n            f\"  ~{key}: null\\n\"\n            f\"  # or\\n\"\n            f\"  ~{key}:\\n\\n\"\n            f\"To remove specific items from a list:\\n\"\n            f\"  ~{key}: [0, 2, 4]  # Remove indices 0, 2, 4\\n\\n\"\n            f\"To remove specific keys from a dict:\\n\"\n            f\"  ~{key}: [\\\"train\\\", \\\"test\\\"]  # Remove keys 'train' and 'test'\\n\\n\"\n            f\"To remove a nested key:\\n\"\n            f\"  {key}:\\n\"\n            f\"    ~nested: null\\n\\n\"\n            f\"Or use path notation:\\n\"\n            f\"  ~{key}::nested: null\",\n        )\n\n    # Validate list is not empty\n    if isinstance(value, list) and len(value) == 0:\n        raise ConfigMergeError(\n            f\"Remove operator '~{key}' with list value cannot be empty\",\n            suggestion=f\"Either provide indices/keys to remove, or use null to remove the entire key.\\n\\n\"\n            f\"To remove the entire key:\\n\"\n            f\"  ~{key}: null\\n\\n\"\n            f\"To remove specific items:\\n\"\n            f\"  ~{key}: [0, 1]  # For lists (indices)\\n\"\n            f'  ~{key}: [\"key1\", \"key2\"]  # For dicts (keys)',\n        )\n</code></pre>"},{"location":"reference/operators/#sparkwheel.operators.apply_operators","title":"<code>apply_operators(base, override)</code>","text":"<p>Apply configuration changes with composition-by-default semantics.</p> <p>Default behavior: Compose (merge dicts, extend lists) Operators:     =key: value   - Replace operator: completely replace value (override default)     ~key: null    - Remove operator: delete key or list items (idempotent)     key: value    - Compose (default): merge dict or extend list</p> Composition-by-Default Philosophy <ul> <li>Dicts merge recursively by default (preserves existing keys)</li> <li>Lists extend by default (append new items)</li> <li>Only scalars and type mismatches replace</li> <li>Use = to explicitly replace entire dicts or lists</li> <li>Use ~ to delete keys (idempotent - no error if missing)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>dict</code> <p>Base configuration dict</p> required <code>override</code> <code>dict</code> <p>Override configuration dict with optional =/~ operators</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Merged configuration dict</p> <p>Raises:</p> Type Description <code>ConfigMergeError</code> <p>If operators are used incorrectly</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Default: Dicts merge\n&gt;&gt;&gt; base = {\"a\": 1, \"b\": {\"x\": 1, \"y\": 2}}\n&gt;&gt;&gt; override = {\"b\": {\"x\": 10}}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"a\": 1, \"b\": {\"x\": 10, \"y\": 2}}\n</code></pre> <pre><code>&gt;&gt;&gt; # Default: Lists extend\n&gt;&gt;&gt; base = {\"plugins\": [\"logger\", \"metrics\"]}\n&gt;&gt;&gt; override = {\"plugins\": [\"cache\"]}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"plugins\": [\"logger\", \"metrics\", \"cache\"]}\n</code></pre> <pre><code>&gt;&gt;&gt; # Replace operator: explicit override\n&gt;&gt;&gt; base = {\"model\": {\"lr\": 0.001, \"dropout\": 0.1}}\n&gt;&gt;&gt; override = {\"=model\": {\"lr\": 0.01}}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"model\": {\"lr\": 0.01}}\n</code></pre> <pre><code>&gt;&gt;&gt; # Remove operator: delete key (idempotent)\n&gt;&gt;&gt; base = {\"a\": 1, \"b\": 2, \"c\": 3}\n&gt;&gt;&gt; override = {\"b\": 5, \"~c\": None}\n&gt;&gt;&gt; apply_operators(base, override)\n{\"a\": 1, \"b\": 5}\n</code></pre> Source code in <code>src/sparkwheel/operators.py</code> <pre><code>def apply_operators(base: dict, override: dict) -&gt; dict:\n    \"\"\"Apply configuration changes with composition-by-default semantics.\n\n    Default behavior: Compose (merge dicts, extend lists)\n    Operators:\n        =key: value   - Replace operator: completely replace value (override default)\n        ~key: null    - Remove operator: delete key or list items (idempotent)\n        key: value    - Compose (default): merge dict or extend list\n\n    Composition-by-Default Philosophy:\n        - Dicts merge recursively by default (preserves existing keys)\n        - Lists extend by default (append new items)\n        - Only scalars and type mismatches replace\n        - Use = to explicitly replace entire dicts or lists\n        - Use ~ to delete keys (idempotent - no error if missing)\n\n    Args:\n        base: Base configuration dict\n        override: Override configuration dict with optional =/~ operators\n\n    Returns:\n        Merged configuration dict\n\n    Raises:\n        ConfigMergeError: If operators are used incorrectly\n\n    Examples:\n        &gt;&gt;&gt; # Default: Dicts merge\n        &gt;&gt;&gt; base = {\"a\": 1, \"b\": {\"x\": 1, \"y\": 2}}\n        &gt;&gt;&gt; override = {\"b\": {\"x\": 10}}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"a\": 1, \"b\": {\"x\": 10, \"y\": 2}}\n\n        &gt;&gt;&gt; # Default: Lists extend\n        &gt;&gt;&gt; base = {\"plugins\": [\"logger\", \"metrics\"]}\n        &gt;&gt;&gt; override = {\"plugins\": [\"cache\"]}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"plugins\": [\"logger\", \"metrics\", \"cache\"]}\n\n        &gt;&gt;&gt; # Replace operator: explicit override\n        &gt;&gt;&gt; base = {\"model\": {\"lr\": 0.001, \"dropout\": 0.1}}\n        &gt;&gt;&gt; override = {\"=model\": {\"lr\": 0.01}}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"model\": {\"lr\": 0.01}}\n\n        &gt;&gt;&gt; # Remove operator: delete key (idempotent)\n        &gt;&gt;&gt; base = {\"a\": 1, \"b\": 2, \"c\": 3}\n        &gt;&gt;&gt; override = {\"b\": 5, \"~c\": None}\n        &gt;&gt;&gt; apply_operators(base, override)\n        {\"a\": 1, \"b\": 5}\n    \"\"\"\n    if not isinstance(base, dict) or not isinstance(override, dict):\n        return deepcopy(override)\n\n    result = deepcopy(base)\n\n    for key, value in override.items():\n        if not isinstance(key, str):\n            result[key] = deepcopy(value)\n            continue\n\n        # Process replace operator (=key)\n        if key.startswith(REPLACE_KEY):\n            actual_key = key[1:]\n            result[actual_key] = deepcopy(value)\n            continue\n\n        # Process remove operator (~key)\n        if key.startswith(REMOVE_KEY):\n            actual_key = key[1:]\n            _validate_delete_operator(actual_key, value)\n\n            # Idempotent: no error if key doesn't exist\n            if actual_key not in result:\n                continue  # Silently skip\n\n            # Handle remove entire key (null or empty value)\n            if value is None or value == \"\":\n                del result[actual_key]\n                continue\n\n            # Handle remove specific items from list or dict (list value)\n            if isinstance(value, list):\n                base_val = result[actual_key]\n\n                # Remove from list by indices\n                if isinstance(base_val, list):\n                    list_len = len(base_val)\n\n                    # Validate all items are integers and normalize negative indices\n                    normalized_indices = []\n                    for idx in value:\n                        if not isinstance(idx, int):\n                            raise ConfigMergeError(\n                                f\"Cannot remove from list '{actual_key}': index must be integer, got {type(idx).__name__}\",\n                                suggestion=f\"When removing from a list, provide integer indices.\\n\\n\"\n                                f\"Example:\\n\"\n                                f\"  ~{actual_key}: [0, 2, 4]  # Remove items at indices 0, 2, 4\\n\"\n                                f\"  ~{actual_key}: [-1]       # Remove last item\",\n                            )\n\n                        # Validate index is in bounds\n                        if idx &gt;= list_len or idx &lt; -list_len:\n                            raise ConfigMergeError(\n                                f\"Cannot remove from list '{actual_key}': index {idx} out of range (list has {list_len} items)\",\n                                suggestion=f\"Valid indices are 0 to {list_len - 1}, or -{list_len} to -1.\\n\"\n                                f\"Use null to remove the entire list:\\n\"\n                                f\"  ~{actual_key}: null\",\n                            )\n\n                        # Normalize negative indices to positive\n                        normalized_idx = idx if idx &gt;= 0 else list_len + idx\n                        normalized_indices.append(normalized_idx)\n\n                    # Sort indices in descending order and remove duplicates\n                    sorted_indices = sorted(set(normalized_indices), reverse=True)\n\n                    # Remove in descending order to avoid shifting issues\n                    for idx in sorted_indices:\n                        del base_val[idx]\n\n                # Remove from dict by keys\n                elif isinstance(base_val, dict):\n                    for del_key in value:\n                        if del_key not in base_val:\n                            raise ConfigMergeError(\n                                f\"Cannot remove non-existent key '{del_key}' from '{actual_key}'\",\n                                suggestion=f\"The key '{del_key}' does not exist in '{actual_key}'.\\n\"\n                                f\"Available keys: {list(base_val.keys())}\",\n                            )\n                        del base_val[del_key]\n\n                else:\n                    raise ConfigMergeError(\n                        f\"Cannot remove items from '{actual_key}': expected list or dict, got {type(base_val).__name__}\",\n                        suggestion=f\"Item removal with '~{actual_key}: [...]' only works for lists and dicts.\\n\"\n                        f\"To remove the entire key:\\n\"\n                        f\"  ~{actual_key}: null\",\n                    )\n\n                continue\n\n        # No operator - COMPOSITION-BY-DEFAULT behavior\n        if key in result:\n            base_val = result[key]\n\n            # For dicts: MERGE (composition)\n            if isinstance(base_val, dict) and isinstance(value, dict):\n                result[key] = apply_operators(base_val, value)\n                continue\n\n            # For lists: EXTEND (composition)\n            if isinstance(base_val, list) and isinstance(value, list):\n                result[key] = base_val + value\n                continue\n\n            # For scalars: REPLACE\n            # For type mismatches: REPLACE\n\n        # Set/replace (for new keys or non-matching types)\n        result[key] = deepcopy(value)\n\n    return result\n</code></pre>"},{"location":"reference/operators/#sparkwheel.operators.validate_operators","title":"<code>validate_operators(config, parent_key='')</code>","text":"<p>Validate operator usage in config tree.</p> <p>With composition-by-default, validation is simpler: 1. Remove operators always work (idempotent delete) 2. Replace operators work on any type 3. No parent context requirements</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dict to validate</p> required <code>parent_key</code> <code>str</code> <p>Parent key path (for error messages)</p> <code>''</code> <p>Raises:</p> Type Description <code>ConfigMergeError</code> <p>If operator usage is invalid</p> Source code in <code>src/sparkwheel/operators.py</code> <pre><code>def validate_operators(config: dict, parent_key: str = \"\") -&gt; None:\n    \"\"\"Validate operator usage in config tree.\n\n    With composition-by-default, validation is simpler:\n    1. Remove operators always work (idempotent delete)\n    2. Replace operators work on any type\n    3. No parent context requirements\n\n    Args:\n        config: Configuration dict to validate\n        parent_key: Parent key path (for error messages)\n\n    Raises:\n        ConfigMergeError: If operator usage is invalid\n    \"\"\"\n    if not isinstance(config, dict):\n        return\n\n    for key, value in config.items():\n        if not isinstance(key, str):\n            continue\n\n        actual_key = key\n        operator = None\n\n        # Detect operator\n        if key.startswith(REPLACE_KEY):\n            actual_key = key[1:]\n            operator = \"replace\"\n        elif key.startswith(REMOVE_KEY):\n            actual_key = key[1:]\n            operator = \"remove\"\n\n        full_key = f\"{parent_key}::{actual_key}\" if parent_key else actual_key\n\n        # Validate remove operator\n        if operator == \"remove\":\n            _validate_delete_operator(actual_key, value)\n\n        # Recurse into nested dicts\n        if isinstance(value, dict) and operator != \"remove\":\n            validate_operators(value, full_key)\n</code></pre>"},{"location":"reference/parser/","title":"parser","text":"<p>Parse configuration tree and create Items.</p>"},{"location":"reference/parser/#sparkwheel.parser.Parser","title":"<code>Parser</code>","text":"<p>Parse config tree and create Items with source locations.</p> <p>Recursively traverses configuration dictionaries and lists, creating appropriate Item subclasses (Component, Expression, or plain Item) for each node.</p> Example <pre><code>config = {\n    \"lr\": 0.001,\n    \"doubled\": \"$@lr * 2\",\n    \"optimizer\": {\n        \"_target_\": \"torch.optim.Adam\",\n        \"lr\": \"@lr\"\n    }\n}\n\nmetadata = MetadataRegistry()\nparser = Parser(globals={}, metadata=metadata)\nitems = parser.parse(config)\n\n# Returns list of Items with proper types\nfor item in items:\n    print(f\"{item.id}: {type(item).__name__}\")\n# Output:\n# lr: Item\n# doubled: Expression\n# optimizer: Component\n# optimizer::lr: Item (the reference string)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>globals</code> <code>dict[str, Any]</code> <p>Global context for expression evaluation</p> required <code>metadata</code> <code>MetadataRegistry</code> <p>MetadataRegistry for source location lookup</p> required Source code in <code>src/sparkwheel/parser.py</code> <pre><code>class Parser:\n    \"\"\"Parse config tree and create Items with source locations.\n\n    Recursively traverses configuration dictionaries and lists, creating\n    appropriate Item subclasses (Component, Expression, or\n    plain Item) for each node.\n\n    Example:\n        ```python\n        config = {\n            \"lr\": 0.001,\n            \"doubled\": \"$@lr * 2\",\n            \"optimizer\": {\n                \"_target_\": \"torch.optim.Adam\",\n                \"lr\": \"@lr\"\n            }\n        }\n\n        metadata = MetadataRegistry()\n        parser = Parser(globals={}, metadata=metadata)\n        items = parser.parse(config)\n\n        # Returns list of Items with proper types\n        for item in items:\n            print(f\"{item.id}: {type(item).__name__}\")\n        # Output:\n        # lr: Item\n        # doubled: Expression\n        # optimizer: Component\n        # optimizer::lr: Item (the reference string)\n        ```\n\n    Args:\n        globals: Global context for expression evaluation\n        metadata: MetadataRegistry for source location lookup\n    \"\"\"\n\n    def __init__(self, globals: dict[str, Any], metadata: MetadataRegistry):\n        \"\"\"Initialize parser with globals and metadata.\n\n        Args:\n            globals: Dictionary of global variables for expression evaluation\n            metadata: MetadataRegistry for looking up source locations\n        \"\"\"\n        self._globals = globals\n        self._metadata = metadata\n\n    def parse(self, config: Any, id_prefix: str = \"\") -&gt; list[Item]:\n        \"\"\"Recursively parse config and create Items.\n\n        Args:\n            config: Configuration data to parse (dict, list, or primitive)\n            id_prefix: ID path prefix for nested items (e.g., \"model::optimizer\")\n\n        Returns:\n            List of all Items created from the config tree\n        \"\"\"\n        items: list[Item] = []\n        self._parse_recursive(config, id_prefix, items)\n        return items\n\n    def _parse_recursive(self, config: Any, id: str, items: list[Item]) -&gt; None:\n        \"\"\"Internal recursive parsing implementation.\n\n        Args:\n            config: Current config node to parse\n            id: Current ID path\n            items: List to accumulate Items (modified in place)\n        \"\"\"\n        # Get source location for this config node\n        source_location = self._metadata.get(id) if id else None\n\n        # Recursively parse nested structures\n        if isinstance(config, dict):\n            for key, value in config.items():\n                sub_id = f\"{id}{ID_SEP_KEY}{key}\" if id else str(key)\n                self._parse_recursive(value, sub_id, items)\n        elif isinstance(config, list):\n            for idx, value in enumerate(config):\n                sub_id = f\"{id}{ID_SEP_KEY}{idx}\" if id else str(idx)\n                self._parse_recursive(value, sub_id, items)\n\n        # Create appropriate Item for this node\n        if Component.is_instantiable(config):\n            items.append(Component(config=config, id=id, source_location=source_location))\n        elif Expression.is_expression(config):\n            items.append(Expression(config=config, id=id, globals=self._globals, source_location=source_location))\n        else:\n            items.append(Item(config=config, id=id, source_location=source_location))\n</code></pre>"},{"location":"reference/parser/#sparkwheel.parser.Parser.__init__","title":"<code>__init__(globals, metadata)</code>","text":"<p>Initialize parser with globals and metadata.</p> <p>Parameters:</p> Name Type Description Default <code>globals</code> <code>dict[str, Any]</code> <p>Dictionary of global variables for expression evaluation</p> required <code>metadata</code> <code>MetadataRegistry</code> <p>MetadataRegistry for looking up source locations</p> required Source code in <code>src/sparkwheel/parser.py</code> <pre><code>def __init__(self, globals: dict[str, Any], metadata: MetadataRegistry):\n    \"\"\"Initialize parser with globals and metadata.\n\n    Args:\n        globals: Dictionary of global variables for expression evaluation\n        metadata: MetadataRegistry for looking up source locations\n    \"\"\"\n    self._globals = globals\n    self._metadata = metadata\n</code></pre>"},{"location":"reference/parser/#sparkwheel.parser.Parser._parse_recursive","title":"<code>_parse_recursive(config, id, items)</code>","text":"<p>Internal recursive parsing implementation.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Current config node to parse</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>items</code> <code>list[Item]</code> <p>List to accumulate Items (modified in place)</p> required Source code in <code>src/sparkwheel/parser.py</code> <pre><code>def _parse_recursive(self, config: Any, id: str, items: list[Item]) -&gt; None:\n    \"\"\"Internal recursive parsing implementation.\n\n    Args:\n        config: Current config node to parse\n        id: Current ID path\n        items: List to accumulate Items (modified in place)\n    \"\"\"\n    # Get source location for this config node\n    source_location = self._metadata.get(id) if id else None\n\n    # Recursively parse nested structures\n    if isinstance(config, dict):\n        for key, value in config.items():\n            sub_id = f\"{id}{ID_SEP_KEY}{key}\" if id else str(key)\n            self._parse_recursive(value, sub_id, items)\n    elif isinstance(config, list):\n        for idx, value in enumerate(config):\n            sub_id = f\"{id}{ID_SEP_KEY}{idx}\" if id else str(idx)\n            self._parse_recursive(value, sub_id, items)\n\n    # Create appropriate Item for this node\n    if Component.is_instantiable(config):\n        items.append(Component(config=config, id=id, source_location=source_location))\n    elif Expression.is_expression(config):\n        items.append(Expression(config=config, id=id, globals=self._globals, source_location=source_location))\n    else:\n        items.append(Item(config=config, id=id, source_location=source_location))\n</code></pre>"},{"location":"reference/parser/#sparkwheel.parser.Parser.parse","title":"<code>parse(config, id_prefix='')</code>","text":"<p>Recursively parse config and create Items.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Configuration data to parse (dict, list, or primitive)</p> required <code>id_prefix</code> <code>str</code> <p>ID path prefix for nested items (e.g., \"model::optimizer\")</p> <code>''</code> <p>Returns:</p> Type Description <code>list[Item]</code> <p>List of all Items created from the config tree</p> Source code in <code>src/sparkwheel/parser.py</code> <pre><code>def parse(self, config: Any, id_prefix: str = \"\") -&gt; list[Item]:\n    \"\"\"Recursively parse config and create Items.\n\n    Args:\n        config: Configuration data to parse (dict, list, or primitive)\n        id_prefix: ID path prefix for nested items (e.g., \"model::optimizer\")\n\n    Returns:\n        List of all Items created from the config tree\n    \"\"\"\n    items: list[Item] = []\n    self._parse_recursive(config, id_prefix, items)\n    return items\n</code></pre>"},{"location":"reference/path_patterns/","title":"path_patterns","text":"<p>Centralized regex patterns for config path parsing.</p> <p>This module contains all regex patterns used across sparkwheel for parsing configuration paths, references, and file paths. Patterns are compiled once at module load and documented with examples.</p> <p>Why regex here? - Complex patterns (lookahead, Unicode support) - Performance (C regex engine) - Correctness (battle-tested patterns)</p> <p>Patterns are centralized here instead of scattered across multiple files for easier maintenance, testing, and documentation.</p>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns","title":"<code>PathPatterns</code>","text":"<p>Collection of compiled regex patterns for config path parsing.</p> <p>All patterns are compiled once at class definition time and reused. Each pattern includes documentation with examples of what it matches.</p> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>class PathPatterns:\n    \"\"\"Collection of compiled regex patterns for config path parsing.\n\n    All patterns are compiled once at class definition time and reused.\n    Each pattern includes documentation with examples of what it matches.\n    \"\"\"\n\n    # File path and config ID splitting\n    # Example: \"config.yaml::model::lr\" -&gt; captures \"config.yaml\"\n    # Uses lookahead (?=...) to find extension without consuming :: separator\n    FILE_AND_ID = re.compile(r\"(.*\\.(yaml|yml))(?=(?:::.*)|$)\", re.IGNORECASE)\n    \"\"\"Split combined file path and config ID.\n\n    The pattern uses lookahead to find the file extension without consuming\n    the :: separator that follows.\n\n    Matches:\n        - \"config.yaml::model::lr\" -&gt; group 1: \"config.yaml\"\n        - \"path/to/file.yml::key\" -&gt; group 1: \"path/to/file.yml\"\n        - \"/abs/path/cfg.yaml::a::b\" -&gt; group 1: \"/abs/path/cfg.yaml\"\n\n    Non-matches:\n        - \"model::lr\" -&gt; no .yaml/.yml extension\n        - \"data.json::key\" -&gt; wrong extension\n\n    Edge cases handled:\n        - Case insensitive: \"Config.YAML::key\" works\n        - Multiple extensions: \"backup.yaml.old\" stops at first .yaml\n        - Absolute paths: \"/etc/config.yaml::key\" works\n    \"\"\"\n\n    RELATIVE_REFERENCE = re.compile(rf\"(?:{RESOLVED_REF_KEY}|{RAW_REF_KEY})(::)+\")\n    \"\"\"Match relative reference prefixes: @::, @::::, %::, etc.\n\n    Used to find relative navigation patterns in config references.\n    The number of :: pairs indicates how many levels to go up.\n\n    Matches:\n        - \"@::\" -&gt; resolved reference one level up (parent)\n        - \"@::::\" -&gt; resolved reference two levels up (grandparent)\n        - \"%::\" -&gt; raw reference one level up\n        - \"%::::\" -&gt; raw reference two levels up\n\n    Examples in context:\n        - In \"model::optimizer\", \"@::lr\" means \"@model::lr\"\n        - In \"a::b::c\", \"@::::x\" means \"@a::x\"\n\n    Pattern breakdown:\n        - (?:@|%) -&gt; @ or % symbol (non-capturing group)\n        - (::)+ -&gt; one or more :: pairs (captured)\n    \"\"\"\n\n    ABSOLUTE_REFERENCE = re.compile(rf\"{RESOLVED_REF_KEY}(\\w+(?:::\\w+)*)\")\n    r\"\"\"Match absolute resolved reference patterns: @id::path::to::value\n\n    Finds @ resolved references in config values and expressions. Handles nested\n    paths with :: separators and list indices (numbers).\n\n    Matches:\n        - \"@model::lr\" -&gt; captures \"model::lr\"\n        - \"@data::0::value\" -&gt; captures \"data::0::value\"\n        - \"@x\" -&gt; captures \"x\"\n\n    Examples in expressions:\n        - \"$@model::lr * 2\" -&gt; matches \"@model::lr\"\n        - \"$@x + @y\" -&gt; matches \"@x\" and \"@y\"\n\n    Pattern breakdown:\n        - @ -&gt; literal @ symbol\n        - (\\w+(?:::\\w+)*) -&gt; captures word chars followed by optional :: and more word chars\n\n    Note: \\w includes [a-zA-Z0-9_] plus Unicode word characters,\n    so this handles international characters correctly.\n    \"\"\"\n\n    @classmethod\n    def split_file_and_id(cls, src: str) -&gt; tuple[str, str]:\n        \"\"\"Split combined file path and config ID using FILE_AND_ID pattern.\n\n        Args:\n            src: String like \"config.yaml::model::lr\"\n\n        Returns:\n            Tuple of (filepath, config_id)\n\n        Examples:\n            &gt;&gt;&gt; PathPatterns.split_file_and_id(\"config.yaml::model::lr\")\n            (\"config.yaml\", \"model::lr\")\n            &gt;&gt;&gt; PathPatterns.split_file_and_id(\"model::lr\")\n            (\"\", \"model::lr\")\n            &gt;&gt;&gt; PathPatterns.split_file_and_id(\"/path/to/file.yml::key\")\n            (\"/path/to/file.yml\", \"key\")\n        \"\"\"\n        src = src.strip()\n        match = cls.FILE_AND_ID.search(src)\n\n        if not match:\n            return \"\", src  # Pure ID, no file path\n\n        filepath = match.group(1)\n        remainder = src[match.end() :]\n\n        # Strip leading :: from config ID part\n        config_id = remainder[2:] if remainder.startswith(\"::\") else remainder\n\n        return filepath, config_id\n\n    @classmethod\n    def find_relative_references(cls, text: str) -&gt; list[str]:\n        \"\"\"Find all relative reference patterns in text.\n\n        Args:\n            text: String to search\n\n        Returns:\n            List of relative reference patterns found (e.g., ['@::', '@::::'])\n\n        Examples:\n            &gt;&gt;&gt; PathPatterns.find_relative_references(\"value: @::sibling\")\n            ['@::']\n            &gt;&gt;&gt; PathPatterns.find_relative_references(\"@::::parent and @::sibling\")\n            ['@::::', '@::']\n        \"\"\"\n        # Use finditer to get full matches instead of just captured groups\n        return [match.group(0) for match in cls.RELATIVE_REFERENCE.finditer(text)]\n\n    @classmethod\n    def find_absolute_references(cls, text: str) -&gt; list[str]:\n        \"\"\"Find all absolute reference patterns in text.\n\n        Only searches in expressions ($...) or pure reference values.\n\n        Args:\n            text: String to search\n\n        Returns:\n            List of reference IDs found (without @ prefix)\n\n        Examples:\n            &gt;&gt;&gt; PathPatterns.find_absolute_references(\"@model::lr\")\n            ['model::lr']\n            &gt;&gt;&gt; PathPatterns.find_absolute_references(\"$@x + @y\")\n            ['x', 'y']\n            &gt;&gt;&gt; PathPatterns.find_absolute_references(\"normal text\")\n            []\n        \"\"\"\n        is_expr = text.startswith(\"$\")\n        is_pure_ref = text.startswith(\"@\")\n\n        if not (is_expr or is_pure_ref):\n            return []\n\n        return cls.ABSOLUTE_REFERENCE.findall(text)\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.ABSOLUTE_REFERENCE","title":"<code>ABSOLUTE_REFERENCE = re.compile(f'{RESOLVED_REF_KEY}(\\w+(?:::\\w+)*)')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Match absolute resolved reference patterns: @id::path::value</p> <p>Finds @ resolved references in config values and expressions. Handles nested paths with :: separators and list indices (numbers).</p> Matches <ul> <li>\"@model::lr\" -&gt; captures \"model::lr\"</li> <li>\"@data::0::value\" -&gt; captures \"data::0::value\"</li> <li>\"@x\" -&gt; captures \"x\"</li> </ul> Examples in expressions <ul> <li>\"$@model::lr * 2\" -&gt; matches \"@model::lr\"</li> <li>\"$@x + @y\" -&gt; matches \"@x\" and \"@y\"</li> </ul> Pattern breakdown <ul> <li>@ -&gt; literal @ symbol</li> <li>(\\w+(?:::\\w+)*) -&gt; captures word chars followed by optional :: and more word chars</li> </ul> <p>Note: \\w includes [a-zA-Z0-9_] plus Unicode word characters, so this handles international characters correctly.</p>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.FILE_AND_ID","title":"<code>FILE_AND_ID = re.compile('(.*\\\\.(yaml|yml))(?=(?:::.*)|$)', re.IGNORECASE)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Split combined file path and config ID.</p> <p>The pattern uses lookahead to find the file extension without consuming the :: separator that follows.</p> Matches <ul> <li>\"config.yaml::model::lr\" -&gt; group 1: \"config.yaml\"</li> <li>\"path/to/file.yml::key\" -&gt; group 1: \"path/to/file.yml\"</li> <li>\"/abs/path/cfg.yaml::b\" -&gt; group 1: \"/abs/path/cfg.yaml\"</li> </ul> Non-matches <ul> <li>\"model::lr\" -&gt; no .yaml/.yml extension</li> <li>\"data.json::key\" -&gt; wrong extension</li> </ul> Edge cases handled <ul> <li>Case insensitive: \"Config.YAML::key\" works</li> <li>Multiple extensions: \"backup.yaml.old\" stops at first .yaml</li> <li>Absolute paths: \"/etc/config.yaml::key\" works</li> </ul>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.RELATIVE_REFERENCE","title":"<code>RELATIVE_REFERENCE = re.compile(f'(?:{RESOLVED_REF_KEY}|{RAW_REF_KEY})(::)+')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Match relative reference prefixes: @::, @::::, %::, etc.</p> <p>Used to find relative navigation patterns in config references. The number of :: pairs indicates how many levels to go up.</p> Matches <ul> <li>\"@::\" -&gt; resolved reference one level up (parent)</li> <li>\"@::::\" -&gt; resolved reference two levels up (grandparent)</li> <li>\"%::\" -&gt; raw reference one level up</li> <li>\"%::::\" -&gt; raw reference two levels up</li> </ul> Examples in context <ul> <li>In \"model::optimizer\", \"@::lr\" means \"@model::lr\"</li> <li>In \"a::c\", \"@::::x\" means \"@a::x\"</li> </ul> Pattern breakdown <ul> <li>(?:@|%) -&gt; @ or % symbol (non-capturing group)</li> <li>(::)+ -&gt; one or more :: pairs (captured)</li> </ul>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.find_absolute_references","title":"<code>find_absolute_references(text)</code>  <code>classmethod</code>","text":"<p>Find all absolute reference patterns in text.</p> <p>Only searches in expressions ($...) or pure reference values.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>String to search</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of reference IDs found (without @ prefix)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; PathPatterns.find_absolute_references(\"@model::lr\")\n['model::lr']\n&gt;&gt;&gt; PathPatterns.find_absolute_references(\"$@x + @y\")\n['x', 'y']\n&gt;&gt;&gt; PathPatterns.find_absolute_references(\"normal text\")\n[]\n</code></pre> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>@classmethod\ndef find_absolute_references(cls, text: str) -&gt; list[str]:\n    \"\"\"Find all absolute reference patterns in text.\n\n    Only searches in expressions ($...) or pure reference values.\n\n    Args:\n        text: String to search\n\n    Returns:\n        List of reference IDs found (without @ prefix)\n\n    Examples:\n        &gt;&gt;&gt; PathPatterns.find_absolute_references(\"@model::lr\")\n        ['model::lr']\n        &gt;&gt;&gt; PathPatterns.find_absolute_references(\"$@x + @y\")\n        ['x', 'y']\n        &gt;&gt;&gt; PathPatterns.find_absolute_references(\"normal text\")\n        []\n    \"\"\"\n    is_expr = text.startswith(\"$\")\n    is_pure_ref = text.startswith(\"@\")\n\n    if not (is_expr or is_pure_ref):\n        return []\n\n    return cls.ABSOLUTE_REFERENCE.findall(text)\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.find_relative_references","title":"<code>find_relative_references(text)</code>  <code>classmethod</code>","text":"<p>Find all relative reference patterns in text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>String to search</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of relative reference patterns found (e.g., ['@::', '@::::'])</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; PathPatterns.find_relative_references(\"value: @::sibling\")\n['@::']\n&gt;&gt;&gt; PathPatterns.find_relative_references(\"@::::parent and @::sibling\")\n['@::::', '@::']\n</code></pre> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>@classmethod\ndef find_relative_references(cls, text: str) -&gt; list[str]:\n    \"\"\"Find all relative reference patterns in text.\n\n    Args:\n        text: String to search\n\n    Returns:\n        List of relative reference patterns found (e.g., ['@::', '@::::'])\n\n    Examples:\n        &gt;&gt;&gt; PathPatterns.find_relative_references(\"value: @::sibling\")\n        ['@::']\n        &gt;&gt;&gt; PathPatterns.find_relative_references(\"@::::parent and @::sibling\")\n        ['@::::', '@::']\n    \"\"\"\n    # Use finditer to get full matches instead of just captured groups\n    return [match.group(0) for match in cls.RELATIVE_REFERENCE.finditer(text)]\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.PathPatterns.split_file_and_id","title":"<code>split_file_and_id(src)</code>  <code>classmethod</code>","text":"<p>Split combined file path and config ID using FILE_AND_ID pattern.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>str</code> <p>String like \"config.yaml::model::lr\"</p> required <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>Tuple of (filepath, config_id)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; PathPatterns.split_file_and_id(\"config.yaml::model::lr\")\n(\"config.yaml\", \"model::lr\")\n&gt;&gt;&gt; PathPatterns.split_file_and_id(\"model::lr\")\n(\"\", \"model::lr\")\n&gt;&gt;&gt; PathPatterns.split_file_and_id(\"/path/to/file.yml::key\")\n(\"/path/to/file.yml\", \"key\")\n</code></pre> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>@classmethod\ndef split_file_and_id(cls, src: str) -&gt; tuple[str, str]:\n    \"\"\"Split combined file path and config ID using FILE_AND_ID pattern.\n\n    Args:\n        src: String like \"config.yaml::model::lr\"\n\n    Returns:\n        Tuple of (filepath, config_id)\n\n    Examples:\n        &gt;&gt;&gt; PathPatterns.split_file_and_id(\"config.yaml::model::lr\")\n        (\"config.yaml\", \"model::lr\")\n        &gt;&gt;&gt; PathPatterns.split_file_and_id(\"model::lr\")\n        (\"\", \"model::lr\")\n        &gt;&gt;&gt; PathPatterns.split_file_and_id(\"/path/to/file.yml::key\")\n        (\"/path/to/file.yml\", \"key\")\n    \"\"\"\n    src = src.strip()\n    match = cls.FILE_AND_ID.search(src)\n\n    if not match:\n        return \"\", src  # Pure ID, no file path\n\n    filepath = match.group(1)\n    remainder = src[match.end() :]\n\n    # Strip leading :: from config ID part\n    config_id = remainder[2:] if remainder.startswith(\"::\") else remainder\n\n    return filepath, config_id\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.find_references","title":"<code>find_references(text)</code>","text":"<p>Convenience function wrapping PathPatterns.find_absolute_references().</p> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>def find_references(text: str) -&gt; list[str]:\n    \"\"\"Convenience function wrapping PathPatterns.find_absolute_references().\"\"\"\n    return PathPatterns.find_absolute_references(text)\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.is_yaml_file","title":"<code>is_yaml_file(filepath)</code>","text":"<p>Check if filepath is a YAML file (.yaml or .yml).</p> <p>Simple string check - no regex needed for this.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if filepath ends with .yaml or .yml (case-insensitive)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; is_yaml_file(\"config.yaml\")\nTrue\n&gt;&gt;&gt; is_yaml_file(\"CONFIG.YAML\")\nTrue\n&gt;&gt;&gt; is_yaml_file(\"data.json\")\nFalse\n</code></pre> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>def is_yaml_file(filepath: str) -&gt; bool:\n    \"\"\"Check if filepath is a YAML file (.yaml or .yml).\n\n    Simple string check - no regex needed for this.\n\n    Args:\n        filepath: Path to check\n\n    Returns:\n        True if filepath ends with .yaml or .yml (case-insensitive)\n\n    Examples:\n        &gt;&gt;&gt; is_yaml_file(\"config.yaml\")\n        True\n        &gt;&gt;&gt; is_yaml_file(\"CONFIG.YAML\")\n        True\n        &gt;&gt;&gt; is_yaml_file(\"data.json\")\n        False\n    \"\"\"\n    lower = filepath.lower()\n    return lower.endswith(\".yaml\") or lower.endswith(\".yml\")\n</code></pre>"},{"location":"reference/path_patterns/#sparkwheel.path_patterns.split_file_and_id","title":"<code>split_file_and_id(src)</code>","text":"<p>Convenience function wrapping PathPatterns.split_file_and_id().</p> Source code in <code>src/sparkwheel/path_patterns.py</code> <pre><code>def split_file_and_id(src: str) -&gt; tuple[str, str]:\n    \"\"\"Convenience function wrapping PathPatterns.split_file_and_id().\"\"\"\n    return PathPatterns.split_file_and_id(src)\n</code></pre>"},{"location":"reference/path_utils/","title":"path_utils","text":"<p>Path parsing and manipulation utilities.</p> <p>Provides helper functions for working with config paths, building on the regex patterns from path_patterns.py.</p>"},{"location":"reference/path_utils/#sparkwheel.path_utils.normalize_id","title":"<code>normalize_id(id)</code>","text":"<p>Normalize ID to string format.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>ID to normalize (string or int)</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representation of ID</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; normalize_id(\"model::lr\")\n\"model::lr\"\n&gt;&gt;&gt; normalize_id(42)\n\"42\"\n</code></pre> Source code in <code>src/sparkwheel/path_utils.py</code> <pre><code>def normalize_id(id: str | int) -&gt; str:\n    \"\"\"Normalize ID to string format.\n\n    Args:\n        id: ID to normalize (string or int)\n\n    Returns:\n        String representation of ID\n\n    Examples:\n        &gt;&gt;&gt; normalize_id(\"model::lr\")\n        \"model::lr\"\n        &gt;&gt;&gt; normalize_id(42)\n        \"42\"\n    \"\"\"\n    return str(id)\n</code></pre>"},{"location":"reference/path_utils/#sparkwheel.path_utils.replace_references","title":"<code>replace_references(text, resolved_refs, local_var_name='__local_refs')</code>","text":"<p>Replace @ references with resolved values.</p> <p>For pure references: Returns the resolved value directly For expressions: Replaces @ref with __local_refs['ref'] for eval() For other text: Returns unchanged</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>String containing references</p> required <code>resolved_refs</code> <code>dict[str, Any]</code> <p>Dict mapping reference IDs to resolved values</p> required <code>local_var_name</code> <code>str</code> <p>Variable name for expression substitution</p> <code>'__local_refs'</code> <p>Returns:</p> Type Description <code>str | Any</code> <ul> <li>Resolved value if text is a pure reference</li> </ul> <code>str | Any</code> <ul> <li>Modified string if text is an expression</li> </ul> <code>str | Any</code> <ul> <li>Original text if no references</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; refs = {\"model::lr\": 0.001, \"x\": 42}\n&gt;&gt;&gt; replace_references(\"@model::lr\", refs)\n0.001\n&gt;&gt;&gt; replace_references(\"$@x * 2\", refs)\n\"$__local_refs['x'] * 2\"\n&gt;&gt;&gt; replace_references(\"normal\", refs)\n\"normal\"\n</code></pre> <p>Raises:</p> Type Description <code>KeyError</code> <p>If a referenced ID is not in resolved_refs</p> Source code in <code>src/sparkwheel/path_utils.py</code> <pre><code>def replace_references(text: str, resolved_refs: dict[str, Any], local_var_name: str = \"__local_refs\") -&gt; str | Any:\n    \"\"\"Replace @ references with resolved values.\n\n    For pure references: Returns the resolved value directly\n    For expressions: Replaces @ref with __local_refs['ref'] for eval()\n    For other text: Returns unchanged\n\n    Args:\n        text: String containing references\n        resolved_refs: Dict mapping reference IDs to resolved values\n        local_var_name: Variable name for expression substitution\n\n    Returns:\n        - Resolved value if text is a pure reference\n        - Modified string if text is an expression\n        - Original text if no references\n\n    Examples:\n        &gt;&gt;&gt; refs = {\"model::lr\": 0.001, \"x\": 42}\n        &gt;&gt;&gt; replace_references(\"@model::lr\", refs)\n        0.001\n        &gt;&gt;&gt; replace_references(\"$@x * 2\", refs)\n        \"$__local_refs['x'] * 2\"\n        &gt;&gt;&gt; replace_references(\"normal\", refs)\n        \"normal\"\n\n    Raises:\n        KeyError: If a referenced ID is not in resolved_refs\n    \"\"\"\n    is_expr = text.startswith(\"$\")\n    is_pure_ref = text.startswith(\"@\") and \"@\" not in text[1:]\n\n    if is_pure_ref:\n        # Entire value is a single reference - return resolved value\n        ref_id = text[1:]  # Strip @\n        if ref_id not in resolved_refs:\n            raise KeyError(f\"Reference '@{ref_id}' not found in resolved references\")\n        return resolved_refs[ref_id]\n\n    if not is_expr:\n        # Not an expression or reference - return as-is\n        return text\n\n    # Expression - find all references and replace with variable access\n    # Use regex to find and replace\n    def replace_match(match):\n        ref_id = match.group(1)\n        if ref_id not in resolved_refs:\n            raise KeyError(f\"Reference '@{ref_id}' not found in resolved references\")\n        return f\"{local_var_name}['{ref_id}']\"\n\n    result = PathPatterns.ABSOLUTE_REFERENCE.sub(replace_match, text)\n    return result\n</code></pre>"},{"location":"reference/path_utils/#sparkwheel.path_utils.resolve_relative_ids","title":"<code>resolve_relative_ids(current_id, value)</code>","text":"<p>Resolve relative references (@::, @::::) to absolute paths.</p> <p>Converts relative navigation patterns to absolute paths based on the current position in the config tree.</p> <p>Parameters:</p> Name Type Description Default <code>current_id</code> <code>str</code> <p>Current position in config (e.g., \"model::optimizer\")</p> required <code>value</code> <code>str</code> <p>String that may contain relative references</p> required <p>Returns:</p> Type Description <code>str</code> <p>String with relative references resolved to absolute</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; resolve_relative_ids(\"model::optimizer\", \"@::lr\")\n\"@model::lr\"\n&gt;&gt;&gt; resolve_relative_ids(\"a::b::c\", \"@::::lr\")\n\"@a::lr\"\n&gt;&gt;&gt; resolve_relative_ids(\"model\", \"@::lr\")\n\"@lr\"\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If relative reference goes beyond root</p> Source code in <code>src/sparkwheel/path_utils.py</code> <pre><code>def resolve_relative_ids(current_id: str, value: str) -&gt; str:\n    \"\"\"Resolve relative references (@::, @::::) to absolute paths.\n\n    Converts relative navigation patterns to absolute paths based on\n    the current position in the config tree.\n\n    Args:\n        current_id: Current position in config (e.g., \"model::optimizer\")\n        value: String that may contain relative references\n\n    Returns:\n        String with relative references resolved to absolute\n\n    Examples:\n        &gt;&gt;&gt; resolve_relative_ids(\"model::optimizer\", \"@::lr\")\n        \"@model::lr\"\n        &gt;&gt;&gt; resolve_relative_ids(\"a::b::c\", \"@::::lr\")\n        \"@a::lr\"\n        &gt;&gt;&gt; resolve_relative_ids(\"model\", \"@::lr\")\n        \"@lr\"\n\n    Raises:\n        ValueError: If relative reference goes beyond root\n    \"\"\"\n    # Find all relative reference patterns using centralized regex\n    patterns = PathPatterns.find_relative_references(value)\n\n    # Sort by length (longest first) to avoid partial replacements\n    # e.g., replace \"@::::\" before \"@::\" so we don't double-process\n    patterns = sorted(set(patterns), key=len, reverse=True)\n\n    current_parts = current_id.split(ID_SEP_KEY) if current_id else []\n\n    for pattern in patterns:\n        # Determine symbol (@ for resolved reference, % for raw reference)\n        symbol = pattern[0]\n\n        # Count :: pairs to determine how many levels to go up\n        # @:: = 1 level up, @:::: = 2 levels up\n        levels_up = pattern[1:].count(ID_SEP_KEY)\n\n        # Validate we don't go too far up the tree\n        if levels_up &gt; len(current_parts):\n            raise ValueError(\n                f\"Relative reference '{pattern}' in '{value}' attempts to go \"\n                f\"{levels_up} levels up, but current path '{current_id}' only \"\n                f\"has {len(current_parts)} levels\"\n            )\n\n        # Calculate the absolute path\n        if levels_up == len(current_parts):\n            # Going to root level\n            absolute = symbol\n        else:\n            # Going to ancestor at specific level\n            ancestor_parts = current_parts[:-levels_up] if levels_up &gt; 0 else current_parts\n            absolute = symbol + ID_SEP_KEY.join(ancestor_parts)\n            if ancestor_parts:  # Add trailing separator if not at root\n                absolute += ID_SEP_KEY\n\n        # Replace pattern in value\n        value = value.replace(pattern, absolute)\n\n    return value\n</code></pre>"},{"location":"reference/path_utils/#sparkwheel.path_utils.scan_references","title":"<code>scan_references(text)</code>","text":"<p>Find all @ reference patterns in text and count occurrences.</p> <p>Only scans in expressions ($...) or pure reference values.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>String to scan</p> required <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping reference IDs (without @) to occurrence counts</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scan_references(\"@model::lr\")\n{\"model::lr\": 1}\n&gt;&gt;&gt; scan_references(\"$@x + @x\")\n{\"x\": 2}\n&gt;&gt;&gt; scan_references(\"normal text\")\n{}\n</code></pre> Source code in <code>src/sparkwheel/path_utils.py</code> <pre><code>def scan_references(text: str) -&gt; dict[str, int]:\n    \"\"\"Find all @ reference patterns in text and count occurrences.\n\n    Only scans in expressions ($...) or pure reference values.\n\n    Args:\n        text: String to scan\n\n    Returns:\n        Dict mapping reference IDs (without @) to occurrence counts\n\n    Examples:\n        &gt;&gt;&gt; scan_references(\"@model::lr\")\n        {\"model::lr\": 1}\n        &gt;&gt;&gt; scan_references(\"$@x + @x\")\n        {\"x\": 2}\n        &gt;&gt;&gt; scan_references(\"normal text\")\n        {}\n    \"\"\"\n    refs: dict[str, int] = {}\n\n    # Only process expressions or pure references\n    is_expr = text.startswith(\"$\")\n    is_pure_ref = text.startswith(\"@\")\n\n    if not (is_expr or is_pure_ref):\n        return refs\n\n    # Use centralized pattern to find all references\n    ref_ids = PathPatterns.find_absolute_references(text)\n\n    # Count occurrences\n    for ref_id in ref_ids:\n        refs[ref_id] = refs.get(ref_id, 0) + 1\n\n    return refs\n</code></pre>"},{"location":"reference/path_utils/#sparkwheel.path_utils.split_id","title":"<code>split_id(id)</code>","text":"<p>Split config ID into parts by :: separator.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>Config ID to split</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of ID components</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_id(\"model::optimizer::lr\")\n[\"model\", \"optimizer\", \"lr\"]\n&gt;&gt;&gt; split_id(\"data::0::value\")\n[\"data\", \"0\", \"value\"]\n&gt;&gt;&gt; split_id(\"simple\")\n[\"simple\"]\n</code></pre> Source code in <code>src/sparkwheel/path_utils.py</code> <pre><code>def split_id(id: str | int) -&gt; list[str]:\n    \"\"\"Split config ID into parts by :: separator.\n\n    Args:\n        id: Config ID to split\n\n    Returns:\n        List of ID components\n\n    Examples:\n        &gt;&gt;&gt; split_id(\"model::optimizer::lr\")\n        [\"model\", \"optimizer\", \"lr\"]\n        &gt;&gt;&gt; split_id(\"data::0::value\")\n        [\"data\", \"0\", \"value\"]\n        &gt;&gt;&gt; split_id(\"simple\")\n        [\"simple\"]\n    \"\"\"\n    return normalize_id(id).split(ID_SEP_KEY)\n</code></pre>"},{"location":"reference/preprocessor/","title":"preprocessor","text":"<p>Configuration preprocessing before parsing.</p> <p>Handles transformations on raw config dicts before Items are created: - Raw reference expansion (% references to external files or local YAML) - Relative ID resolution (@::, @:::: \u2192 absolute paths)</p>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>Preprocess raw config before parsing into Items.</p> <p>Pipeline: Raw YAML dict \u2192 Preprocessor \u2192 Parser \u2192 Resolver \u2192 Final values</p> <p>This is the first processing stage after loading YAML: - Expands % raw references (loads external files or local YAML and copies values) - Converts relative IDs (@::, @::::) to absolute paths (@)</p> <p>Operates on raw Python dicts/lists, not on Item objects.</p> Example <p>loader = Loader() preprocessor = Preprocessor(loader)</p> <p>raw_config = { ...     \"lr\": 0.001, ...     \"base\": \"%defaults.yaml::learning_rate\",  # Raw reference (external) ...     \"model\": { ...         \"lr\": \"@::lr\"  # Relative resolved reference ...     } ... }</p> <p>preprocessed = preprocessor.process(raw_config, raw_config)</p> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>class Preprocessor:\n    \"\"\"Preprocess raw config before parsing into Items.\n\n    Pipeline: Raw YAML dict \u2192 Preprocessor \u2192 Parser \u2192 Resolver \u2192 Final values\n\n    This is the first processing stage after loading YAML:\n    - Expands % raw references (loads external files or local YAML and copies values)\n    - Converts relative IDs (@::, @::::) to absolute paths (@)\n\n    Operates on raw Python dicts/lists, not on Item objects.\n\n    Example:\n        &gt;&gt;&gt; loader = Loader()\n        &gt;&gt;&gt; preprocessor = Preprocessor(loader)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; raw_config = {\n        ...     \"lr\": 0.001,\n        ...     \"base\": \"%defaults.yaml::learning_rate\",  # Raw reference (external)\n        ...     \"model\": {\n        ...         \"lr\": \"@::lr\"  # Relative resolved reference\n        ...     }\n        ... }\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; preprocessed = preprocessor.process(raw_config, raw_config)\n        &gt;&gt;&gt; # Result:\n        &gt;&gt;&gt; # {\n        &gt;&gt;&gt; #     \"lr\": 0.001,\n        &gt;&gt;&gt; #     \"base\": 0.0005,  # Loaded from defaults.yaml\n        &gt;&gt;&gt; #     \"model\": {\n        &gt;&gt;&gt; #         \"lr\": \"@model::lr\"  # Converted to absolute\n        &gt;&gt;&gt; #     }\n        &gt;&gt;&gt; # }\n    \"\"\"\n\n    def __init__(self, loader, globals: dict[str, Any] | None = None):\n        \"\"\"Initialize preprocessor.\n\n        Args:\n            loader: Loader instance for loading external raw reference files\n            globals: Global context (unused here, kept for API consistency)\n        \"\"\"\n        self.loader = loader\n        self.globals = globals or {}\n\n    def process(self, config: Any, base_data: dict, id: str = \"\") -&gt; Any:\n        \"\"\"Preprocess entire config tree.\n\n        Main entry point - walks config tree recursively and applies\n        all preprocessing transformations.\n\n        Args:\n            config: Raw config structure to process\n            base_data: Root config dict (for resolving local macros)\n            id: Current ID path in tree (for relative ID resolution)\n\n        Returns:\n            Preprocessed config ready for parsing\n\n        Raises:\n            ValueError: If circular raw reference detected\n        \"\"\"\n        return self._process_recursive(config, base_data, id, set())\n\n    def _process_recursive(\n        self,\n        config: Any,\n        base_data: dict,\n        id: str,\n        raw_ref_stack: set[str],\n    ) -&gt; Any:\n        \"\"\"Internal recursive preprocessing implementation.\n\n        Args:\n            config: Current config node\n            base_data: Root config dict\n            id: Current ID path\n            raw_ref_stack: Circular reference detection\n\n        Returns:\n            Preprocessed config\n        \"\"\"\n        # Recursively process nested structures\n        if isinstance(config, dict):\n            for key in list(config.keys()):\n                sub_id = f\"{id}{ID_SEP_KEY}{key}\" if id else str(key)\n                config[key] = self._process_recursive(config[key], base_data, sub_id, raw_ref_stack)\n\n        elif isinstance(config, list):\n            for idx in range(len(config)):\n                sub_id = f\"{id}{ID_SEP_KEY}{idx}\" if id else str(idx)\n                config[idx] = self._process_recursive(config[idx], base_data, sub_id, raw_ref_stack)\n\n        # Process string values\n        if isinstance(config, str):\n            # Step 1: Resolve relative IDs (@::, @::::) to absolute (@)\n            config = resolve_relative_ids(id, config)\n\n            # Step 2: Expand raw references (%)\n            if config.startswith(RAW_REF_KEY):\n                config = self._expand_raw_ref(config, base_data, raw_ref_stack)\n\n        return config\n\n    def _expand_raw_ref(self, raw_ref: str, base_data: dict, raw_ref_stack: set[str]) -&gt; Any:\n        \"\"\"Expand a single raw reference by loading external file or local YAML.\n\n        Args:\n            raw_ref: Raw reference string (e.g., \"%file.yaml::key\" or \"%key\")\n            base_data: Root config for local raw references\n            raw_ref_stack: Circular reference detection\n\n        Returns:\n            Value from raw reference (deep copied)\n\n        Raises:\n            ValueError: If circular reference detected\n        \"\"\"\n        # Circular reference check\n        if raw_ref in raw_ref_stack:\n            chain = \" -&gt; \".join(sorted(raw_ref_stack))\n            raise ValueError(f\"Circular raw reference detected: '{raw_ref}'\\nRaw reference chain: {chain} -&gt; {raw_ref}\")\n\n        # Parse: \"%file.yaml::key\" \u2192 (\"file.yaml\", \"key\")\n        path, ids = split_file_and_id(raw_ref[len(RAW_REF_KEY) :])\n\n        raw_ref_stack.add(raw_ref)\n\n        try:\n            # Load config (external file or local)\n            if not path:\n                loaded_config = base_data  # Local raw reference: %key\n            else:\n                loaded_config, _ = self.loader.load_file(path)  # External: %file.yaml::key\n\n            # Navigate to referenced value\n            result = self._get_by_id(loaded_config, ids)\n\n            # Recursively preprocess the loaded value\n            result = self._process_recursive(result, loaded_config, ids, raw_ref_stack)\n\n            # Deep copy for independence\n            return deepcopy(result)\n\n        finally:\n            raw_ref_stack.discard(raw_ref)\n\n    @staticmethod\n    def _get_by_id(config: dict, id: str) -&gt; Any:\n        \"\"\"Navigate config dict by ID path.\n\n        Args:\n            config: Config dict to navigate\n            id: ID path (e.g., \"model::optimizer::lr\")\n\n        Returns:\n            Value at ID path\n\n        Raises:\n            KeyError: If path not found\n            TypeError: If trying to index non-dict/list\n        \"\"\"\n        if not id:\n            return config\n\n        current = config\n        for key in split_id(id):\n            if isinstance(current, dict):\n                current = current[key]\n            elif isinstance(current, list):\n                current = current[int(key)]\n            else:\n                raise TypeError(f\"Cannot index {type(current).__name__} with key '{key}' at path '{id}'\")\n\n        return current\n</code></pre>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--result","title":"Result:","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--_1","title":"{","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--lr-0001","title":"\"lr\": 0.001,","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--base-00005-loaded-from-defaultsyaml","title":"\"base\": 0.0005,  # Loaded from defaults.yaml","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--model","title":"\"model\": {","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--lr-modellr-converted-to-absolute","title":"\"lr\": \"@model::lr\"  # Converted to absolute","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--_2","title":"}","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor--_3","title":"}","text":""},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor.__init__","title":"<code>__init__(loader, globals=None)</code>","text":"<p>Initialize preprocessor.</p> <p>Parameters:</p> Name Type Description Default <code>loader</code> <p>Loader instance for loading external raw reference files</p> required <code>globals</code> <code>dict[str, Any] | None</code> <p>Global context (unused here, kept for API consistency)</p> <code>None</code> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>def __init__(self, loader, globals: dict[str, Any] | None = None):\n    \"\"\"Initialize preprocessor.\n\n    Args:\n        loader: Loader instance for loading external raw reference files\n        globals: Global context (unused here, kept for API consistency)\n    \"\"\"\n    self.loader = loader\n    self.globals = globals or {}\n</code></pre>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor._expand_raw_ref","title":"<code>_expand_raw_ref(raw_ref, base_data, raw_ref_stack)</code>","text":"<p>Expand a single raw reference by loading external file or local YAML.</p> <p>Parameters:</p> Name Type Description Default <code>raw_ref</code> <code>str</code> <p>Raw reference string (e.g., \"%file.yaml::key\" or \"%key\")</p> required <code>base_data</code> <code>dict</code> <p>Root config for local raw references</p> required <code>raw_ref_stack</code> <code>set[str]</code> <p>Circular reference detection</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Value from raw reference (deep copied)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If circular reference detected</p> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>def _expand_raw_ref(self, raw_ref: str, base_data: dict, raw_ref_stack: set[str]) -&gt; Any:\n    \"\"\"Expand a single raw reference by loading external file or local YAML.\n\n    Args:\n        raw_ref: Raw reference string (e.g., \"%file.yaml::key\" or \"%key\")\n        base_data: Root config for local raw references\n        raw_ref_stack: Circular reference detection\n\n    Returns:\n        Value from raw reference (deep copied)\n\n    Raises:\n        ValueError: If circular reference detected\n    \"\"\"\n    # Circular reference check\n    if raw_ref in raw_ref_stack:\n        chain = \" -&gt; \".join(sorted(raw_ref_stack))\n        raise ValueError(f\"Circular raw reference detected: '{raw_ref}'\\nRaw reference chain: {chain} -&gt; {raw_ref}\")\n\n    # Parse: \"%file.yaml::key\" \u2192 (\"file.yaml\", \"key\")\n    path, ids = split_file_and_id(raw_ref[len(RAW_REF_KEY) :])\n\n    raw_ref_stack.add(raw_ref)\n\n    try:\n        # Load config (external file or local)\n        if not path:\n            loaded_config = base_data  # Local raw reference: %key\n        else:\n            loaded_config, _ = self.loader.load_file(path)  # External: %file.yaml::key\n\n        # Navigate to referenced value\n        result = self._get_by_id(loaded_config, ids)\n\n        # Recursively preprocess the loaded value\n        result = self._process_recursive(result, loaded_config, ids, raw_ref_stack)\n\n        # Deep copy for independence\n        return deepcopy(result)\n\n    finally:\n        raw_ref_stack.discard(raw_ref)\n</code></pre>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor._get_by_id","title":"<code>_get_by_id(config, id)</code>  <code>staticmethod</code>","text":"<p>Navigate config dict by ID path.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Config dict to navigate</p> required <code>id</code> <code>str</code> <p>ID path (e.g., \"model::optimizer::lr\")</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Value at ID path</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If path not found</p> <code>TypeError</code> <p>If trying to index non-dict/list</p> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>@staticmethod\ndef _get_by_id(config: dict, id: str) -&gt; Any:\n    \"\"\"Navigate config dict by ID path.\n\n    Args:\n        config: Config dict to navigate\n        id: ID path (e.g., \"model::optimizer::lr\")\n\n    Returns:\n        Value at ID path\n\n    Raises:\n        KeyError: If path not found\n        TypeError: If trying to index non-dict/list\n    \"\"\"\n    if not id:\n        return config\n\n    current = config\n    for key in split_id(id):\n        if isinstance(current, dict):\n            current = current[key]\n        elif isinstance(current, list):\n            current = current[int(key)]\n        else:\n            raise TypeError(f\"Cannot index {type(current).__name__} with key '{key}' at path '{id}'\")\n\n    return current\n</code></pre>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor._process_recursive","title":"<code>_process_recursive(config, base_data, id, raw_ref_stack)</code>","text":"<p>Internal recursive preprocessing implementation.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Current config node</p> required <code>base_data</code> <code>dict</code> <p>Root config dict</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>raw_ref_stack</code> <code>set[str]</code> <p>Circular reference detection</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Preprocessed config</p> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>def _process_recursive(\n    self,\n    config: Any,\n    base_data: dict,\n    id: str,\n    raw_ref_stack: set[str],\n) -&gt; Any:\n    \"\"\"Internal recursive preprocessing implementation.\n\n    Args:\n        config: Current config node\n        base_data: Root config dict\n        id: Current ID path\n        raw_ref_stack: Circular reference detection\n\n    Returns:\n        Preprocessed config\n    \"\"\"\n    # Recursively process nested structures\n    if isinstance(config, dict):\n        for key in list(config.keys()):\n            sub_id = f\"{id}{ID_SEP_KEY}{key}\" if id else str(key)\n            config[key] = self._process_recursive(config[key], base_data, sub_id, raw_ref_stack)\n\n    elif isinstance(config, list):\n        for idx in range(len(config)):\n            sub_id = f\"{id}{ID_SEP_KEY}{idx}\" if id else str(idx)\n            config[idx] = self._process_recursive(config[idx], base_data, sub_id, raw_ref_stack)\n\n    # Process string values\n    if isinstance(config, str):\n        # Step 1: Resolve relative IDs (@::, @::::) to absolute (@)\n        config = resolve_relative_ids(id, config)\n\n        # Step 2: Expand raw references (%)\n        if config.startswith(RAW_REF_KEY):\n            config = self._expand_raw_ref(config, base_data, raw_ref_stack)\n\n    return config\n</code></pre>"},{"location":"reference/preprocessor/#sparkwheel.preprocessor.Preprocessor.process","title":"<code>process(config, base_data, id='')</code>","text":"<p>Preprocess entire config tree.</p> <p>Main entry point - walks config tree recursively and applies all preprocessing transformations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Raw config structure to process</p> required <code>base_data</code> <code>dict</code> <p>Root config dict (for resolving local macros)</p> required <code>id</code> <code>str</code> <p>Current ID path in tree (for relative ID resolution)</p> <code>''</code> <p>Returns:</p> Type Description <code>Any</code> <p>Preprocessed config ready for parsing</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If circular raw reference detected</p> Source code in <code>src/sparkwheel/preprocessor.py</code> <pre><code>def process(self, config: Any, base_data: dict, id: str = \"\") -&gt; Any:\n    \"\"\"Preprocess entire config tree.\n\n    Main entry point - walks config tree recursively and applies\n    all preprocessing transformations.\n\n    Args:\n        config: Raw config structure to process\n        base_data: Root config dict (for resolving local macros)\n        id: Current ID path in tree (for relative ID resolution)\n\n    Returns:\n        Preprocessed config ready for parsing\n\n    Raises:\n        ValueError: If circular raw reference detected\n    \"\"\"\n    return self._process_recursive(config, base_data, id, set())\n</code></pre>"},{"location":"reference/resolver/","title":"resolver","text":"<p>Resolve references between Items.</p>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver","title":"<code>Resolver</code>","text":"<p>Resolve references between Items.</p> <p>Manages Items and resolves resolved reference strings (starting with @) by substituting them with their corresponding resolved values (instantiated objects, evaluated expressions, etc.).</p> Example <pre><code>from sparkwheel import Item, Component, Resolver\n\nresolver = Resolver()\n\n# Add items\nresolver.add_item(Item(config=0.001, id=\"lr\"))\nresolver.add_item(Item(config={\"lr\": \"@lr\"}, id=\"config\"))\n\n# Resolve\nresult = resolver.resolve(\"config\")\nprint(result)  # {\"lr\": 0.001}\n</code></pre> <p>Resolved references can use :: separator for nested access: - Dictionary keys: @config::subkey - List indices: @list::0::subitem</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>class Resolver:\n    \"\"\"Resolve references between Items.\n\n    Manages Items and resolves resolved reference strings (starting with @) by\n    substituting them with their corresponding resolved values (instantiated objects,\n    evaluated expressions, etc.).\n\n    Example:\n        ```python\n        from sparkwheel import Item, Component, Resolver\n\n        resolver = Resolver()\n\n        # Add items\n        resolver.add_item(Item(config=0.001, id=\"lr\"))\n        resolver.add_item(Item(config={\"lr\": \"@lr\"}, id=\"config\"))\n\n        # Resolve\n        result = resolver.resolve(\"config\")\n        print(result)  # {\"lr\": 0.001}\n        ```\n\n    Resolved references can use :: separator for nested access:\n    - Dictionary keys: @config::key::subkey\n    - List indices: @list::0::subitem\n    \"\"\"\n\n    _vars = \"__local_refs\"  # Variable name for resolved refs in expression evaluation\n    sep = ID_SEP_KEY  # Separator for nested key access\n    ref = RESOLVED_REF_KEY  # Resolved reference prefix (@)\n    allow_missing_reference = allow_missing_reference\n    max_resolution_depth = 100  # Prevent DoS from deeply nested references\n\n    def __init__(self, items: list[Item] | None = None):\n        \"\"\"Initialize resolver with optional items.\n\n        Args:\n            items: Optional list of Items to add during initialization\n        \"\"\"\n        self._items: dict[str, Item] = {}\n        self._resolved: dict[str, Any] = {}\n\n        if items:\n            for item in items:\n                self.add_item(item)\n\n    def reset(self) -&gt; None:\n        \"\"\"Clear all items and resolved content.\"\"\"\n        self._items = {}\n        self._resolved = {}\n\n    def is_resolved(self) -&gt; bool:\n        \"\"\"Check if any items have been resolved.\"\"\"\n        return bool(self._resolved)\n\n    def add_item(self, item: Item) -&gt; None:\n        \"\"\"Add a Item to resolve.\n\n        Args:\n            item: Item to add\n        \"\"\"\n        id = item.get_id()\n        if id in self._items:\n            warnings.warn(\n                f\"Duplicate config item ID '{id}' detected. \"\n                f\"The new item will be ignored and the existing item will be kept. \"\n                f\"This may indicate a configuration error.\",\n                UserWarning,\n                stacklevel=2,\n            )\n            return\n        self._items[id] = item\n\n    def add_items(self, items: list[Item]) -&gt; None:\n        \"\"\"Add multiple Items at once.\n\n        Args:\n            items: List of Items to add\n        \"\"\"\n        for item in items:\n            self.add_item(item)\n\n    def get_item(self, id: str, resolve: bool = False, **kwargs: Any) -&gt; Item | None:\n        \"\"\"Get Item by id, optionally resolved.\n\n        Args:\n            id: ID of the config item\n            resolve: Whether to resolve the item (default: False)\n            **kwargs: Additional arguments for resolution\n\n        Returns:\n            Item if found, None otherwise (or resolved value if resolve=True)\n        \"\"\"\n        id = self.normalize_id(id)\n        if resolve and id not in self._resolved:\n            self._resolve_one_item(id=id, **kwargs)\n        return self._items.get(id)\n\n    def resolve(\n        self,\n        id: str = \"\",\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Resolve a config item and return the result.\n\n        Resolves all references, instantiates components (if requested), and\n        evaluates expressions (if requested). Results are cached for efficiency.\n\n        Args:\n            id: ID of item to resolve (empty string for root)\n            instantiate: Whether to instantiate components with _target_\n            eval_expr: Whether to evaluate expressions starting with $\n            default: Default value if id not found\n\n        Returns:\n            Resolved value (instantiated object, evaluated result, or raw value)\n\n        Raises:\n            ConfigKeyError: If id not found and no default provided\n            CircularReferenceError: If circular reference detected\n        \"\"\"\n        return self._resolve_one_item(id=id, instantiate=instantiate, eval_expr=eval_expr, default=default)\n\n    def _resolve_one_item(\n        self,\n        id: str,\n        waiting_list: set[str] | None = None,\n        _depth: int = 0,\n        instantiate: bool = True,\n        eval_expr: bool = True,\n        default: Any = None,\n    ) -&gt; Any:\n        \"\"\"Internal recursive resolution implementation.\n\n        Args:\n            id: ID to resolve\n            waiting_list: Set of IDs currently being resolved (for cycle detection)\n            _depth: Current recursion depth (for DoS prevention)\n            instantiate: Whether to instantiate components\n            eval_expr: Whether to evaluate expressions\n            default: Default value if not found\n\n        Returns:\n            Resolved value\n\n        Raises:\n            RecursionError: If max depth exceeded\n            CircularReferenceError: If circular reference detected\n            ConfigKeyError: If reference not found\n        \"\"\"\n        # Prevent stack overflow attacks\n        if _depth &gt;= self.max_resolution_depth:\n            raise RecursionError(\n                f\"Maximum reference resolution depth ({self.max_resolution_depth}) exceeded while resolving '{id}'. \"\n                f\"This may indicate an overly complex configuration or a potential DoS attack.\"\n            )\n\n        id = self.normalize_id(id)\n\n        # Return cached result if available\n        if id in self._resolved:\n            return self._resolved[id]\n\n        # Look up the item\n        try:\n            item = look_up_option(id, self._items, print_all_options=False, default=default or \"no_default\")\n        except ValueError as err:\n            # Provide helpful error with suggestions\n            source_location = None\n            for config_item in self._items.values():\n                if hasattr(config_item, \"source_location\") and config_item.source_location:\n                    source_location = config_item.source_location\n                    break\n\n            available_keys = list(self._items.keys())\n            config_context = None\n\n            # For nested IDs, try to get parent context to show available keys\n            if ID_SEP_KEY in id:\n                parent_id = ID_SEP_KEY.join(id.split(ID_SEP_KEY)[:-1])\n                try:\n                    parent_item = self.get_item(parent_id)\n                    if parent_item and isinstance(parent_item.get_config(), dict):\n                        config_context = parent_item.get_config()\n                except (ValueError, KeyError):\n                    pass\n\n            raise ConfigKeyError(\n                f\"Config ID '{id}' not found in the configuration\",\n                source_location=source_location,\n                missing_key=id,\n                available_keys=available_keys,\n                config_context=config_context,\n            ) from err\n\n        # If default was returned, just return it\n        if not isinstance(item, Item):\n            return item\n\n        item_config = item.get_config()\n\n        # Initialize waiting list for circular reference detection\n        if waiting_list is None:\n            waiting_list = set()\n        waiting_list.add(id)\n\n        # First, resolve any import expressions (they need to run first)\n        for t, v in self._items.items():\n            if t not in self._resolved and isinstance(v, Expression) and v.is_import_statement(v.get_config()):\n                self._resolved[t] = v.evaluate() if eval_expr else v\n\n        # Find all references in this item's config\n        refs = self.find_refs_in_config(config=item_config, id=id)\n\n        # Resolve dependencies first\n        for dep_id in refs.keys():\n            # Check for circular references\n            if dep_id in waiting_list:\n                raise CircularReferenceError(\n                    f\"Circular reference detected: '{dep_id}' references back to '{id}'\",\n                    source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                )\n\n            # Resolve dependency if not already resolved\n            if dep_id not in self._resolved:\n                try:\n                    look_up_option(dep_id, self._items, print_all_options=False)\n                except ValueError as err:\n                    msg = f\"the referring item `@{dep_id}` is not defined in the config content.\"\n                    if not self.allow_missing_reference:\n                        available_keys = list(self._items.keys())\n                        raise ConfigKeyError(\n                            f\"Reference '@{dep_id}' not found in configuration\",\n                            source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                            missing_key=dep_id,\n                            available_keys=available_keys,\n                        ) from err\n                    warnings.warn(msg, stacklevel=2)\n                    continue\n\n                # Recursively resolve dependency\n                self._resolve_one_item(\n                    id=dep_id,\n                    waiting_list=waiting_list,\n                    _depth=_depth + 1,\n                    instantiate=instantiate,\n                    eval_expr=eval_expr,\n                )\n                waiting_list.discard(dep_id)\n\n        # All dependencies resolved, now resolve this item\n        new_config = self.update_config_with_refs(config=item_config, id=id, refs=self._resolved)\n        item.update_config(config=new_config)\n\n        # Generate final resolved value based on item type\n        if isinstance(item, Component):\n            self._resolved[id] = item.instantiate() if instantiate else item\n        elif isinstance(item, Expression):\n            self._resolved[id] = item.evaluate(globals={f\"{self._vars}\": self._resolved}) if eval_expr else item\n        else:\n            self._resolved[id] = new_config\n\n        return self._resolved[id]\n\n    @classmethod\n    def normalize_id(cls, id: str | int) -&gt; str:\n        \"\"\"Normalize ID to string format.\n\n        Args:\n            id: ID to normalize\n\n        Returns:\n            String ID\n        \"\"\"\n        return str(id)\n\n    @classmethod\n    def split_id(cls, id: str | int, last: bool = False) -&gt; list[str]:\n        \"\"\"Split ID string by separator.\n\n        Args:\n            id: ID to split\n            last: If True, only split rightmost part\n\n        Returns:\n            List of ID components\n        \"\"\"\n        if not last:\n            return cls.normalize_id(id).split(cls.sep)\n        res = cls.normalize_id(id).rsplit(cls.sep, 1)\n        return [\"\".join(res[:-1]), res[-1]]\n\n    @classmethod\n    def iter_subconfigs(cls, id: str, config: Any) -&gt; Iterator[tuple[str, str, Any]]:\n        \"\"\"Iterate over sub-configs with IDs.\n\n        Args:\n            id: Current ID path\n            config: Config to iterate (dict or list)\n\n        Yields:\n            Tuples of (key, sub_id, value)\n        \"\"\"\n        for k, v in config.items() if isinstance(config, dict) else enumerate(config):\n            sub_id = f\"{id}{cls.sep}{k}\" if id != \"\" else f\"{k}\"\n            yield k, sub_id, v\n\n    @classmethod\n    def match_refs_pattern(cls, value: str) -&gt; dict[str, int]:\n        \"\"\"Find reference patterns in a string.\n\n        Args:\n            value: String to search for references\n\n        Returns:\n            Dict mapping reference IDs to occurrence counts\n        \"\"\"\n        value = normalize_id(value)\n        return scan_references(value)\n\n    @classmethod\n    def update_refs_pattern(cls, value: str, refs: dict) -&gt; str:\n        \"\"\"Replace reference patterns with resolved values.\n\n        Args:\n            value: String containing references\n            refs: Dict of resolved references\n\n        Returns:\n            String with references replaced\n        \"\"\"\n        value = normalize_id(value)\n\n        try:\n            return replace_references(value, refs, cls._vars)\n        except KeyError as e:\n            # Extract reference ID from error message\n            # The error message format is: \"Reference '@ref_id' not found in resolved references\"\n            ref_id = str(e).split(\"'\")[1].lstrip(\"@\")\n            msg = f\"can not find expected ID '{ref_id}' in the references.\"\n            if not cls.allow_missing_reference:\n                raise KeyError(msg) from e\n            warnings.warn(msg, stacklevel=2)\n            return value\n\n    @classmethod\n    def find_refs_in_config(cls, config: Any, id: str, refs: dict[str, int] | None = None) -&gt; dict[str, int]:\n        \"\"\"Recursively find all references in config.\n\n        Args:\n            config: Config to search\n            id: Current ID path\n            refs: Accumulated references dict\n\n        Returns:\n            Dict of reference IDs to counts\n        \"\"\"\n        refs_ = refs or {}\n\n        # Check string values for reference patterns\n        if isinstance(config, str):\n            for ref_id, count in cls.match_refs_pattern(value=config).items():\n                refs_[ref_id] = refs_.get(ref_id, 0) + count\n\n        # Recursively search nested structures\n        if isinstance(config, (list, dict)):\n            for _, sub_id, v in cls.iter_subconfigs(id, config):\n                # Instantiable and expression items are also dependencies\n                if (Component.is_instantiable(v) or Expression.is_expression(v)) and sub_id not in refs_:\n                    refs_[sub_id] = 1\n                refs_ = cls.find_refs_in_config(v, sub_id, refs_)\n\n        return refs_\n\n    @classmethod\n    def update_config_with_refs(cls, config: Any, id: str, refs: dict | None = None) -&gt; Any:\n        \"\"\"Update config by replacing references with resolved values.\n\n        Args:\n            config: Config to update\n            id: Current ID path\n            refs: Dict of resolved references\n\n        Returns:\n            Config with references replaced\n        \"\"\"\n        refs_ = refs or {}\n\n        # Replace references in strings\n        if isinstance(config, str):\n            return cls.update_refs_pattern(config, refs_)\n\n        # Return non-container types as-is\n        if not isinstance(config, (list, dict)):\n            return config\n\n        # Recursively update nested structures\n        ret = type(config)()\n        for idx, sub_id, v in cls.iter_subconfigs(id, config):\n            if Component.is_instantiable(v) or Expression.is_expression(v):\n                updated = refs_[sub_id]\n                # Skip disabled components\n                if Component.is_instantiable(v) and updated is None:\n                    continue\n            else:\n                updated = cls.update_config_with_refs(v, sub_id, refs_)\n\n            if isinstance(ret, dict):\n                ret[idx] = updated\n            else:\n                ret.append(updated)\n\n        return ret\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.__init__","title":"<code>__init__(items=None)</code>","text":"<p>Initialize resolver with optional items.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[Item] | None</code> <p>Optional list of Items to add during initialization</p> <code>None</code> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def __init__(self, items: list[Item] | None = None):\n    \"\"\"Initialize resolver with optional items.\n\n    Args:\n        items: Optional list of Items to add during initialization\n    \"\"\"\n    self._items: dict[str, Item] = {}\n    self._resolved: dict[str, Any] = {}\n\n    if items:\n        for item in items:\n            self.add_item(item)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver._resolve_one_item","title":"<code>_resolve_one_item(id, waiting_list=None, _depth=0, instantiate=True, eval_expr=True, default=None)</code>","text":"<p>Internal recursive resolution implementation.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID to resolve</p> required <code>waiting_list</code> <code>set[str] | None</code> <p>Set of IDs currently being resolved (for cycle detection)</p> <code>None</code> <code>_depth</code> <code>int</code> <p>Current recursion depth (for DoS prevention)</p> <code>0</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate expressions</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value</p> <p>Raises:</p> Type Description <code>RecursionError</code> <p>If max depth exceeded</p> <code>CircularReferenceError</code> <p>If circular reference detected</p> <code>ConfigKeyError</code> <p>If reference not found</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def _resolve_one_item(\n    self,\n    id: str,\n    waiting_list: set[str] | None = None,\n    _depth: int = 0,\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Internal recursive resolution implementation.\n\n    Args:\n        id: ID to resolve\n        waiting_list: Set of IDs currently being resolved (for cycle detection)\n        _depth: Current recursion depth (for DoS prevention)\n        instantiate: Whether to instantiate components\n        eval_expr: Whether to evaluate expressions\n        default: Default value if not found\n\n    Returns:\n        Resolved value\n\n    Raises:\n        RecursionError: If max depth exceeded\n        CircularReferenceError: If circular reference detected\n        ConfigKeyError: If reference not found\n    \"\"\"\n    # Prevent stack overflow attacks\n    if _depth &gt;= self.max_resolution_depth:\n        raise RecursionError(\n            f\"Maximum reference resolution depth ({self.max_resolution_depth}) exceeded while resolving '{id}'. \"\n            f\"This may indicate an overly complex configuration or a potential DoS attack.\"\n        )\n\n    id = self.normalize_id(id)\n\n    # Return cached result if available\n    if id in self._resolved:\n        return self._resolved[id]\n\n    # Look up the item\n    try:\n        item = look_up_option(id, self._items, print_all_options=False, default=default or \"no_default\")\n    except ValueError as err:\n        # Provide helpful error with suggestions\n        source_location = None\n        for config_item in self._items.values():\n            if hasattr(config_item, \"source_location\") and config_item.source_location:\n                source_location = config_item.source_location\n                break\n\n        available_keys = list(self._items.keys())\n        config_context = None\n\n        # For nested IDs, try to get parent context to show available keys\n        if ID_SEP_KEY in id:\n            parent_id = ID_SEP_KEY.join(id.split(ID_SEP_KEY)[:-1])\n            try:\n                parent_item = self.get_item(parent_id)\n                if parent_item and isinstance(parent_item.get_config(), dict):\n                    config_context = parent_item.get_config()\n            except (ValueError, KeyError):\n                pass\n\n        raise ConfigKeyError(\n            f\"Config ID '{id}' not found in the configuration\",\n            source_location=source_location,\n            missing_key=id,\n            available_keys=available_keys,\n            config_context=config_context,\n        ) from err\n\n    # If default was returned, just return it\n    if not isinstance(item, Item):\n        return item\n\n    item_config = item.get_config()\n\n    # Initialize waiting list for circular reference detection\n    if waiting_list is None:\n        waiting_list = set()\n    waiting_list.add(id)\n\n    # First, resolve any import expressions (they need to run first)\n    for t, v in self._items.items():\n        if t not in self._resolved and isinstance(v, Expression) and v.is_import_statement(v.get_config()):\n            self._resolved[t] = v.evaluate() if eval_expr else v\n\n    # Find all references in this item's config\n    refs = self.find_refs_in_config(config=item_config, id=id)\n\n    # Resolve dependencies first\n    for dep_id in refs.keys():\n        # Check for circular references\n        if dep_id in waiting_list:\n            raise CircularReferenceError(\n                f\"Circular reference detected: '{dep_id}' references back to '{id}'\",\n                source_location=item.source_location if hasattr(item, \"source_location\") else None,\n            )\n\n        # Resolve dependency if not already resolved\n        if dep_id not in self._resolved:\n            try:\n                look_up_option(dep_id, self._items, print_all_options=False)\n            except ValueError as err:\n                msg = f\"the referring item `@{dep_id}` is not defined in the config content.\"\n                if not self.allow_missing_reference:\n                    available_keys = list(self._items.keys())\n                    raise ConfigKeyError(\n                        f\"Reference '@{dep_id}' not found in configuration\",\n                        source_location=item.source_location if hasattr(item, \"source_location\") else None,\n                        missing_key=dep_id,\n                        available_keys=available_keys,\n                    ) from err\n                warnings.warn(msg, stacklevel=2)\n                continue\n\n            # Recursively resolve dependency\n            self._resolve_one_item(\n                id=dep_id,\n                waiting_list=waiting_list,\n                _depth=_depth + 1,\n                instantiate=instantiate,\n                eval_expr=eval_expr,\n            )\n            waiting_list.discard(dep_id)\n\n    # All dependencies resolved, now resolve this item\n    new_config = self.update_config_with_refs(config=item_config, id=id, refs=self._resolved)\n    item.update_config(config=new_config)\n\n    # Generate final resolved value based on item type\n    if isinstance(item, Component):\n        self._resolved[id] = item.instantiate() if instantiate else item\n    elif isinstance(item, Expression):\n        self._resolved[id] = item.evaluate(globals={f\"{self._vars}\": self._resolved}) if eval_expr else item\n    else:\n        self._resolved[id] = new_config\n\n    return self._resolved[id]\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.add_item","title":"<code>add_item(item)</code>","text":"<p>Add a Item to resolve.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Item</code> <p>Item to add</p> required Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def add_item(self, item: Item) -&gt; None:\n    \"\"\"Add a Item to resolve.\n\n    Args:\n        item: Item to add\n    \"\"\"\n    id = item.get_id()\n    if id in self._items:\n        warnings.warn(\n            f\"Duplicate config item ID '{id}' detected. \"\n            f\"The new item will be ignored and the existing item will be kept. \"\n            f\"This may indicate a configuration error.\",\n            UserWarning,\n            stacklevel=2,\n        )\n        return\n    self._items[id] = item\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.add_items","title":"<code>add_items(items)</code>","text":"<p>Add multiple Items at once.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[Item]</code> <p>List of Items to add</p> required Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def add_items(self, items: list[Item]) -&gt; None:\n    \"\"\"Add multiple Items at once.\n\n    Args:\n        items: List of Items to add\n    \"\"\"\n    for item in items:\n        self.add_item(item)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.find_refs_in_config","title":"<code>find_refs_in_config(config, id, refs=None)</code>  <code>classmethod</code>","text":"<p>Recursively find all references in config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Config to search</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>refs</code> <code>dict[str, int] | None</code> <p>Accumulated references dict</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict of reference IDs to counts</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef find_refs_in_config(cls, config: Any, id: str, refs: dict[str, int] | None = None) -&gt; dict[str, int]:\n    \"\"\"Recursively find all references in config.\n\n    Args:\n        config: Config to search\n        id: Current ID path\n        refs: Accumulated references dict\n\n    Returns:\n        Dict of reference IDs to counts\n    \"\"\"\n    refs_ = refs or {}\n\n    # Check string values for reference patterns\n    if isinstance(config, str):\n        for ref_id, count in cls.match_refs_pattern(value=config).items():\n            refs_[ref_id] = refs_.get(ref_id, 0) + count\n\n    # Recursively search nested structures\n    if isinstance(config, (list, dict)):\n        for _, sub_id, v in cls.iter_subconfigs(id, config):\n            # Instantiable and expression items are also dependencies\n            if (Component.is_instantiable(v) or Expression.is_expression(v)) and sub_id not in refs_:\n                refs_[sub_id] = 1\n            refs_ = cls.find_refs_in_config(v, sub_id, refs_)\n\n    return refs_\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.get_item","title":"<code>get_item(id, resolve=False, **kwargs)</code>","text":"<p>Get Item by id, optionally resolved.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID of the config item</p> required <code>resolve</code> <code>bool</code> <p>Whether to resolve the item (default: False)</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for resolution</p> <code>{}</code> <p>Returns:</p> Type Description <code>Item | None</code> <p>Item if found, None otherwise (or resolved value if resolve=True)</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def get_item(self, id: str, resolve: bool = False, **kwargs: Any) -&gt; Item | None:\n    \"\"\"Get Item by id, optionally resolved.\n\n    Args:\n        id: ID of the config item\n        resolve: Whether to resolve the item (default: False)\n        **kwargs: Additional arguments for resolution\n\n    Returns:\n        Item if found, None otherwise (or resolved value if resolve=True)\n    \"\"\"\n    id = self.normalize_id(id)\n    if resolve and id not in self._resolved:\n        self._resolve_one_item(id=id, **kwargs)\n    return self._items.get(id)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.is_resolved","title":"<code>is_resolved()</code>","text":"<p>Check if any items have been resolved.</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def is_resolved(self) -&gt; bool:\n    \"\"\"Check if any items have been resolved.\"\"\"\n    return bool(self._resolved)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.iter_subconfigs","title":"<code>iter_subconfigs(id, config)</code>  <code>classmethod</code>","text":"<p>Iterate over sub-configs with IDs.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Current ID path</p> required <code>config</code> <code>Any</code> <p>Config to iterate (dict or list)</p> required <p>Yields:</p> Type Description <code>tuple[str, str, Any]</code> <p>Tuples of (key, sub_id, value)</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef iter_subconfigs(cls, id: str, config: Any) -&gt; Iterator[tuple[str, str, Any]]:\n    \"\"\"Iterate over sub-configs with IDs.\n\n    Args:\n        id: Current ID path\n        config: Config to iterate (dict or list)\n\n    Yields:\n        Tuples of (key, sub_id, value)\n    \"\"\"\n    for k, v in config.items() if isinstance(config, dict) else enumerate(config):\n        sub_id = f\"{id}{cls.sep}{k}\" if id != \"\" else f\"{k}\"\n        yield k, sub_id, v\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.match_refs_pattern","title":"<code>match_refs_pattern(value)</code>  <code>classmethod</code>","text":"<p>Find reference patterns in a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>String to search for references</p> required <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>Dict mapping reference IDs to occurrence counts</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef match_refs_pattern(cls, value: str) -&gt; dict[str, int]:\n    \"\"\"Find reference patterns in a string.\n\n    Args:\n        value: String to search for references\n\n    Returns:\n        Dict mapping reference IDs to occurrence counts\n    \"\"\"\n    value = normalize_id(value)\n    return scan_references(value)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.normalize_id","title":"<code>normalize_id(id)</code>  <code>classmethod</code>","text":"<p>Normalize ID to string format.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>ID to normalize</p> required <p>Returns:</p> Type Description <code>str</code> <p>String ID</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef normalize_id(cls, id: str | int) -&gt; str:\n    \"\"\"Normalize ID to string format.\n\n    Args:\n        id: ID to normalize\n\n    Returns:\n        String ID\n    \"\"\"\n    return str(id)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.reset","title":"<code>reset()</code>","text":"<p>Clear all items and resolved content.</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Clear all items and resolved content.\"\"\"\n    self._items = {}\n    self._resolved = {}\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.resolve","title":"<code>resolve(id='', instantiate=True, eval_expr=True, default=None)</code>","text":"<p>Resolve a config item and return the result.</p> <p>Resolves all references, instantiates components (if requested), and evaluates expressions (if requested). Results are cached for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>ID of item to resolve (empty string for root)</p> <code>''</code> <code>instantiate</code> <code>bool</code> <p>Whether to instantiate components with target</p> <code>True</code> <code>eval_expr</code> <code>bool</code> <p>Whether to evaluate expressions starting with $</p> <code>True</code> <code>default</code> <code>Any</code> <p>Default value if id not found</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Resolved value (instantiated object, evaluated result, or raw value)</p> <p>Raises:</p> Type Description <code>ConfigKeyError</code> <p>If id not found and no default provided</p> <code>CircularReferenceError</code> <p>If circular reference detected</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>def resolve(\n    self,\n    id: str = \"\",\n    instantiate: bool = True,\n    eval_expr: bool = True,\n    default: Any = None,\n) -&gt; Any:\n    \"\"\"Resolve a config item and return the result.\n\n    Resolves all references, instantiates components (if requested), and\n    evaluates expressions (if requested). Results are cached for efficiency.\n\n    Args:\n        id: ID of item to resolve (empty string for root)\n        instantiate: Whether to instantiate components with _target_\n        eval_expr: Whether to evaluate expressions starting with $\n        default: Default value if id not found\n\n    Returns:\n        Resolved value (instantiated object, evaluated result, or raw value)\n\n    Raises:\n        ConfigKeyError: If id not found and no default provided\n        CircularReferenceError: If circular reference detected\n    \"\"\"\n    return self._resolve_one_item(id=id, instantiate=instantiate, eval_expr=eval_expr, default=default)\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.split_id","title":"<code>split_id(id, last=False)</code>  <code>classmethod</code>","text":"<p>Split ID string by separator.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | int</code> <p>ID to split</p> required <code>last</code> <code>bool</code> <p>If True, only split rightmost part</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of ID components</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef split_id(cls, id: str | int, last: bool = False) -&gt; list[str]:\n    \"\"\"Split ID string by separator.\n\n    Args:\n        id: ID to split\n        last: If True, only split rightmost part\n\n    Returns:\n        List of ID components\n    \"\"\"\n    if not last:\n        return cls.normalize_id(id).split(cls.sep)\n    res = cls.normalize_id(id).rsplit(cls.sep, 1)\n    return [\"\".join(res[:-1]), res[-1]]\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.update_config_with_refs","title":"<code>update_config_with_refs(config, id, refs=None)</code>  <code>classmethod</code>","text":"<p>Update config by replacing references with resolved values.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Any</code> <p>Config to update</p> required <code>id</code> <code>str</code> <p>Current ID path</p> required <code>refs</code> <code>dict | None</code> <p>Dict of resolved references</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Config with references replaced</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef update_config_with_refs(cls, config: Any, id: str, refs: dict | None = None) -&gt; Any:\n    \"\"\"Update config by replacing references with resolved values.\n\n    Args:\n        config: Config to update\n        id: Current ID path\n        refs: Dict of resolved references\n\n    Returns:\n        Config with references replaced\n    \"\"\"\n    refs_ = refs or {}\n\n    # Replace references in strings\n    if isinstance(config, str):\n        return cls.update_refs_pattern(config, refs_)\n\n    # Return non-container types as-is\n    if not isinstance(config, (list, dict)):\n        return config\n\n    # Recursively update nested structures\n    ret = type(config)()\n    for idx, sub_id, v in cls.iter_subconfigs(id, config):\n        if Component.is_instantiable(v) or Expression.is_expression(v):\n            updated = refs_[sub_id]\n            # Skip disabled components\n            if Component.is_instantiable(v) and updated is None:\n                continue\n        else:\n            updated = cls.update_config_with_refs(v, sub_id, refs_)\n\n        if isinstance(ret, dict):\n            ret[idx] = updated\n        else:\n            ret.append(updated)\n\n    return ret\n</code></pre>"},{"location":"reference/resolver/#sparkwheel.resolver.Resolver.update_refs_pattern","title":"<code>update_refs_pattern(value, refs)</code>  <code>classmethod</code>","text":"<p>Replace reference patterns with resolved values.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>String containing references</p> required <code>refs</code> <code>dict</code> <p>Dict of resolved references</p> required <p>Returns:</p> Type Description <code>str</code> <p>String with references replaced</p> Source code in <code>src/sparkwheel/resolver.py</code> <pre><code>@classmethod\ndef update_refs_pattern(cls, value: str, refs: dict) -&gt; str:\n    \"\"\"Replace reference patterns with resolved values.\n\n    Args:\n        value: String containing references\n        refs: Dict of resolved references\n\n    Returns:\n        String with references replaced\n    \"\"\"\n    value = normalize_id(value)\n\n    try:\n        return replace_references(value, refs, cls._vars)\n    except KeyError as e:\n        # Extract reference ID from error message\n        # The error message format is: \"Reference '@ref_id' not found in resolved references\"\n        ref_id = str(e).split(\"'\")[1].lstrip(\"@\")\n        msg = f\"can not find expected ID '{ref_id}' in the references.\"\n        if not cls.allow_missing_reference:\n            raise KeyError(msg) from e\n        warnings.warn(msg, stacklevel=2)\n        return value\n</code></pre>"},{"location":"reference/schema/","title":"schema","text":"<p>Schema validation using dataclasses.</p> <p>This module provides structured config validation using Python dataclasses. Define configuration schemas with type hints, then validate your YAML configs against them at runtime.</p> Example <pre><code>from dataclasses import dataclass\nfrom typing import Optional\nfrom sparkwheel import Config\nfrom sparkwheel.schema import validate\n\n@dataclass\nclass OptimizerConfig:\n    lr: float\n    momentum: float = 0.9\n    weight_decay: Optional[float] = None\n\n@dataclass\nclass ModelConfig:\n    hidden_size: int\n    num_layers: int\n    dropout: float\n    optimizer: OptimizerConfig\n\n# Load and validate config\nconfig = Config.load(\"config.yaml\")\nvalidate(config.get(), ModelConfig)  # Raises error if invalid\n\n# Or validate during load\nconfig = Config.load(\"config.yaml\", schema=ModelConfig)\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when configuration validation fails.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Error description</p> <code>field_path</code> <p>Dot-separated path to the invalid field (e.g., \"model.optimizer.lr\")</p> <code>expected_type</code> <p>The type that was expected</p> <code>actual_value</code> <p>The value that failed validation</p> <code>source_location</code> <p>Optional location in source file where error occurred</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>class ValidationError(BaseError):\n    \"\"\"Raised when configuration validation fails.\n\n    Attributes:\n        message: Error description\n        field_path: Dot-separated path to the invalid field (e.g., \"model.optimizer.lr\")\n        expected_type: The type that was expected\n        actual_value: The value that failed validation\n        source_location: Optional location in source file where error occurred\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        field_path: str = \"\",\n        expected_type: type | None = None,\n        actual_value: Any = None,\n        source_location: SourceLocation | None = None,\n    ):\n        \"\"\"Initialize validation error.\n\n        Args:\n            message: Human-readable error message\n            field_path: Dot-separated path to invalid field\n            expected_type: Expected type for the field\n            actual_value: The actual value that failed validation\n            source_location: Source location where the invalid value was defined\n        \"\"\"\n        self.field_path = field_path\n        self.expected_type = expected_type\n        self.actual_value = actual_value\n\n        # Build detailed message\n        full_message = message\n        if field_path:\n            full_message = f\"Validation error at '{field_path}': {message}\"\n        if expected_type is not None:\n            type_name = getattr(expected_type, \"__name__\", str(expected_type))\n            full_message += f\"\\n  Expected type: {type_name}\"\n        if actual_value is not None:\n            actual_type = type(actual_value).__name__\n            full_message += f\"\\n  Actual type: {actual_type}\"\n            full_message += f\"\\n  Actual value: {actual_value!r}\"\n\n        super().__init__(full_message, source_location=source_location)\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema.ValidationError.__init__","title":"<code>__init__(message, field_path='', expected_type=None, actual_value=None, source_location=None)</code>","text":"<p>Initialize validation error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message</p> required <code>field_path</code> <code>str</code> <p>Dot-separated path to invalid field</p> <code>''</code> <code>expected_type</code> <code>type | None</code> <p>Expected type for the field</p> <code>None</code> <code>actual_value</code> <code>Any</code> <p>The actual value that failed validation</p> <code>None</code> <code>source_location</code> <code>SourceLocation | None</code> <p>Source location where the invalid value was defined</p> <code>None</code> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    field_path: str = \"\",\n    expected_type: type | None = None,\n    actual_value: Any = None,\n    source_location: SourceLocation | None = None,\n):\n    \"\"\"Initialize validation error.\n\n    Args:\n        message: Human-readable error message\n        field_path: Dot-separated path to invalid field\n        expected_type: Expected type for the field\n        actual_value: The actual value that failed validation\n        source_location: Source location where the invalid value was defined\n    \"\"\"\n    self.field_path = field_path\n    self.expected_type = expected_type\n    self.actual_value = actual_value\n\n    # Build detailed message\n    full_message = message\n    if field_path:\n        full_message = f\"Validation error at '{field_path}': {message}\"\n    if expected_type is not None:\n        type_name = getattr(expected_type, \"__name__\", str(expected_type))\n        full_message += f\"\\n  Expected type: {type_name}\"\n    if actual_value is not None:\n        actual_type = type(actual_value).__name__\n        full_message += f\"\\n  Actual type: {actual_type}\"\n        full_message += f\"\\n  Actual value: {actual_value!r}\"\n\n    super().__init__(full_message, source_location=source_location)\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._find_discriminator","title":"<code>_find_discriminator(union_types)</code>","text":"<p>Find discriminator field in a Union of dataclasses.</p> <p>A discriminator is a field that: - Exists in all dataclass types in the Union - Has Literal type annotation - Has unique values per type</p> <p>Parameters:</p> Name Type Description Default <code>union_types</code> <code>tuple</code> <p>Types in the Union</p> required <p>Returns:</p> Type Description <code>tuple[bool, str | None]</code> <p>(has_discriminator, field_name)</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _find_discriminator(union_types: tuple) -&gt; tuple[bool, str | None]:\n    \"\"\"Find discriminator field in a Union of dataclasses.\n\n    A discriminator is a field that:\n    - Exists in all dataclass types in the Union\n    - Has Literal type annotation\n    - Has unique values per type\n\n    Args:\n        union_types: Types in the Union\n\n    Returns:\n        (has_discriminator, field_name)\n    \"\"\"\n    from typing import Literal\n\n    # Filter to dataclasses only\n    dataclass_types = [t for t in union_types if dataclasses.is_dataclass(t)]\n    if len(dataclass_types) &lt; 2:\n        return False, None\n\n    # Find fields that exist in all types with Literal annotation\n    all_fields = {}\n    for dc_type in dataclass_types:\n        for f in dataclasses.fields(dc_type):\n            if get_origin(f.type) is Literal:\n                if f.name not in all_fields:\n                    all_fields[f.name] = []\n                literal_values = get_args(f.type)\n                all_fields[f.name].append({\"type\": dc_type, \"values\": literal_values})\n\n    # Find a field present in all types with unique values\n    for field_name, type_infos in all_fields.items():\n        if len(type_infos) != len(dataclass_types):\n            continue  # Not in all types\n\n        # Check values are unique across types\n        all_values = set()\n        is_unique = True\n        for info in type_infos:\n            for val in info[\"values\"]:\n                if val in all_values:\n                    is_unique = False\n                    break\n                all_values.add(val)\n            if not is_unique:\n                break\n\n        if is_unique:\n            return True, field_name\n\n    return False, None\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._format_union_type","title":"<code>_format_union_type(types_tuple)</code>","text":"<p>Format a tuple of types as Union[...] for error messages.</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _format_union_type(types_tuple: tuple) -&gt; str:\n    \"\"\"Format a tuple of types as Union[...] for error messages.\"\"\"\n    type_names = []\n    for t in types_tuple:\n        if hasattr(t, \"__name__\"):\n            type_names.append(t.__name__)\n        else:\n            type_names.append(str(t))\n    return f\"Union[{', '.join(type_names)}]\"\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._get_source_location","title":"<code>_get_source_location(metadata, field_path)</code>","text":"<p>Get source location from metadata registry.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>Any</code> <p>MetadataRegistry instance</p> required <code>field_path</code> <code>str</code> <p>Dot-separated field path to look up</p> required <p>Returns:</p> Type Description <code>SourceLocation | None</code> <p>SourceLocation if found, None otherwise</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _get_source_location(metadata: Any, field_path: str) -&gt; SourceLocation | None:\n    \"\"\"Get source location from metadata registry.\n\n    Args:\n        metadata: MetadataRegistry instance\n        field_path: Dot-separated field path to look up\n\n    Returns:\n        SourceLocation if found, None otherwise\n    \"\"\"\n    if metadata is None:\n        return None\n\n    try:\n        # Convert dot notation to :: notation used by sparkwheel\n        id_path = field_path.replace(\".\", \"::\")\n        return metadata.get(id_path)\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._get_validators","title":"<code>_get_validators(schema_type)</code>","text":"<p>Get all validator methods from a dataclass.</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _get_validators(schema_type: type) -&gt; list:\n    \"\"\"Get all validator methods from a dataclass.\"\"\"\n    validators = []\n    for attr_name in dir(schema_type):\n        if attr_name.startswith(\"_\"):\n            continue\n        try:\n            attr = getattr(schema_type, attr_name)\n            if callable(attr) and getattr(attr, \"__is_validator__\", False):\n                validators.append(attr)\n        except AttributeError:\n            continue\n    return validators\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._is_union_type","title":"<code>_is_union_type(origin)</code>","text":"<p>Check if origin is a Union type (handles both typing.Union and types.UnionType).</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _is_union_type(origin) -&gt; bool:\n    \"\"\"Check if origin is a Union type (handles both typing.Union and types.UnionType).\"\"\"\n    if origin is Union:\n        return True\n    # Python 3.10+ uses types.UnionType for X | Y syntax\n    if hasattr(types, \"UnionType\") and origin is types.UnionType:\n        return True\n    return False\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._run_validators","title":"<code>_run_validators(config, schema, field_path='', metadata=None)</code>","text":"<p>Run all @validator methods on a dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>Configuration dict</p> required <code>schema</code> <code>type</code> <p>Dataclass type</p> required <code>field_path</code> <code>str</code> <p>Path to this config</p> <code>''</code> <code>metadata</code> <code>Any</code> <p>Optional metadata</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _run_validators(\n    config: dict[str, Any],\n    schema: type,\n    field_path: str = \"\",\n    metadata: Any = None,\n) -&gt; None:\n    \"\"\"Run all @validator methods on a dataclass.\n\n    Args:\n        config: Configuration dict\n        schema: Dataclass type\n        field_path: Path to this config\n        metadata: Optional metadata\n\n    Raises:\n        ValidationError: If validation fails\n    \"\"\"\n    validators = _get_validators(schema)\n    if not validators:\n        return\n\n    # Skip validation for configs with references/expressions/macros\n    # They'll be validated after resolution\n    for value in config.values():\n        if isinstance(value, str) and value.startswith((\"@\", \"$\", \"%\")):\n            # Has unresolved references - skip custom validation\n            return\n\n    # Create instance to call validators on\n    try:\n        instance = schema(**config)\n    except Exception:\n        # Can't create instance - skip validation\n        return\n\n    source_loc = _get_source_location(metadata, field_path) if metadata else None\n\n    for validator_method in validators:\n        try:\n            validator_method(instance)\n        except ValueError as e:\n            raise ValidationError(\n                str(e),\n                field_path=field_path,\n                source_location=source_loc,\n            ) from e\n        except Exception as e:\n            raise ValidationError(\n                f\"Validator '{validator_method.__name__}' raised {type(e).__name__}: {e}\",\n                field_path=field_path,\n                source_location=source_loc,\n            ) from e\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._validate_discriminated_union","title":"<code>_validate_discriminated_union(value, union_types, discriminator_field, field_path, metadata=None)</code>","text":"<p>Validate a discriminated union by checking the discriminator.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>Value to validate (must be dict)</p> required <code>union_types</code> <code>tuple</code> <p>Types in the Union</p> required <code>discriminator_field</code> <code>str</code> <p>Name of discriminator field</p> required <code>field_path</code> <code>str</code> <p>Path to field</p> required <code>metadata</code> <code>Any</code> <p>Optional metadata</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _validate_discriminated_union(\n    value: Any,\n    union_types: tuple,\n    discriminator_field: str,\n    field_path: str,\n    metadata: Any = None,\n) -&gt; None:\n    \"\"\"Validate a discriminated union by checking the discriminator.\n\n    Args:\n        value: Value to validate (must be dict)\n        union_types: Types in the Union\n        discriminator_field: Name of discriminator field\n        field_path: Path to field\n        metadata: Optional metadata\n\n    Raises:\n        ValidationError: If validation fails\n    \"\"\"\n    source_loc = _get_source_location(metadata, field_path) if metadata else None\n\n    if not isinstance(value, dict):\n        raise ValidationError(\n            f\"Discriminated union requires dict, got {type(value).__name__}\",\n            field_path=field_path,\n            actual_value=value,\n            source_location=source_loc,\n        )\n\n    # Check discriminator field exists\n    if discriminator_field not in value:\n        dataclass_types = [t for t in union_types if dataclasses.is_dataclass(t)]\n        type_names = \", \".join(t.__name__ for t in dataclass_types)\n        raise ValidationError(\n            f\"Missing discriminator field '{discriminator_field}' (required for union of {type_names})\",\n            field_path=field_path,\n            actual_value=value,\n            source_location=source_loc,\n        )\n\n    discriminator_value = value[discriminator_field]\n\n    # Find matching type\n    dataclass_types = [t for t in union_types if dataclasses.is_dataclass(t)]\n    matching_type = None\n\n    for dc_type in dataclass_types:\n        for f in dataclasses.fields(dc_type):\n            if f.name == discriminator_field:\n                literal_values = get_args(f.type)\n                if discriminator_value in literal_values:\n                    matching_type = dc_type\n                    break\n        if matching_type:\n            break\n\n    if matching_type is None:\n        # Build helpful error with valid values\n        valid_values = []\n        for dc_type in dataclass_types:\n            for f in dataclasses.fields(dc_type):\n                if f.name == discriminator_field:\n                    literal_values = get_args(f.type)\n                    for val in literal_values:\n                        valid_values.append(f\"'{val}' ({dc_type.__name__})\")\n\n        valid_str = \", \".join(valid_values)\n        raise ValidationError(\n            f\"Invalid discriminator value '{discriminator_value}'. Valid: {valid_str}\",\n            field_path=field_path,\n            actual_value=value,\n            source_location=source_loc,\n        )\n\n    # Validate against the selected type\n    validate(value, matching_type, field_path, metadata)\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema._validate_field","title":"<code>_validate_field(value, expected_type, field_path, metadata=None)</code>","text":"<p>Validate a single field value against its expected type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to validate</p> required <code>expected_type</code> <code>type</code> <p>The expected type (may be generic like list[int])</p> required <code>field_path</code> <code>str</code> <p>Dot-separated path to this field</p> required <code>metadata</code> <code>Any</code> <p>Optional metadata registry for source locations</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails</p> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def _validate_field(\n    value: Any,\n    expected_type: type,\n    field_path: str,\n    metadata: Any = None,\n) -&gt; None:\n    \"\"\"Validate a single field value against its expected type.\n\n    Args:\n        value: The value to validate\n        expected_type: The expected type (may be generic like list[int])\n        field_path: Dot-separated path to this field\n        metadata: Optional metadata registry for source locations\n\n    Raises:\n        ValidationError: If validation fails\n    \"\"\"\n    source_loc = _get_source_location(metadata, field_path) if metadata else None\n\n    # Handle None values\n    origin = get_origin(expected_type)\n    args = get_args(expected_type)\n\n    # Handle Optional[T] (which is Union[T, None])\n    if _is_union_type(origin):\n        # Check for discriminated union first\n        has_discriminator, discriminator_field = _find_discriminator(args)\n        if has_discriminator and discriminator_field:\n            _validate_discriminated_union(value, args, discriminator_field, field_path, metadata)\n            return\n\n        # Check if None is allowed\n        if type(None) in args:\n            if value is None:\n                return  # None is valid\n            # Remove None from the union and validate against remaining types\n            non_none_types = [t for t in args if t is not type(None)]\n            if len(non_none_types) == 1:\n                # Simple Optional[T] case - recursively validate with the single type\n                _validate_field(value, non_none_types[0], field_path, metadata)\n                return\n            else:\n                # Union with multiple non-None types - try each and collect errors\n                errors = []\n                for union_type in non_none_types:\n                    try:\n                        _validate_field(value, union_type, field_path, metadata)\n                        return  # Validation succeeded\n                    except ValidationError as e:\n                        type_name = getattr(union_type, \"__name__\", str(union_type))\n                        # Extract just the error message without field path prefix\n                        error_msg = str(e).split(\"\\n\")[0]\n                        if f\"Validation error at '{field_path}': \" in error_msg:\n                            error_msg = error_msg.replace(f\"Validation error at '{field_path}': \", \"\")\n                        errors.append(f\"  Tried {type_name}: {error_msg}\")\n\n                # All failed - build comprehensive error message\n                union_str = _format_union_type(non_none_types)\n                error_details = \"\\n\".join(errors)\n                raise ValidationError(\n                    f\"Value doesn't match any type in {union_str}\\n{error_details}\",\n                    field_path=field_path,\n                    expected_type=expected_type,\n                    actual_value=value,\n                    source_location=source_loc,\n                )\n        else:\n            # Non-Optional Union - try each type and collect errors\n            errors = []\n            for union_type in args:\n                try:\n                    _validate_field(value, union_type, field_path, metadata)\n                    return  # Validation succeeded\n                except ValidationError as e:\n                    type_name = getattr(union_type, \"__name__\", str(union_type))\n                    # Extract just the error message without field path prefix\n                    error_msg = str(e).split(\"\\n\")[0]\n                    if f\"Validation error at '{field_path}': \" in error_msg:\n                        error_msg = error_msg.replace(f\"Validation error at '{field_path}': \", \"\")\n                    errors.append(f\"  Tried {type_name}: {error_msg}\")\n\n            # All failed - build comprehensive error message\n            union_str = _format_union_type(args)\n            error_details = \"\\n\".join(errors)\n            raise ValidationError(\n                f\"Value doesn't match any type in {union_str}\\n{error_details}\",\n                field_path=field_path,\n                expected_type=expected_type,\n                actual_value=value,\n                source_location=source_loc,\n            )\n\n    # Handle list[T]\n    if origin is list:\n        if not isinstance(value, list):\n            raise ValidationError(\n                \"Expected list\",\n                field_path=field_path,\n                expected_type=list,\n                actual_value=value,\n                source_location=source_loc,\n            )\n        if args:\n            item_type = args[0]\n            for i, item in enumerate(value):\n                _validate_field(\n                    item,\n                    item_type,\n                    f\"{field_path}[{i}]\",\n                    metadata,\n                )\n        return\n\n    # Handle dict[K, V]\n    if origin is dict:\n        if not isinstance(value, dict):\n            raise ValidationError(\n                \"Expected dict\",\n                field_path=field_path,\n                expected_type=dict,\n                actual_value=value,\n                source_location=source_loc,\n            )\n        if args and len(args) == 2:\n            key_type, value_type = args\n            for k, v in value.items():\n                # Validate key type\n                if not isinstance(k, key_type):\n                    raise ValidationError(\n                        \"Dict key has wrong type\",\n                        field_path=f\"{field_path}[{k!r}]\",\n                        expected_type=key_type,\n                        actual_value=k,\n                        source_location=source_loc,\n                    )\n                # Validate value type\n                _validate_field(\n                    v,\n                    value_type,\n                    f\"{field_path}[{k!r}]\",\n                    metadata,\n                )\n        return\n\n    # Handle nested dataclasses\n    if dataclasses.is_dataclass(expected_type):\n        validate(value, expected_type, field_path, metadata)\n        return\n\n    # Handle Literal types\n    from typing import Literal\n\n    if origin is Literal:\n        if value not in args:\n            valid_values = \", \".join(repr(v) for v in args)\n            raise ValidationError(\n                f\"Value must be one of {valid_values}, got {value!r}\",\n                field_path=field_path,\n                expected_type=expected_type,\n                actual_value=value,\n                source_location=source_loc,\n            )\n        return\n\n    # Handle basic types (int, str, float, bool, etc.)\n    if not isinstance(value, expected_type):\n        # Special case: accept resolved references (@), raw references (%), and expressions ($) as strings\n        # since they'll be resolved/expanded later\n        if isinstance(value, str) and (value.startswith(\"@\") or value.startswith(\"$\") or value.startswith(\"%\")):\n            # This is a resolved reference/raw reference/expression that will be processed later\n            # We can't validate its type until resolution\n            return\n\n        # Special case: allow int for float\n        if expected_type is float and isinstance(value, int):\n            return\n\n        raise ValidationError(\n            \"Type mismatch\",\n            field_path=field_path,\n            expected_type=expected_type,\n            actual_value=value,\n            source_location=source_loc,\n        )\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema.validate","title":"<code>validate(config, schema, field_path='', metadata=None)</code>","text":"<p>Validate configuration against a dataclass schema.</p> <p>Performs recursive type checking to ensure the configuration matches the structure and types defined in the dataclass schema.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>Configuration dictionary to validate</p> required <code>schema</code> <code>type</code> <p>Dataclass type defining the expected structure</p> required <code>field_path</code> <code>str</code> <p>Internal parameter for tracking nested field paths</p> <code>''</code> <code>metadata</code> <code>Any</code> <p>Optional metadata registry for source locations</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails</p> <code>TypeError</code> <p>If schema is not a dataclass</p> Example <pre><code>from dataclasses import dataclass\nfrom sparkwheel import Config\nfrom sparkwheel.schema import validate\n\n@dataclass\nclass AppConfig:\n    name: str\n    port: int\n    debug: bool = False\n\nconfig = Config.load(\"app.yaml\")\nvalidate(config.get(), AppConfig)\n</code></pre> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def validate(\n    config: dict[str, Any],\n    schema: type,\n    field_path: str = \"\",\n    metadata: Any = None,\n) -&gt; None:\n    \"\"\"Validate configuration against a dataclass schema.\n\n    Performs recursive type checking to ensure the configuration matches\n    the structure and types defined in the dataclass schema.\n\n    Args:\n        config: Configuration dictionary to validate\n        schema: Dataclass type defining the expected structure\n        field_path: Internal parameter for tracking nested field paths\n        metadata: Optional metadata registry for source locations\n\n    Raises:\n        ValidationError: If validation fails\n        TypeError: If schema is not a dataclass\n\n    Example:\n        ```python\n        from dataclasses import dataclass\n        from sparkwheel import Config\n        from sparkwheel.schema import validate\n\n        @dataclass\n        class AppConfig:\n            name: str\n            port: int\n            debug: bool = False\n\n        config = Config.load(\"app.yaml\")\n        validate(config.get(), AppConfig)\n        ```\n    \"\"\"\n    if not dataclasses.is_dataclass(schema):\n        raise TypeError(f\"Schema must be a dataclass, got {type(schema).__name__}\")\n\n    if not isinstance(config, dict):\n        source_loc = _get_source_location(metadata, field_path) if metadata else None\n        raise ValidationError(\n            f\"Expected dict for dataclass {schema.__name__}\",\n            field_path=field_path,\n            expected_type=dict,\n            actual_value=config,\n            source_location=source_loc,\n        )\n\n    # Get all fields from the dataclass\n    schema_fields = {f.name: f for f in dataclasses.fields(schema)}\n\n    # Check for required fields\n    for field_name, field_info in schema_fields.items():\n        current_path = f\"{field_path}.{field_name}\" if field_path else field_name\n\n        # Check if field is missing\n        if field_name not in config:\n            # Field has default or default_factory -&gt; optional\n            if field_info.default is not dataclasses.MISSING or field_info.default_factory is not dataclasses.MISSING:  # type: ignore[comparison-overlap]\n                continue\n            # No default -&gt; required\n            source_loc = _get_source_location(metadata, field_path) if metadata else None\n            raise ValidationError(\n                f\"Missing required field '{field_name}'\",\n                field_path=current_path,\n                expected_type=field_info.type,\n                source_location=source_loc,\n            )\n\n        # Validate the field value\n        _validate_field(\n            config[field_name],\n            field_info.type,\n            current_path,\n            metadata,\n        )\n\n    # Check for unexpected fields\n    unexpected_fields = set(config.keys()) - set(schema_fields.keys())\n    # Filter out sparkwheel special keys\n    special_keys = {\"_target_\", \"_disabled_\", \"_requires_\", \"_mode_\"}\n    unexpected_fields = unexpected_fields - special_keys\n\n    if unexpected_fields:\n        first_unexpected = sorted(unexpected_fields)[0]\n        current_path = f\"{field_path}.{first_unexpected}\" if field_path else first_unexpected\n        source_loc = _get_source_location(metadata, current_path) if metadata else None\n        raise ValidationError(\n            f\"Unexpected field '{first_unexpected}' not in schema {schema.__name__}\",\n            field_path=current_path,\n            source_location=source_loc,\n        )\n\n    # Run custom validators\n    _run_validators(config, schema, field_path, metadata)\n</code></pre>"},{"location":"reference/schema/#sparkwheel.schema.validator","title":"<code>validator(func)</code>","text":"<p>Decorator to mark a method as a validator.</p> <p>Validators run after type checking and can validate single fields or relationships between fields. Raise ValueError on failure.</p> Example <p>@dataclass class Config:     lr: float     start: int     end: int</p> <pre><code>@validator\ndef check_lr(self):\n    if not (0 &lt; self.lr &lt; 1):\n        raise ValueError(\"lr must be between 0 and 1\")\n\n@validator\ndef check_range(self):\n    if self.end &lt;= self.start:\n        raise ValueError(\"end must be &gt; start\")\n</code></pre> Source code in <code>src/sparkwheel/schema.py</code> <pre><code>def validator(func):\n    \"\"\"Decorator to mark a method as a validator.\n\n    Validators run after type checking and can validate single fields\n    or relationships between fields. Raise ValueError on failure.\n\n    Example:\n        @dataclass\n        class Config:\n            lr: float\n            start: int\n            end: int\n\n            @validator\n            def check_lr(self):\n                if not (0 &lt; self.lr &lt; 1):\n                    raise ValueError(\"lr must be between 0 and 1\")\n\n            @validator\n            def check_range(self):\n                if self.end &lt;= self.start:\n                    raise ValueError(\"end must be &gt; start\")\n    \"\"\"\n    func.__is_validator__ = True\n    return func\n</code></pre>"},{"location":"reference/errors/","title":"errors","text":"<ul> <li>context</li> <li>formatters</li> <li>suggestions</li> </ul>"},{"location":"reference/errors/#sparkwheel.errors.enable_colors","title":"<code>enable_colors(enabled=None)</code>","text":"<p>Enable or disable color output.</p> <p>Parameters:</p> Name Type Description Default <code>enabled</code> <code>bool | None</code> <p>True to enable, False to disable, None for auto-detection</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Current color enable status</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; enable_colors(False)  # Disable colors\nFalse\n&gt;&gt;&gt; enable_colors(True)   # Force enable colors\nTrue\n&gt;&gt;&gt; enable_colors()       # Auto-detect\nTrue  # (if terminal supports it)\n</code></pre> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def enable_colors(enabled: bool | None = None) -&gt; bool:\n    \"\"\"Enable or disable color output.\n\n    Args:\n        enabled: True to enable, False to disable, None for auto-detection\n\n    Returns:\n        Current color enable status\n\n    Examples:\n        &gt;&gt;&gt; enable_colors(False)  # Disable colors\n        False\n        &gt;&gt;&gt; enable_colors(True)   # Force enable colors\n        True\n        &gt;&gt;&gt; enable_colors()       # Auto-detect\n        True  # (if terminal supports it)\n    \"\"\"\n    global _COLORS_ENABLED\n\n    if enabled is None:\n        _COLORS_ENABLED = _supports_color()\n    else:\n        _COLORS_ENABLED = enabled\n\n    return _COLORS_ENABLED\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_available_keys","title":"<code>format_available_keys(config, max_keys=10)</code>","text":"<p>Format available keys for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>Configuration dictionary to extract keys from</p> required <code>max_keys</code> <code>int</code> <p>Maximum number of keys to display (default: 10)</p> <code>10</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with available keys and their values (truncated if needed)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; config = {\"_target_\": \"torch.nn.Linear\", \"in_features\": 784, \"out_features\": 10}\n&gt;&gt;&gt; print(format_available_keys(config))\nAvailable keys:\n  - _target_: \"torch.nn.Linear\"\n  - in_features: 784\n  - out_features: 10\n</code></pre> Source code in <code>src/sparkwheel/errors/context.py</code> <pre><code>def format_available_keys(config: dict[str, Any], max_keys: int = 10) -&gt; str:\n    \"\"\"Format available keys for display in error messages.\n\n    Args:\n        config: Configuration dictionary to extract keys from\n        max_keys: Maximum number of keys to display (default: 10)\n\n    Returns:\n        Formatted string with available keys and their values (truncated if needed)\n\n    Examples:\n        &gt;&gt;&gt; config = {\"_target_\": \"torch.nn.Linear\", \"in_features\": 784, \"out_features\": 10}\n        &gt;&gt;&gt; print(format_available_keys(config))\n        Available keys:\n          - _target_: \"torch.nn.Linear\"\n          - in_features: 784\n          - out_features: 10\n    \"\"\"\n    if not config or not isinstance(config, dict):\n        return \"\"\n\n    lines = [\"Available keys:\"]\n\n    keys_to_show = list(config.keys())[:max_keys]\n\n    for key in keys_to_show:\n        value = config[key]\n        value_repr = _format_value_repr(value)\n        lines.append(f\"  - {key}: {value_repr}\")\n\n    if len(config) &gt; max_keys:\n        remaining = len(config) - max_keys\n        lines.append(f\"  ... and {remaining} more\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_code","title":"<code>format_code(text)</code>","text":"<p>Format text as code/metadata (blue).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_code(text: str) -&gt; str:\n    \"\"\"Format text as code/metadata (blue).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, BLUE)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_error","title":"<code>format_error(text)</code>","text":"<p>Format text as an error (red).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format_error(\"Error message\")\n'\u001b[31mError message\u001b[0m'  # With colors enabled\n&gt;&gt;&gt; format_error(\"Error message\")\n'Error message'  # With colors disabled\n</code></pre> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_error(text: str) -&gt; str:\n    \"\"\"Format text as an error (red).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n\n    Examples:\n        &gt;&gt;&gt; format_error(\"Error message\")\n        '\\x1b[31mError message\\x1b[0m'  # With colors enabled\n        &gt;&gt;&gt; format_error(\"Error message\")\n        'Error message'  # With colors disabled\n    \"\"\"\n    return _colorize(text, RED)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_resolution_chain","title":"<code>format_resolution_chain(chain, title='Resolution chain:')</code>","text":"<p>Format a resolution chain for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>chain</code> <code>list[tuple[str, str, bool]]</code> <p>List of (id, reference, success) tuples representing the resolution chain</p> required <code>title</code> <code>str</code> <p>Title for the chain display</p> <code>'Resolution chain:'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with the resolution chain visualization</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; chain = [\n...     (\"training::optimizer\", \"@optimizer\", True),\n...     (\"optimizer::lr\", \"@base::learning_rate\", True),\n...     (\"base::learning_rate\", \"\", False),\n... ]\n&gt;&gt;&gt; print(format_resolution_chain(chain))\nResolution chain:\n  1. training::optimizer = \"@optimizer\" \u2713\n  2. optimizer::lr = \"@base::learning_rate\" \u2713\n  3. base::learning_rate = \u274c NOT FOUND\n</code></pre> Source code in <code>src/sparkwheel/errors/context.py</code> <pre><code>def format_resolution_chain(\n    chain: list[tuple[str, str, bool]],\n    title: str = \"Resolution chain:\",\n) -&gt; str:\n    \"\"\"Format a resolution chain for display in error messages.\n\n    Args:\n        chain: List of (id, reference, success) tuples representing the resolution chain\n        title: Title for the chain display\n\n    Returns:\n        Formatted string with the resolution chain visualization\n\n    Examples:\n        &gt;&gt;&gt; chain = [\n        ...     (\"training::optimizer\", \"@optimizer\", True),\n        ...     (\"optimizer::lr\", \"@base::learning_rate\", True),\n        ...     (\"base::learning_rate\", \"\", False),\n        ... ]\n        &gt;&gt;&gt; print(format_resolution_chain(chain))\n        Resolution chain:\n          1. training::optimizer = \"@optimizer\" \u2713\n          2. optimizer::lr = \"@base::learning_rate\" \u2713\n          3. base::learning_rate = \u274c NOT FOUND\n    \"\"\"\n    if not chain:\n        return \"\"\n\n    lines = [title]\n\n    for i, (id_str, reference, success) in enumerate(chain, 1):\n        if success:\n            if reference:\n                status = \"\u2713\"\n                lines.append(f'  {i}. {id_str} = \"{reference}\" {status}')\n            else:\n                lines.append(f\"  {i}. {id_str} \u2713\")\n        else:\n            lines.append(f\"  {i}. {id_str} = \u274c NOT FOUND\")\n\n    # Add suggestion\n    if chain and not chain[-1][2]:  # Last item failed\n        lines.append(\"\")\n        lines.append(f\"\ud83d\udca1 The reference chain failed at step {len(chain)}.\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_suggestion","title":"<code>format_suggestion(text)</code>","text":"<p>Format text as a suggestion (yellow).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_suggestion(text: str) -&gt; str:\n    \"\"\"Format text as a suggestion (yellow).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, YELLOW)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.format_suggestions","title":"<code>format_suggestions(suggestions)</code>","text":"<p>Format suggestion list for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>suggestions</code> <code>list[tuple[str, float]]</code> <p>List of (suggestion, similarity_score) tuples</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with suggestions, or empty string if no suggestions</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format_suggestions([('parameters', 0.9), ('param_groups', 0.54)])\n'\ud83d\udca1 Did you mean one of these?\\n    - parameters \u2713 (90% match)\\n    - param_groups (54% match)'\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def format_suggestions(suggestions: list[tuple[str, float]]) -&gt; str:\n    \"\"\"Format suggestion list for display in error messages.\n\n    Args:\n        suggestions: List of (suggestion, similarity_score) tuples\n\n    Returns:\n        Formatted string with suggestions, or empty string if no suggestions\n\n    Examples:\n        &gt;&gt;&gt; format_suggestions([('parameters', 0.9), ('param_groups', 0.54)])\n        '\ud83d\udca1 Did you mean one of these?\\\\n    - parameters \u2713 (90% match)\\\\n    - param_groups (54% match)'\n    \"\"\"\n    if not suggestions:\n        return \"\"\n\n    lines = [\"\ud83d\udca1 Did you mean one of these?\"]\n    for suggestion, score in suggestions:\n        # Add checkmark for very close matches (&gt;80% similarity)\n        check = \" \u2713\" if score &gt; 0.8 else \"\"\n        percentage = int(score * 100)\n        lines.append(f\"    - {suggestion}{check} ({percentage}% match)\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.get_suggestions","title":"<code>get_suggestions(key, available_keys, max_suggestions=3, similarity_threshold=0.6)</code>","text":"<p>Get suggestions for a potentially misspelled key.</p> <p>Uses Levenshtein distance to find similar keys and ranks them by similarity.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key that wasn't found</p> required <code>available_keys</code> <code>Sequence[str]</code> <p>List of available keys to compare against</p> required <code>max_suggestions</code> <code>int</code> <p>Maximum number of suggestions to return (default: 3)</p> <code>3</code> <code>similarity_threshold</code> <code>float</code> <p>Minimum similarity score (0-1) for suggestions (default: 0.6)                  Lower values are more lenient, higher values are stricter</p> <code>0.6</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (suggestion, similarity_score) tuples, sorted by similarity (best first)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = [\"parameters\", \"param_groups\", \"learning_rate\", \"weight_decay\"]\n&gt;&gt;&gt; get_suggestions(\"paramters\", keys)\n[('parameters', 0.9), ('param_groups', 0.54)]\n&gt;&gt;&gt; get_suggestions(\"lr\", keys)\n[]  # No matches above threshold\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def get_suggestions(\n    key: str,\n    available_keys: Sequence[str],\n    max_suggestions: int = 3,\n    similarity_threshold: float = 0.6,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Get suggestions for a potentially misspelled key.\n\n    Uses Levenshtein distance to find similar keys and ranks them by similarity.\n\n    Args:\n        key: The key that wasn't found\n        available_keys: List of available keys to compare against\n        max_suggestions: Maximum number of suggestions to return (default: 3)\n        similarity_threshold: Minimum similarity score (0-1) for suggestions (default: 0.6)\n                             Lower values are more lenient, higher values are stricter\n\n    Returns:\n        List of (suggestion, similarity_score) tuples, sorted by similarity (best first)\n\n    Examples:\n        &gt;&gt;&gt; keys = [\"parameters\", \"param_groups\", \"learning_rate\", \"weight_decay\"]\n        &gt;&gt;&gt; get_suggestions(\"paramters\", keys)\n        [('parameters', 0.9), ('param_groups', 0.54)]\n        &gt;&gt;&gt; get_suggestions(\"lr\", keys)\n        []  # No matches above threshold\n    \"\"\"\n    if not key or not available_keys:\n        return []\n\n    scored_suggestions = []\n\n    for candidate in available_keys:\n        # Calculate similarity score (1.0 = perfect match, 0.0 = completely different)\n        max_len = max(len(key), len(candidate))\n        if max_len == 0:\n            continue\n\n        distance = levenshtein_distance(key.lower(), candidate.lower())\n        similarity = 1.0 - (distance / max_len)\n\n        # Only include suggestions above threshold\n        if similarity &gt;= similarity_threshold:\n            scored_suggestions.append((candidate, similarity))\n\n    # Sort by similarity (best first) and limit to max_suggestions\n    scored_suggestions.sort(key=lambda x: x[1], reverse=True)\n    return scored_suggestions[:max_suggestions]\n</code></pre>"},{"location":"reference/errors/#sparkwheel.errors.levenshtein_distance","title":"<code>levenshtein_distance(s1, s2)</code>","text":"<p>Calculate the Levenshtein distance between two strings.</p> <p>The Levenshtein distance is the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into another.</p> <p>Parameters:</p> Name Type Description Default <code>s1</code> <code>str</code> <p>First string</p> required <code>s2</code> <code>str</code> <p>Second string</p> required <p>Returns:</p> Type Description <code>int</code> <p>Integer representing the edit distance between s1 and s2</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; levenshtein_distance(\"kitten\", \"sitting\")\n3\n&gt;&gt;&gt; levenshtein_distance(\"hello\", \"hello\")\n0\n&gt;&gt;&gt; levenshtein_distance(\"hello\", \"helo\")\n1\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def levenshtein_distance(s1: str, s2: str) -&gt; int:\n    \"\"\"Calculate the Levenshtein distance between two strings.\n\n    The Levenshtein distance is the minimum number of single-character edits\n    (insertions, deletions, or substitutions) required to change one word into another.\n\n    Args:\n        s1: First string\n        s2: Second string\n\n    Returns:\n        Integer representing the edit distance between s1 and s2\n\n    Examples:\n        &gt;&gt;&gt; levenshtein_distance(\"kitten\", \"sitting\")\n        3\n        &gt;&gt;&gt; levenshtein_distance(\"hello\", \"hello\")\n        0\n        &gt;&gt;&gt; levenshtein_distance(\"hello\", \"helo\")\n        1\n    \"\"\"\n    if len(s1) &lt; len(s2):\n        return levenshtein_distance(s2, s1)\n\n    if len(s2) == 0:\n        return len(s1)\n\n    # Create distance matrix\n    previous_row = range(len(s2) + 1)\n\n    for i, c1 in enumerate(s1):\n        current_row = [i + 1]\n        for j, c2 in enumerate(s2):\n            # Cost of insertions, deletions, or substitutions\n            insertions = previous_row[j + 1] + 1\n            deletions = current_row[j] + 1\n            substitutions = previous_row[j] + (c1 != c2)\n            current_row.append(min(insertions, deletions, substitutions))\n        previous_row = current_row\n\n    return previous_row[-1]\n</code></pre>"},{"location":"reference/errors/context/","title":"context","text":"<p>Context display utilities for error messages - available keys, resolution chains, etc.</p>"},{"location":"reference/errors/context/#sparkwheel.errors.context._format_value_repr","title":"<code>_format_value_repr(value, max_length=50)</code>","text":"<p>Format a value for compact display.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>Value to format</p> required <code>max_length</code> <code>int</code> <p>Maximum length for the representation</p> <code>50</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string representation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; _format_value_repr(\"hello\")\n'\"hello\"'\n&gt;&gt;&gt; _format_value_repr(42)\n'42'\n&gt;&gt;&gt; _format_value_repr({\"a\": 1, \"b\": 2})\n'{a: 1, b: 2}'\n</code></pre> Source code in <code>src/sparkwheel/errors/context.py</code> <pre><code>def _format_value_repr(value: Any, max_length: int = 50) -&gt; str:\n    \"\"\"Format a value for compact display.\n\n    Args:\n        value: Value to format\n        max_length: Maximum length for the representation\n\n    Returns:\n        Formatted string representation\n\n    Examples:\n        &gt;&gt;&gt; _format_value_repr(\"hello\")\n        '\"hello\"'\n        &gt;&gt;&gt; _format_value_repr(42)\n        '42'\n        &gt;&gt;&gt; _format_value_repr({\"a\": 1, \"b\": 2})\n        '{a: 1, b: 2}'\n    \"\"\"\n    if isinstance(value, str):\n        repr_str = f'\"{value}\"'\n    elif isinstance(value, (int, float, bool, type(None))):\n        repr_str = str(value)\n    elif isinstance(value, dict):\n        if not value:\n            repr_str = \"{}\"\n        elif len(value) &lt;= 3:\n            # Show small dicts compactly\n            items = [f\"{k}: {_format_value_repr(v, max_length=20)}\" for k, v in list(value.items())[:3]]\n            repr_str = \"{\" + \", \".join(items) + \"}\"\n        else:\n            repr_str = f\"{{...}} ({len(value)} keys)\"\n    elif isinstance(value, list):\n        if not value:\n            repr_str = \"[]\"\n        elif len(value) &lt;= 3:\n            items = [_format_value_repr(v, max_length=20) for v in value[:3]]\n            repr_str = \"[\" + \", \".join(items) + \"]\"\n        else:\n            repr_str = f\"[...] ({len(value)} items)\"\n    else:\n        repr_str = str(type(value).__name__)\n\n    # Truncate if too long\n    if len(repr_str) &gt; max_length:\n        repr_str = repr_str[: max_length - 3] + \"...\"\n\n    return repr_str\n</code></pre>"},{"location":"reference/errors/context/#sparkwheel.errors.context.format_available_keys","title":"<code>format_available_keys(config, max_keys=10)</code>","text":"<p>Format available keys for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, Any]</code> <p>Configuration dictionary to extract keys from</p> required <code>max_keys</code> <code>int</code> <p>Maximum number of keys to display (default: 10)</p> <code>10</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with available keys and their values (truncated if needed)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; config = {\"_target_\": \"torch.nn.Linear\", \"in_features\": 784, \"out_features\": 10}\n&gt;&gt;&gt; print(format_available_keys(config))\nAvailable keys:\n  - _target_: \"torch.nn.Linear\"\n  - in_features: 784\n  - out_features: 10\n</code></pre> Source code in <code>src/sparkwheel/errors/context.py</code> <pre><code>def format_available_keys(config: dict[str, Any], max_keys: int = 10) -&gt; str:\n    \"\"\"Format available keys for display in error messages.\n\n    Args:\n        config: Configuration dictionary to extract keys from\n        max_keys: Maximum number of keys to display (default: 10)\n\n    Returns:\n        Formatted string with available keys and their values (truncated if needed)\n\n    Examples:\n        &gt;&gt;&gt; config = {\"_target_\": \"torch.nn.Linear\", \"in_features\": 784, \"out_features\": 10}\n        &gt;&gt;&gt; print(format_available_keys(config))\n        Available keys:\n          - _target_: \"torch.nn.Linear\"\n          - in_features: 784\n          - out_features: 10\n    \"\"\"\n    if not config or not isinstance(config, dict):\n        return \"\"\n\n    lines = [\"Available keys:\"]\n\n    keys_to_show = list(config.keys())[:max_keys]\n\n    for key in keys_to_show:\n        value = config[key]\n        value_repr = _format_value_repr(value)\n        lines.append(f\"  - {key}: {value_repr}\")\n\n    if len(config) &gt; max_keys:\n        remaining = len(config) - max_keys\n        lines.append(f\"  ... and {remaining} more\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/context/#sparkwheel.errors.context.format_resolution_chain","title":"<code>format_resolution_chain(chain, title='Resolution chain:')</code>","text":"<p>Format a resolution chain for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>chain</code> <code>list[tuple[str, str, bool]]</code> <p>List of (id, reference, success) tuples representing the resolution chain</p> required <code>title</code> <code>str</code> <p>Title for the chain display</p> <code>'Resolution chain:'</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with the resolution chain visualization</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; chain = [\n...     (\"training::optimizer\", \"@optimizer\", True),\n...     (\"optimizer::lr\", \"@base::learning_rate\", True),\n...     (\"base::learning_rate\", \"\", False),\n... ]\n&gt;&gt;&gt; print(format_resolution_chain(chain))\nResolution chain:\n  1. training::optimizer = \"@optimizer\" \u2713\n  2. optimizer::lr = \"@base::learning_rate\" \u2713\n  3. base::learning_rate = \u274c NOT FOUND\n</code></pre> Source code in <code>src/sparkwheel/errors/context.py</code> <pre><code>def format_resolution_chain(\n    chain: list[tuple[str, str, bool]],\n    title: str = \"Resolution chain:\",\n) -&gt; str:\n    \"\"\"Format a resolution chain for display in error messages.\n\n    Args:\n        chain: List of (id, reference, success) tuples representing the resolution chain\n        title: Title for the chain display\n\n    Returns:\n        Formatted string with the resolution chain visualization\n\n    Examples:\n        &gt;&gt;&gt; chain = [\n        ...     (\"training::optimizer\", \"@optimizer\", True),\n        ...     (\"optimizer::lr\", \"@base::learning_rate\", True),\n        ...     (\"base::learning_rate\", \"\", False),\n        ... ]\n        &gt;&gt;&gt; print(format_resolution_chain(chain))\n        Resolution chain:\n          1. training::optimizer = \"@optimizer\" \u2713\n          2. optimizer::lr = \"@base::learning_rate\" \u2713\n          3. base::learning_rate = \u274c NOT FOUND\n    \"\"\"\n    if not chain:\n        return \"\"\n\n    lines = [title]\n\n    for i, (id_str, reference, success) in enumerate(chain, 1):\n        if success:\n            if reference:\n                status = \"\u2713\"\n                lines.append(f'  {i}. {id_str} = \"{reference}\" {status}')\n            else:\n                lines.append(f\"  {i}. {id_str} \u2713\")\n        else:\n            lines.append(f\"  {i}. {id_str} = \u274c NOT FOUND\")\n\n    # Add suggestion\n    if chain and not chain[-1][2]:  # Last item failed\n        lines.append(\"\")\n        lines.append(f\"\ud83d\udca1 The reference chain failed at step {len(chain)}.\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/formatters/","title":"formatters","text":"<p>Color formatting utilities for terminal output with auto-detection.</p>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters._colorize","title":"<code>_colorize(text, color)</code>","text":"<p>Apply color to text if colors are enabled.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to colorize</p> required <code>color</code> <code>str</code> <p>ANSI color code</p> required <p>Returns:</p> Type Description <code>str</code> <p>Colorized text if colors enabled, otherwise plain text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def _colorize(text: str, color: str) -&gt; str:\n    \"\"\"Apply color to text if colors are enabled.\n\n    Args:\n        text: Text to colorize\n        color: ANSI color code\n\n    Returns:\n        Colorized text if colors enabled, otherwise plain text\n    \"\"\"\n    if _get_colors_enabled():\n        return f\"{color}{text}{RESET}\"\n    return text\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters._get_colors_enabled","title":"<code>_get_colors_enabled()</code>","text":"<p>Get current color enable status, initializing if needed.</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def _get_colors_enabled() -&gt; bool:\n    \"\"\"Get current color enable status, initializing if needed.\"\"\"\n    global _COLORS_ENABLED\n\n    if _COLORS_ENABLED is None:\n        enable_colors()  # Auto-detect\n\n    return _COLORS_ENABLED  # type: ignore[return-value]\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters._supports_color","title":"<code>_supports_color()</code>","text":"<p>Auto-detect if the terminal supports colors.</p> <p>Follows industry standards for color detection: 1. NO_COLOR environment variable disables colors (https://no-color.org/) 2. SPARKWHEEL_NO_COLOR environment variable disables colors (sparkwheel-specific) 3. FORCE_COLOR environment variable enables colors (https://force-color.org/) 4. stdout TTY detection (auto-detect) 5. Default: disable colors</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if colors should be enabled, False otherwise</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def _supports_color() -&gt; bool:\n    \"\"\"Auto-detect if the terminal supports colors.\n\n    Follows industry standards for color detection:\n    1. NO_COLOR environment variable disables colors (https://no-color.org/)\n    2. SPARKWHEEL_NO_COLOR environment variable disables colors (sparkwheel-specific)\n    3. FORCE_COLOR environment variable enables colors (https://force-color.org/)\n    4. stdout TTY detection (auto-detect)\n    5. Default: disable colors\n\n    Returns:\n        True if colors should be enabled, False otherwise\n    \"\"\"\n    # Check NO_COLOR environment variable (https://no-color.org/)\n    # Highest priority - explicit user preference to disable\n    if os.environ.get(\"NO_COLOR\"):\n        return False\n\n    # Check sparkwheel-specific disable flag\n    if os.environ.get(\"SPARKWHEEL_NO_COLOR\"):\n        return False\n\n    # Check FORCE_COLOR environment variable (https://force-color.org/)\n    # Explicit enable for CI environments, piping, etc.\n    if os.environ.get(\"FORCE_COLOR\"):\n        return True\n\n    # Auto-detect: Check if stdout is a TTY\n    if hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty():\n        return True\n\n    # Default: disable colors\n    return False\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.enable_colors","title":"<code>enable_colors(enabled=None)</code>","text":"<p>Enable or disable color output.</p> <p>Parameters:</p> Name Type Description Default <code>enabled</code> <code>bool | None</code> <p>True to enable, False to disable, None for auto-detection</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Current color enable status</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; enable_colors(False)  # Disable colors\nFalse\n&gt;&gt;&gt; enable_colors(True)   # Force enable colors\nTrue\n&gt;&gt;&gt; enable_colors()       # Auto-detect\nTrue  # (if terminal supports it)\n</code></pre> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def enable_colors(enabled: bool | None = None) -&gt; bool:\n    \"\"\"Enable or disable color output.\n\n    Args:\n        enabled: True to enable, False to disable, None for auto-detection\n\n    Returns:\n        Current color enable status\n\n    Examples:\n        &gt;&gt;&gt; enable_colors(False)  # Disable colors\n        False\n        &gt;&gt;&gt; enable_colors(True)   # Force enable colors\n        True\n        &gt;&gt;&gt; enable_colors()       # Auto-detect\n        True  # (if terminal supports it)\n    \"\"\"\n    global _COLORS_ENABLED\n\n    if enabled is None:\n        _COLORS_ENABLED = _supports_color()\n    else:\n        _COLORS_ENABLED = enabled\n\n    return _COLORS_ENABLED\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_bold","title":"<code>format_bold(text)</code>","text":"<p>Format text as bold.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_bold(text: str) -&gt; str:\n    \"\"\"Format text as bold.\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    if _get_colors_enabled():\n        return f\"{BOLD}{text}{RESET}\"\n    return text\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_code","title":"<code>format_code(text)</code>","text":"<p>Format text as code/metadata (blue).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_code(text: str) -&gt; str:\n    \"\"\"Format text as code/metadata (blue).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, BLUE)\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_context","title":"<code>format_context(text)</code>","text":"<p>Format text as context (gray).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_context(text: str) -&gt; str:\n    \"\"\"Format text as context (gray).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, GRAY)\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_error","title":"<code>format_error(text)</code>","text":"<p>Format text as an error (red).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format_error(\"Error message\")\n'\u001b[31mError message\u001b[0m'  # With colors enabled\n&gt;&gt;&gt; format_error(\"Error message\")\n'Error message'  # With colors disabled\n</code></pre> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_error(text: str) -&gt; str:\n    \"\"\"Format text as an error (red).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n\n    Examples:\n        &gt;&gt;&gt; format_error(\"Error message\")\n        '\\x1b[31mError message\\x1b[0m'  # With colors enabled\n        &gt;&gt;&gt; format_error(\"Error message\")\n        'Error message'  # With colors disabled\n    \"\"\"\n    return _colorize(text, RED)\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_success","title":"<code>format_success(text)</code>","text":"<p>Format text as success/correct (green).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_success(text: str) -&gt; str:\n    \"\"\"Format text as success/correct (green).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, GREEN)\n</code></pre>"},{"location":"reference/errors/formatters/#sparkwheel.errors.formatters.format_suggestion","title":"<code>format_suggestion(text)</code>","text":"<p>Format text as a suggestion (yellow).</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to format</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted text</p> Source code in <code>src/sparkwheel/errors/formatters.py</code> <pre><code>def format_suggestion(text: str) -&gt; str:\n    \"\"\"Format text as a suggestion (yellow).\n\n    Args:\n        text: Text to format\n\n    Returns:\n        Formatted text\n    \"\"\"\n    return _colorize(text, YELLOW)\n</code></pre>"},{"location":"reference/errors/suggestions/","title":"suggestions","text":"<p>Smart suggestions for typos and common mistakes using Levenshtein distance.</p>"},{"location":"reference/errors/suggestions/#sparkwheel.errors.suggestions.format_suggestions","title":"<code>format_suggestions(suggestions)</code>","text":"<p>Format suggestion list for display in error messages.</p> <p>Parameters:</p> Name Type Description Default <code>suggestions</code> <code>list[tuple[str, float]]</code> <p>List of (suggestion, similarity_score) tuples</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with suggestions, or empty string if no suggestions</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; format_suggestions([('parameters', 0.9), ('param_groups', 0.54)])\n'\ud83d\udca1 Did you mean one of these?\\n    - parameters \u2713 (90% match)\\n    - param_groups (54% match)'\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def format_suggestions(suggestions: list[tuple[str, float]]) -&gt; str:\n    \"\"\"Format suggestion list for display in error messages.\n\n    Args:\n        suggestions: List of (suggestion, similarity_score) tuples\n\n    Returns:\n        Formatted string with suggestions, or empty string if no suggestions\n\n    Examples:\n        &gt;&gt;&gt; format_suggestions([('parameters', 0.9), ('param_groups', 0.54)])\n        '\ud83d\udca1 Did you mean one of these?\\\\n    - parameters \u2713 (90% match)\\\\n    - param_groups (54% match)'\n    \"\"\"\n    if not suggestions:\n        return \"\"\n\n    lines = [\"\ud83d\udca1 Did you mean one of these?\"]\n    for suggestion, score in suggestions:\n        # Add checkmark for very close matches (&gt;80% similarity)\n        check = \" \u2713\" if score &gt; 0.8 else \"\"\n        percentage = int(score * 100)\n        lines.append(f\"    - {suggestion}{check} ({percentage}% match)\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/errors/suggestions/#sparkwheel.errors.suggestions.get_suggestions","title":"<code>get_suggestions(key, available_keys, max_suggestions=3, similarity_threshold=0.6)</code>","text":"<p>Get suggestions for a potentially misspelled key.</p> <p>Uses Levenshtein distance to find similar keys and ranks them by similarity.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key that wasn't found</p> required <code>available_keys</code> <code>Sequence[str]</code> <p>List of available keys to compare against</p> required <code>max_suggestions</code> <code>int</code> <p>Maximum number of suggestions to return (default: 3)</p> <code>3</code> <code>similarity_threshold</code> <code>float</code> <p>Minimum similarity score (0-1) for suggestions (default: 0.6)                  Lower values are more lenient, higher values are stricter</p> <code>0.6</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (suggestion, similarity_score) tuples, sorted by similarity (best first)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = [\"parameters\", \"param_groups\", \"learning_rate\", \"weight_decay\"]\n&gt;&gt;&gt; get_suggestions(\"paramters\", keys)\n[('parameters', 0.9), ('param_groups', 0.54)]\n&gt;&gt;&gt; get_suggestions(\"lr\", keys)\n[]  # No matches above threshold\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def get_suggestions(\n    key: str,\n    available_keys: Sequence[str],\n    max_suggestions: int = 3,\n    similarity_threshold: float = 0.6,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Get suggestions for a potentially misspelled key.\n\n    Uses Levenshtein distance to find similar keys and ranks them by similarity.\n\n    Args:\n        key: The key that wasn't found\n        available_keys: List of available keys to compare against\n        max_suggestions: Maximum number of suggestions to return (default: 3)\n        similarity_threshold: Minimum similarity score (0-1) for suggestions (default: 0.6)\n                             Lower values are more lenient, higher values are stricter\n\n    Returns:\n        List of (suggestion, similarity_score) tuples, sorted by similarity (best first)\n\n    Examples:\n        &gt;&gt;&gt; keys = [\"parameters\", \"param_groups\", \"learning_rate\", \"weight_decay\"]\n        &gt;&gt;&gt; get_suggestions(\"paramters\", keys)\n        [('parameters', 0.9), ('param_groups', 0.54)]\n        &gt;&gt;&gt; get_suggestions(\"lr\", keys)\n        []  # No matches above threshold\n    \"\"\"\n    if not key or not available_keys:\n        return []\n\n    scored_suggestions = []\n\n    for candidate in available_keys:\n        # Calculate similarity score (1.0 = perfect match, 0.0 = completely different)\n        max_len = max(len(key), len(candidate))\n        if max_len == 0:\n            continue\n\n        distance = levenshtein_distance(key.lower(), candidate.lower())\n        similarity = 1.0 - (distance / max_len)\n\n        # Only include suggestions above threshold\n        if similarity &gt;= similarity_threshold:\n            scored_suggestions.append((candidate, similarity))\n\n    # Sort by similarity (best first) and limit to max_suggestions\n    scored_suggestions.sort(key=lambda x: x[1], reverse=True)\n    return scored_suggestions[:max_suggestions]\n</code></pre>"},{"location":"reference/errors/suggestions/#sparkwheel.errors.suggestions.levenshtein_distance","title":"<code>levenshtein_distance(s1, s2)</code>","text":"<p>Calculate the Levenshtein distance between two strings.</p> <p>The Levenshtein distance is the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into another.</p> <p>Parameters:</p> Name Type Description Default <code>s1</code> <code>str</code> <p>First string</p> required <code>s2</code> <code>str</code> <p>Second string</p> required <p>Returns:</p> Type Description <code>int</code> <p>Integer representing the edit distance between s1 and s2</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; levenshtein_distance(\"kitten\", \"sitting\")\n3\n&gt;&gt;&gt; levenshtein_distance(\"hello\", \"hello\")\n0\n&gt;&gt;&gt; levenshtein_distance(\"hello\", \"helo\")\n1\n</code></pre> Source code in <code>src/sparkwheel/errors/suggestions.py</code> <pre><code>def levenshtein_distance(s1: str, s2: str) -&gt; int:\n    \"\"\"Calculate the Levenshtein distance between two strings.\n\n    The Levenshtein distance is the minimum number of single-character edits\n    (insertions, deletions, or substitutions) required to change one word into another.\n\n    Args:\n        s1: First string\n        s2: Second string\n\n    Returns:\n        Integer representing the edit distance between s1 and s2\n\n    Examples:\n        &gt;&gt;&gt; levenshtein_distance(\"kitten\", \"sitting\")\n        3\n        &gt;&gt;&gt; levenshtein_distance(\"hello\", \"hello\")\n        0\n        &gt;&gt;&gt; levenshtein_distance(\"hello\", \"helo\")\n        1\n    \"\"\"\n    if len(s1) &lt; len(s2):\n        return levenshtein_distance(s2, s1)\n\n    if len(s2) == 0:\n        return len(s1)\n\n    # Create distance matrix\n    previous_row = range(len(s2) + 1)\n\n    for i, c1 in enumerate(s1):\n        current_row = [i + 1]\n        for j, c2 in enumerate(s2):\n            # Cost of insertions, deletions, or substitutions\n            insertions = previous_row[j + 1] + 1\n            deletions = current_row[j] + 1\n            substitutions = previous_row[j] + (c1 != c2)\n            current_row.append(min(insertions, deletions, substitutions))\n        previous_row = current_row\n\n    return previous_row[-1]\n</code></pre>"},{"location":"reference/utils/","title":"utils","text":"<ul> <li>module</li> <li>types</li> <li>constants</li> <li>exceptions</li> <li>misc</li> <li>enums</li> </ul>"},{"location":"reference/utils/#sparkwheel.utils.CheckKeyDuplicatesYamlLoader","title":"<code>CheckKeyDuplicatesYamlLoader</code>","text":"<p>               Bases: <code>SafeLoader</code></p> <p>YAML loader that detects duplicate keys and either warns or raises an error. Also tracks line numbers for values to enable better error reporting.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>class CheckKeyDuplicatesYamlLoader(SafeLoader):\n    \"\"\"\n    YAML loader that detects duplicate keys and either warns or raises an error.\n    Also tracks line numbers for values to enable better error reporting.\n    \"\"\"\n\n    def __init__(self, stream):\n        super().__init__(stream)\n        # Store filename if available\n        self.source_file = getattr(stream, \"name\", None)\n\n    def construct_mapping(self, node, deep=False):\n        mapping = set()\n        for key_node, _ in node.value:\n            key = self.construct_object(key_node, deep=deep)\n            if key in mapping:\n                if os.environ.get(\"SPARKWHEEL_STRICT_KEYS\", \"0\") == \"1\":\n                    raise ValueError(f\"Duplicate key: `{key}`\")\n                else:\n                    warnings.warn(f\"Duplicate key: `{key}`\", stacklevel=2)\n            mapping.add(key)\n        return super().construct_mapping(node, deep)\n\n    def construct_object(self, node, deep=False):\n        \"\"\"Construct object and attach source location metadata.\"\"\"\n        obj = super().construct_object(node, deep)\n\n        # Attach location metadata to the object if it's a dict or scalar\n        # This allows us to track where each config value came from\n        if hasattr(node, \"start_mark\") and self.source_file:\n            # Store metadata as a special attribute that we can extract later\n            # We'll use a tuple: (value, line, column, filepath)\n            if isinstance(obj, dict):\n                # For dicts, store location info in a special key\n                obj[\"__sparkwheel_metadata__\"] = {\n                    \"line\": node.start_mark.line + 1,  # YAML uses 0-indexed lines\n                    \"column\": node.start_mark.column,\n                    \"file\": self.source_file,\n                }\n\n        return obj\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.CheckKeyDuplicatesYamlLoader.construct_object","title":"<code>construct_object(node, deep=False)</code>","text":"<p>Construct object and attach source location metadata.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def construct_object(self, node, deep=False):\n    \"\"\"Construct object and attach source location metadata.\"\"\"\n    obj = super().construct_object(node, deep)\n\n    # Attach location metadata to the object if it's a dict or scalar\n    # This allows us to track where each config value came from\n    if hasattr(node, \"start_mark\") and self.source_file:\n        # Store metadata as a special attribute that we can extract later\n        # We'll use a tuple: (value, line, column, filepath)\n        if isinstance(obj, dict):\n            # For dicts, store location info in a special key\n            obj[\"__sparkwheel_metadata__\"] = {\n                \"line\": node.start_mark.line + 1,  # YAML uses 0-indexed lines\n                \"column\": node.start_mark.column,\n                \"file\": self.source_file,\n            }\n\n    return obj\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.CompInitMode","title":"<code>CompInitMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Component initialization mode for Component.</p> <ul> <li>DEFAULT: Instantiate by calling the component</li> <li>CALLABLE: Return the callable (or partial with kwargs)</li> <li>DEBUG: Use pdb.runcall for debugging</li> </ul> Source code in <code>src/sparkwheel/utils/enums.py</code> <pre><code>class CompInitMode(StrEnum):\n    \"\"\"\n    Component initialization mode for Component.\n\n    - DEFAULT: Instantiate by calling the component\n    - CALLABLE: Return the callable (or partial with kwargs)\n    - DEBUG: Use pdb.runcall for debugging\n    \"\"\"\n\n    DEFAULT = \"default\"\n    CALLABLE = \"callable\"\n    DEBUG = \"debug\"\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.check_key_duplicates","title":"<code>check_key_duplicates(ordered_pairs)</code>","text":"<p>Checks if there is a duplicated key in the sequence of <code>ordered_pairs</code>. If there is - it will log a warning or raise ValueError (if configured by environmental var <code>SPARKWHEEL_STRICT_KEYS==1</code>)</p> <p>Otherwise, it returns the dict made from this sequence.</p> <p>Note: This function is kept for compatibility but is primarily used by the YAML loader.</p> <p>Parameters:</p> Name Type Description Default <code>ordered_pairs</code> <code>list[tuple[Any, Any]]</code> <p>sequence of (key, value)</p> required Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def check_key_duplicates(ordered_pairs: list[tuple[Any, Any]]) -&gt; dict[Any, Any]:\n    \"\"\"\n    Checks if there is a duplicated key in the sequence of `ordered_pairs`.\n    If there is - it will log a warning or raise ValueError\n    (if configured by environmental var `SPARKWHEEL_STRICT_KEYS==1`)\n\n    Otherwise, it returns the dict made from this sequence.\n\n    Note: This function is kept for compatibility but is primarily used by the YAML loader.\n\n    Args:\n        ordered_pairs: sequence of (key, value)\n    \"\"\"\n    keys = set()\n    for k, _ in ordered_pairs:\n        if k in keys:\n            if os.environ.get(\"SPARKWHEEL_STRICT_KEYS\", \"0\") == \"1\":\n                raise ValueError(f\"Duplicate key: `{k}`\")\n            else:\n                warnings.warn(f\"Duplicate key: `{k}`\", stacklevel=2)\n        else:\n            keys.add(k)\n    return dict(ordered_pairs)\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.damerau_levenshtein_distance","title":"<code>damerau_levenshtein_distance(s1, s2)</code>","text":"<p>Calculates the Damerau\u2013Levenshtein distance between two strings for spelling correction. https://en.wikipedia.org/wiki/Damerau\u2013Levenshtein_distance</p> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def damerau_levenshtein_distance(s1: str, s2: str) -&gt; int:\n    \"\"\"\n    Calculates the Damerau\u2013Levenshtein distance between two strings for spelling correction.\n    https://en.wikipedia.org/wiki/Damerau\u2013Levenshtein_distance\n    \"\"\"\n    if s1 == s2:\n        return 0\n    string_1_length = len(s1)\n    string_2_length = len(s2)\n    if not s1:\n        return string_2_length\n    if not s2:\n        return string_1_length\n    d = {(i, -1): i + 1 for i in range(-1, string_1_length + 1)}\n    for j in range(-1, string_2_length + 1):\n        d[(-1, j)] = j + 1\n\n    for i, s1i in enumerate(s1):\n        for j, s2j in enumerate(s2):\n            cost = 0 if s1i == s2j else 1\n            d[(i, j)] = min(\n                d[(i - 1, j)] + 1,  # deletion\n                d[(i, j - 1)] + 1,  # insertion\n                d[(i - 1, j - 1)] + cost,  # substitution\n            )\n            if i and j and s1i == s2[j - 1] and s1[i - 1] == s2j:\n                d[(i, j)] = min(d[(i, j)], d[i - 2, j - 2] + cost)  # transposition\n\n    return d[string_1_length - 1, string_2_length - 1]\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.ensure_tuple","title":"<code>ensure_tuple(vals)</code>","text":"<p>Returns a tuple of <code>vals</code>.</p> <p>Parameters:</p> Name Type Description Default <code>vals</code> <code>Any</code> <p>input data to convert to a tuple.</p> required Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def ensure_tuple(vals: Any) -&gt; tuple:\n    \"\"\"\n    Returns a tuple of `vals`.\n\n    Args:\n        vals: input data to convert to a tuple.\n    \"\"\"\n    return tuple(vals) if issequenceiterable(vals) else (vals,)\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.first","title":"<code>first(iterable, default=None)</code>","text":"<p>Returns the first item in the given iterable or <code>default</code> if empty.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def first(iterable: Iterable[T], default: T | None = None) -&gt; T | None:\n    \"\"\"\n    Returns the first item in the given iterable or `default` if empty.\n    \"\"\"\n    for i in iterable:\n        return i\n    return default\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.instantiate","title":"<code>instantiate(__path, __mode, **kwargs)</code>","text":"<p>Create an object instance or call a callable object from a class or function represented by <code>__path</code>. <code>kwargs</code> will be part of the input arguments to the class constructor or function. The target component must be a class or a function, if not, return the component directly.</p> <p>Parameters:</p> Name Type Description Default <code>__path</code> <code>str</code> <p>if a string is provided, it's interpreted as the full path of the target class or function component. If a callable is provided, <code>__path(**kwargs)</code> will be invoked and returned for <code>__mode=\"default\"</code>. For <code>__mode=\"callable\"</code>, the callable will be returned as <code>__path</code> or, if <code>kwargs</code> are provided, as <code>functools.partial(__path, **kwargs)</code> for future invoking.</p> required <code>__mode</code> <code>str</code> <p>the operating mode for invoking the (callable) <code>component</code> represented by <code>__path</code>:</p> <ul> <li><code>\"default\"</code>: returns <code>component(**kwargs)</code></li> <li><code>\"callable\"</code>: returns <code>component</code> or, if <code>kwargs</code> are provided, <code>functools.partial(component, **kwargs)</code></li> <li><code>\"debug\"</code>: returns <code>pdb.runcall(component, **kwargs)</code></li> </ul> required <code>kwargs</code> <code>Any</code> <p>keyword arguments to the callable represented by <code>__path</code>.</p> <code>{}</code> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def instantiate(__path: str, __mode: str, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    Create an object instance or call a callable object from a class or function represented by ``__path``.\n    `kwargs` will be part of the input arguments to the class constructor or function.\n    The target component must be a class or a function, if not, return the component directly.\n\n    Args:\n        __path: if a string is provided, it's interpreted as the full path of the target class or function component.\n            If a callable is provided, ``__path(**kwargs)`` will be invoked and returned for ``__mode=\"default\"``.\n            For ``__mode=\"callable\"``, the callable will be returned as ``__path`` or, if ``kwargs`` are provided,\n            as ``functools.partial(__path, **kwargs)`` for future invoking.\n\n        __mode: the operating mode for invoking the (callable) ``component`` represented by ``__path``:\n\n            - ``\"default\"``: returns ``component(**kwargs)``\n            - ``\"callable\"``: returns ``component`` or, if ``kwargs`` are provided, ``functools.partial(component, **kwargs)``\n            - ``\"debug\"``: returns ``pdb.runcall(component, **kwargs)``\n\n        kwargs: keyword arguments to the callable represented by ``__path``.\n    \"\"\"\n    component = locate(__path) if isinstance(__path, str) else __path\n    if component is None:\n        raise ModuleNotFoundError(f\"Cannot locate class or function path: '{__path}'.\")\n    m = look_up_option(__mode, CompInitMode)\n    try:\n        if kwargs.pop(\"_debug_\", False) or run_debug:\n            warnings.warn(\n                f\"\\n\\npdb: instantiating component={component}, mode={m}\\n\"\n                f\"See also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n                stacklevel=2,\n            )\n            breakpoint()  # noqa: T100\n        if not callable(component):\n            warnings.warn(f\"Component {component} is not callable when mode={m}.\", stacklevel=2)\n            return component\n        if m == CompInitMode.DEFAULT:\n            return component(**kwargs)\n        if m == CompInitMode.CALLABLE:\n            return partial(component, **kwargs) if kwargs else component\n        if m == CompInitMode.DEBUG:\n            warnings.warn(\n                f\"\\n\\npdb: instantiating component={component}, mode={m}\\n\"\n                f\"See also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n                stacklevel=2,\n            )\n            return pdb.runcall(component, **kwargs)\n    except Exception as e:\n        # Preserve the original exception type and message for better debugging\n        error_msg = (\n            f\"Failed to instantiate component '{__path}' with keywords: {','.join(kwargs.keys())}\\n\"\n            f\"  Original error ({type(e).__name__}): {str(e)}\\n\"\n            f\"  Set '_mode_={CompInitMode.DEBUG}' to enter debugging mode.\"\n        )\n        raise InstantiationError(error_msg) from e\n\n    warnings.warn(f\"Component to instantiate must represent a valid class or function, but got {__path}.\", stacklevel=2)\n    return component\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.issequenceiterable","title":"<code>issequenceiterable(obj)</code>","text":"<p>Determine if the object is an iterable sequence and is not a string.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def issequenceiterable(obj: Any) -&gt; bool:\n    \"\"\"\n    Determine if the object is an iterable sequence and is not a string.\n    \"\"\"\n    try:\n        if hasattr(obj, \"ndim\") and obj.ndim == 0:\n            return False  # a 0-d tensor is not iterable\n    except Exception:\n        return False\n    return isinstance(obj, Iterable) and not isinstance(obj, (str, bytes))\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.look_up_option","title":"<code>look_up_option(opt_str, supported, default='no_default', print_all_options=True)</code>","text":"<p>Look up the option in the supported collection and return the matched item. Raise a value error possibly with a guess of the closest match.</p> <p>Parameters:</p> Name Type Description Default <code>opt_str</code> <code>Hashable</code> <p>The option string or Enum to look up.</p> required <code>supported</code> <code>Collection | EnumMeta</code> <p>The collection of supported options, it can be list, tuple, set, dict, or Enum.</p> required <code>default</code> <code>Any</code> <p>If it is given, this method will return <code>default</code> when <code>opt_str</code> is not found, instead of raising a <code>ValueError</code>. Otherwise, it defaults to <code>\"no_default\"</code>, so that the method may raise a <code>ValueError</code>.</p> <code>'no_default'</code> <code>print_all_options</code> <code>bool</code> <p>whether to print all available options when <code>opt_str</code> is not found. Defaults to True</p> <code>True</code> <p>Examples:</p> <p>.. code-block:: python</p> <pre><code>from enum import Enum\nfrom sparkwheel.utils import look_up_option\nclass Color(Enum):\n    RED = \"red\"\n    BLUE = \"blue\"\nlook_up_option(\"red\", Color)  # &lt;Color.RED: 'red'&gt;\nlook_up_option(Color.RED, Color)  # &lt;Color.RED: 'red'&gt;\nlook_up_option(\"read\", Color)\n# ValueError: By 'read', did you mean 'red'?\n# 'read' is not a valid option.\n# Available options are {'blue', 'red'}.\nlook_up_option(\"red\", {\"red\", \"blue\"})  # \"red\"\n</code></pre> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def look_up_option(\n    opt_str: Hashable,\n    supported: Collection | enum.EnumMeta,\n    default: Any = \"no_default\",\n    print_all_options: bool = True,\n) -&gt; Any:\n    \"\"\"\n    Look up the option in the supported collection and return the matched item.\n    Raise a value error possibly with a guess of the closest match.\n\n    Args:\n        opt_str: The option string or Enum to look up.\n        supported: The collection of supported options, it can be list, tuple, set, dict, or Enum.\n        default: If it is given, this method will return `default` when `opt_str` is not found,\n            instead of raising a `ValueError`. Otherwise, it defaults to `\"no_default\"`,\n            so that the method may raise a `ValueError`.\n        print_all_options: whether to print all available options when `opt_str` is not found. Defaults to True\n\n    Examples:\n\n    .. code-block:: python\n\n        from enum import Enum\n        from sparkwheel.utils import look_up_option\n        class Color(Enum):\n            RED = \"red\"\n            BLUE = \"blue\"\n        look_up_option(\"red\", Color)  # &lt;Color.RED: 'red'&gt;\n        look_up_option(Color.RED, Color)  # &lt;Color.RED: 'red'&gt;\n        look_up_option(\"read\", Color)\n        # ValueError: By 'read', did you mean 'red'?\n        # 'read' is not a valid option.\n        # Available options are {'blue', 'red'}.\n        look_up_option(\"red\", {\"red\", \"blue\"})  # \"red\"\n    \"\"\"\n    if not isinstance(opt_str, Hashable):\n        raise ValueError(f\"Unrecognized option type: {type(opt_str)}:{opt_str}.\")\n    if isinstance(opt_str, str):\n        opt_str = opt_str.strip()\n    if isinstance(supported, enum.EnumMeta):\n        if isinstance(opt_str, str) and opt_str in {item.value for item in supported}:  # type: ignore[attr-defined]\n            # such as: \"example\" in MyEnum\n            return supported(opt_str)\n        if isinstance(opt_str, enum.Enum) and opt_str in supported:\n            # such as: MyEnum.EXAMPLE in MyEnum\n            return opt_str\n    elif isinstance(supported, dict) and opt_str in supported:\n        # such as: MyDict[key]\n        return supported[opt_str]\n    elif isinstance(supported, Collection) and opt_str in supported:\n        return opt_str\n\n    if default != \"no_default\":\n        return default\n\n    # find a close match\n    set_to_check: set\n    if isinstance(supported, enum.EnumMeta):\n        set_to_check = {item.value for item in supported}  # type: ignore[attr-defined]\n    else:\n        set_to_check = set(supported) if supported is not None else set()\n    if not set_to_check:\n        raise ValueError(f\"No options available: {supported}.\")\n    edit_dists = {}\n    opt_str = f\"{opt_str}\"\n    for key in set_to_check:\n        edit_dist = damerau_levenshtein_distance(f\"{key}\", opt_str)\n        if edit_dist &lt;= 3:\n            edit_dists[key] = edit_dist\n\n    supported_msg = f\"Available options are {set_to_check}.\\n\" if print_all_options else \"\"\n    if edit_dists:\n        guess_at_spelling = min(edit_dists, key=edit_dists.get)  # type: ignore[arg-type]\n        raise ValueError(\n            f\"By '{opt_str}', did you mean '{guess_at_spelling}'?\\n\" + f\"'{opt_str}' is not a valid value.\\n\" + supported_msg\n        )\n    raise ValueError(f\"Unsupported option '{opt_str}', \" + supported_msg)\n</code></pre>"},{"location":"reference/utils/#sparkwheel.utils.optional_import","title":"<code>optional_import(module, version='', name='')</code>","text":"<p>Imports an optional module specified by <code>module</code> string. Any importing related exceptions will be stored, and exceptions raise lazily when attempting to use the failed-to-import module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>name of the module to be imported.</p> required <code>version</code> <code>str</code> <p>version string (currently not checked, for future use).</p> <code>''</code> <code>name</code> <code>str</code> <p>a non-module attribute (such as method/class) to import from the imported module.</p> <code>''</code> <p>Returns:</p> Type Description <code>tuple[Any, bool]</code> <p>The imported module and a boolean flag indicating whether the import is successful.</p> <p>Examples::</p> <pre><code>&gt;&gt;&gt; yaml, flag = optional_import('yaml')\n&gt;&gt;&gt; print(flag)\nTrue\n\n&gt;&gt;&gt; the_module, flag = optional_import('unknown_module')\n&gt;&gt;&gt; print(flag)\nFalse\n&gt;&gt;&gt; the_module.method  # trying to access a module which is not imported\nOptionalImportError: import unknown_module (No module named 'unknown_module').\n</code></pre> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def optional_import(\n    module: str,\n    version: str = \"\",\n    name: str = \"\",\n) -&gt; tuple[Any, bool]:\n    \"\"\"\n    Imports an optional module specified by `module` string.\n    Any importing related exceptions will be stored, and exceptions raise lazily\n    when attempting to use the failed-to-import module.\n\n    Args:\n        module: name of the module to be imported.\n        version: version string (currently not checked, for future use).\n        name: a non-module attribute (such as method/class) to import from the imported module.\n\n    Returns:\n        The imported module and a boolean flag indicating whether the import is successful.\n\n    Examples::\n\n        &gt;&gt;&gt; yaml, flag = optional_import('yaml')\n        &gt;&gt;&gt; print(flag)\n        True\n\n        &gt;&gt;&gt; the_module, flag = optional_import('unknown_module')\n        &gt;&gt;&gt; print(flag)\n        False\n        &gt;&gt;&gt; the_module.method  # trying to access a module which is not imported\n        OptionalImportError: import unknown_module (No module named 'unknown_module').\n    \"\"\"\n    exception_str = \"\"\n    if name:\n        actual_cmd = f\"from {module} import {name}\"\n    else:\n        actual_cmd = f\"import {module}\"\n    try:\n        the_module = import_module(module)\n        if name:  # user specified to load class/function/... from the module\n            the_module = getattr(the_module, name)\n        return the_module, True\n    except Exception as import_exception:\n        exception_str = f\"{import_exception}\"\n\n    # Return a placeholder that raises on access\n    class _LazyRaise:\n        def __getattr__(self, name):\n            msg = f\"{actual_cmd}\"\n            if exception_str:\n                msg += f\" ({exception_str})\"\n            raise OptionalImportError(msg)\n\n    return _LazyRaise(), False\n</code></pre>"},{"location":"reference/utils/constants/","title":"constants","text":""},{"location":"reference/utils/enums/","title":"enums","text":""},{"location":"reference/utils/enums/#sparkwheel.utils.enums.CompInitMode","title":"<code>CompInitMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Component initialization mode for Component.</p> <ul> <li>DEFAULT: Instantiate by calling the component</li> <li>CALLABLE: Return the callable (or partial with kwargs)</li> <li>DEBUG: Use pdb.runcall for debugging</li> </ul> Source code in <code>src/sparkwheel/utils/enums.py</code> <pre><code>class CompInitMode(StrEnum):\n    \"\"\"\n    Component initialization mode for Component.\n\n    - DEFAULT: Instantiate by calling the component\n    - CALLABLE: Return the callable (or partial with kwargs)\n    - DEBUG: Use pdb.runcall for debugging\n    \"\"\"\n\n    DEFAULT = \"default\"\n    CALLABLE = \"callable\"\n    DEBUG = \"debug\"\n</code></pre>"},{"location":"reference/utils/enums/#sparkwheel.utils.enums.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>String enumeration base class.</p> Source code in <code>src/sparkwheel/utils/enums.py</code> <pre><code>class StrEnum(str, Enum):\n    \"\"\"String enumeration base class.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/","title":"exceptions","text":"<p>Custom exceptions for sparkwheel with source location tracking and helpful error messages.</p>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.BaseError","title":"<code>BaseError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for sparkwheel with rich error context.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>The error message</p> <code>source_location</code> <p>Optional location in config file where error occurred</p> <code>suggestion</code> <p>Optional helpful suggestion for fixing the error</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class BaseError(Exception):\n    \"\"\"Base exception for sparkwheel with rich error context.\n\n    Attributes:\n        message: The error message\n        source_location: Optional location in config file where error occurred\n        suggestion: Optional helpful suggestion for fixing the error\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        source_location: SourceLocation | None = None,\n        suggestion: str | None = None,\n    ) -&gt; None:\n        self.source_location = source_location\n        self.suggestion = suggestion\n        self._original_message = message\n        super().__init__(self._format_message())\n\n    def _format_message(self) -&gt; str:\n        \"\"\"Format error message with source location and suggestions.\n\n        Critical info (file:line) is on the first line for Rich compatibility,\n        since Rich's traceback only shows the first line of exception messages.\n        \"\"\"\n        parts = []\n\n        # Put file:line on the FIRST line for Rich visibility\n        if self.source_location:\n            location = f\"{self.source_location.filepath}:{self.source_location.line}\"\n            if self.source_location.id:\n                parts.append(f\"[{location} @ {self.source_location.id}] {self._original_message}\")\n            else:\n                parts.append(f\"[{location}] {self._original_message}\")\n        else:\n            parts.append(self._original_message)\n\n        # Add code snippet on subsequent lines (will be visible in full traceback)\n        if self.source_location:\n            snippet = self._get_config_snippet()\n            if snippet:\n                parts.append(f\"\\n\\n{snippet}\")\n\n        if self.suggestion:\n            parts.append(f\"\\n\\n  \ud83d\udca1 {self.suggestion}\")\n\n        return \"\".join(parts)\n\n    def _get_config_snippet(self) -&gt; str:\n        \"\"\"Extract and format a code snippet from the config file.\"\"\"\n        if not self.source_location:\n            return \"\"\n\n        try:\n            filepath = Path(self.source_location.filepath)\n            if not filepath.exists():\n                return \"\"\n\n            with open(filepath) as f:\n                lines = f.readlines()\n\n            # Show 2 lines before and 1 line after the error\n            line_num = self.source_location.line\n            start = max(0, line_num - 3)\n            end = min(len(lines), line_num + 2)\n\n            snippet_lines = []\n            for i in range(start, end):\n                marker = \"\u2192\" if i == line_num - 1 else \" \"\n                # Use 4-digit line numbers for alignment\n                snippet_lines.append(f\"  {marker} {i + 1:4d} \u2502 {lines[i].rstrip()}\")\n\n            return \"\\n\".join(snippet_lines)\n        except Exception:\n            # If we can't read the file, just skip the snippet\n            return \"\"\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.BaseError._format_message","title":"<code>_format_message()</code>","text":"<p>Format error message with source location and suggestions.</p> <p>Critical info (file:line) is on the first line for Rich compatibility, since Rich's traceback only shows the first line of exception messages.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _format_message(self) -&gt; str:\n    \"\"\"Format error message with source location and suggestions.\n\n    Critical info (file:line) is on the first line for Rich compatibility,\n    since Rich's traceback only shows the first line of exception messages.\n    \"\"\"\n    parts = []\n\n    # Put file:line on the FIRST line for Rich visibility\n    if self.source_location:\n        location = f\"{self.source_location.filepath}:{self.source_location.line}\"\n        if self.source_location.id:\n            parts.append(f\"[{location} @ {self.source_location.id}] {self._original_message}\")\n        else:\n            parts.append(f\"[{location}] {self._original_message}\")\n    else:\n        parts.append(self._original_message)\n\n    # Add code snippet on subsequent lines (will be visible in full traceback)\n    if self.source_location:\n        snippet = self._get_config_snippet()\n        if snippet:\n            parts.append(f\"\\n\\n{snippet}\")\n\n    if self.suggestion:\n        parts.append(f\"\\n\\n  \ud83d\udca1 {self.suggestion}\")\n\n    return \"\".join(parts)\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.BaseError._get_config_snippet","title":"<code>_get_config_snippet()</code>","text":"<p>Extract and format a code snippet from the config file.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _get_config_snippet(self) -&gt; str:\n    \"\"\"Extract and format a code snippet from the config file.\"\"\"\n    if not self.source_location:\n        return \"\"\n\n    try:\n        filepath = Path(self.source_location.filepath)\n        if not filepath.exists():\n            return \"\"\n\n        with open(filepath) as f:\n            lines = f.readlines()\n\n        # Show 2 lines before and 1 line after the error\n        line_num = self.source_location.line\n        start = max(0, line_num - 3)\n        end = min(len(lines), line_num + 2)\n\n        snippet_lines = []\n        for i in range(start, end):\n            marker = \"\u2192\" if i == line_num - 1 else \" \"\n            # Use 4-digit line numbers for alignment\n            snippet_lines.append(f\"  {marker} {i + 1:4d} \u2502 {lines[i].rstrip()}\")\n\n        return \"\\n\".join(snippet_lines)\n    except Exception:\n        # If we can't read the file, just skip the snippet\n        return \"\"\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.CircularReferenceError","title":"<code>CircularReferenceError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when circular references are detected in config.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class CircularReferenceError(BaseError):\n    \"\"\"Raised when circular references are detected in config.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.ConfigKeyError","title":"<code>ConfigKeyError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when a config key is not found.</p> <p>Supports smart suggestions and available keys display.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ConfigKeyError(BaseError):\n    \"\"\"Raised when a config key is not found.\n\n    Supports smart suggestions and available keys display.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        source_location: SourceLocation | None = None,\n        suggestion: str | None = None,\n        missing_key: str | None = None,\n        available_keys: list[str] | None = None,\n        config_context: dict[str, Any] | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize ConfigKeyError with enhanced context.\n\n        Args:\n            message: Error message\n            source_location: Location where error occurred\n            suggestion: Manual suggestion (optional)\n            missing_key: The key that wasn't found\n            available_keys: List of available keys for suggestions\n            config_context: The config dict where the key wasn't found (for displaying available keys)\n        \"\"\"\n        self.missing_key = missing_key\n        self.available_keys = available_keys or []\n        self.config_context = config_context\n\n        # Auto-generate suggestion if not provided\n        if not suggestion and missing_key and available_keys:\n            suggestion = self._generate_suggestion()\n\n        super().__init__(message, source_location, suggestion)\n\n    def _generate_suggestion(self) -&gt; str | None:\n        \"\"\"Generate smart suggestion with typo detection and available keys.\"\"\"\n        from ..errors import format_available_keys, format_suggestions, get_suggestions\n\n        parts = []\n\n        # Try to find similar keys\n        if self.missing_key and self.available_keys:\n            suggestions = get_suggestions(self.missing_key, self.available_keys)\n            if suggestions:\n                parts.append(format_suggestions(suggestions))\n\n        # Show available keys if we have config context and not too many keys\n        if self.config_context and len(self.config_context) &lt;= 10:\n            available = format_available_keys(self.config_context)\n            if available:\n                if parts:\n                    parts.append(\"\")  # Blank line separator\n                parts.append(available)\n\n        return \"\\n\".join(parts) if parts else None\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.ConfigKeyError.__init__","title":"<code>__init__(message, source_location=None, suggestion=None, missing_key=None, available_keys=None, config_context=None)</code>","text":"<p>Initialize ConfigKeyError with enhanced context.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message</p> required <code>source_location</code> <code>SourceLocation | None</code> <p>Location where error occurred</p> <code>None</code> <code>suggestion</code> <code>str | None</code> <p>Manual suggestion (optional)</p> <code>None</code> <code>missing_key</code> <code>str | None</code> <p>The key that wasn't found</p> <code>None</code> <code>available_keys</code> <code>list[str] | None</code> <p>List of available keys for suggestions</p> <code>None</code> <code>config_context</code> <code>dict[str, Any] | None</code> <p>The config dict where the key wasn't found (for displaying available keys)</p> <code>None</code> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    source_location: SourceLocation | None = None,\n    suggestion: str | None = None,\n    missing_key: str | None = None,\n    available_keys: list[str] | None = None,\n    config_context: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Initialize ConfigKeyError with enhanced context.\n\n    Args:\n        message: Error message\n        source_location: Location where error occurred\n        suggestion: Manual suggestion (optional)\n        missing_key: The key that wasn't found\n        available_keys: List of available keys for suggestions\n        config_context: The config dict where the key wasn't found (for displaying available keys)\n    \"\"\"\n    self.missing_key = missing_key\n    self.available_keys = available_keys or []\n    self.config_context = config_context\n\n    # Auto-generate suggestion if not provided\n    if not suggestion and missing_key and available_keys:\n        suggestion = self._generate_suggestion()\n\n    super().__init__(message, source_location, suggestion)\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.ConfigKeyError._generate_suggestion","title":"<code>_generate_suggestion()</code>","text":"<p>Generate smart suggestion with typo detection and available keys.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>def _generate_suggestion(self) -&gt; str | None:\n    \"\"\"Generate smart suggestion with typo detection and available keys.\"\"\"\n    from ..errors import format_available_keys, format_suggestions, get_suggestions\n\n    parts = []\n\n    # Try to find similar keys\n    if self.missing_key and self.available_keys:\n        suggestions = get_suggestions(self.missing_key, self.available_keys)\n        if suggestions:\n            parts.append(format_suggestions(suggestions))\n\n    # Show available keys if we have config context and not too many keys\n    if self.config_context and len(self.config_context) &lt;= 10:\n        available = format_available_keys(self.config_context)\n        if available:\n            if parts:\n                parts.append(\"\")  # Blank line separator\n            parts.append(available)\n\n    return \"\\n\".join(parts) if parts else None\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.ConfigMergeError","title":"<code>ConfigMergeError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when configuration merge operation fails.</p> <p>This is typically raised when using operators (= or ~) incorrectly: - Using ~ on a non-existent key - Using ~ with invalid value (must be null, empty, or list) - Type mismatch during merge (e.g., trying to merge dict into list)</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ConfigMergeError(BaseError):\n    \"\"\"Raised when configuration merge operation fails.\n\n    This is typically raised when using operators (= or ~) incorrectly:\n    - Using ~ on a non-existent key\n    - Using ~ with invalid value (must be null, empty, or list)\n    - Type mismatch during merge (e.g., trying to merge dict into list)\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.EvaluationError","title":"<code>EvaluationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when evaluating an expression fails.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class EvaluationError(BaseError):\n    \"\"\"Raised when evaluating an expression fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.InstantiationError","title":"<code>InstantiationError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when instantiating a component fails.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class InstantiationError(BaseError):\n    \"\"\"Raised when instantiating a component fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.ModuleNotFoundError","title":"<code>ModuleNotFoundError</code>","text":"<p>               Bases: <code>BaseError</code></p> <p>Raised when a target module/class/function cannot be located.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>class ModuleNotFoundError(BaseError):\n    \"\"\"Raised when a _target_ module/class/function cannot be located.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/utils/exceptions/#sparkwheel.utils.exceptions.SourceLocation","title":"<code>SourceLocation</code>  <code>dataclass</code>","text":"<p>Tracks the source location of a config item.</p> Source code in <code>src/sparkwheel/utils/exceptions.py</code> <pre><code>@dataclass\nclass SourceLocation:\n    \"\"\"Tracks the source location of a config item.\"\"\"\n\n    filepath: str\n    line: int\n    column: int = 0\n    id: str = \"\"\n\n    def __str__(self) -&gt; str:\n        return f\"{self.filepath}:{self.line}\"\n</code></pre>"},{"location":"reference/utils/misc/","title":"misc","text":""},{"location":"reference/utils/misc/#sparkwheel.utils.misc.CheckKeyDuplicatesYamlLoader","title":"<code>CheckKeyDuplicatesYamlLoader</code>","text":"<p>               Bases: <code>SafeLoader</code></p> <p>YAML loader that detects duplicate keys and either warns or raises an error. Also tracks line numbers for values to enable better error reporting.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>class CheckKeyDuplicatesYamlLoader(SafeLoader):\n    \"\"\"\n    YAML loader that detects duplicate keys and either warns or raises an error.\n    Also tracks line numbers for values to enable better error reporting.\n    \"\"\"\n\n    def __init__(self, stream):\n        super().__init__(stream)\n        # Store filename if available\n        self.source_file = getattr(stream, \"name\", None)\n\n    def construct_mapping(self, node, deep=False):\n        mapping = set()\n        for key_node, _ in node.value:\n            key = self.construct_object(key_node, deep=deep)\n            if key in mapping:\n                if os.environ.get(\"SPARKWHEEL_STRICT_KEYS\", \"0\") == \"1\":\n                    raise ValueError(f\"Duplicate key: `{key}`\")\n                else:\n                    warnings.warn(f\"Duplicate key: `{key}`\", stacklevel=2)\n            mapping.add(key)\n        return super().construct_mapping(node, deep)\n\n    def construct_object(self, node, deep=False):\n        \"\"\"Construct object and attach source location metadata.\"\"\"\n        obj = super().construct_object(node, deep)\n\n        # Attach location metadata to the object if it's a dict or scalar\n        # This allows us to track where each config value came from\n        if hasattr(node, \"start_mark\") and self.source_file:\n            # Store metadata as a special attribute that we can extract later\n            # We'll use a tuple: (value, line, column, filepath)\n            if isinstance(obj, dict):\n                # For dicts, store location info in a special key\n                obj[\"__sparkwheel_metadata__\"] = {\n                    \"line\": node.start_mark.line + 1,  # YAML uses 0-indexed lines\n                    \"column\": node.start_mark.column,\n                    \"file\": self.source_file,\n                }\n\n        return obj\n</code></pre>"},{"location":"reference/utils/misc/#sparkwheel.utils.misc.CheckKeyDuplicatesYamlLoader.construct_object","title":"<code>construct_object(node, deep=False)</code>","text":"<p>Construct object and attach source location metadata.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def construct_object(self, node, deep=False):\n    \"\"\"Construct object and attach source location metadata.\"\"\"\n    obj = super().construct_object(node, deep)\n\n    # Attach location metadata to the object if it's a dict or scalar\n    # This allows us to track where each config value came from\n    if hasattr(node, \"start_mark\") and self.source_file:\n        # Store metadata as a special attribute that we can extract later\n        # We'll use a tuple: (value, line, column, filepath)\n        if isinstance(obj, dict):\n            # For dicts, store location info in a special key\n            obj[\"__sparkwheel_metadata__\"] = {\n                \"line\": node.start_mark.line + 1,  # YAML uses 0-indexed lines\n                \"column\": node.start_mark.column,\n                \"file\": self.source_file,\n            }\n\n    return obj\n</code></pre>"},{"location":"reference/utils/misc/#sparkwheel.utils.misc.check_key_duplicates","title":"<code>check_key_duplicates(ordered_pairs)</code>","text":"<p>Checks if there is a duplicated key in the sequence of <code>ordered_pairs</code>. If there is - it will log a warning or raise ValueError (if configured by environmental var <code>SPARKWHEEL_STRICT_KEYS==1</code>)</p> <p>Otherwise, it returns the dict made from this sequence.</p> <p>Note: This function is kept for compatibility but is primarily used by the YAML loader.</p> <p>Parameters:</p> Name Type Description Default <code>ordered_pairs</code> <code>list[tuple[Any, Any]]</code> <p>sequence of (key, value)</p> required Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def check_key_duplicates(ordered_pairs: list[tuple[Any, Any]]) -&gt; dict[Any, Any]:\n    \"\"\"\n    Checks if there is a duplicated key in the sequence of `ordered_pairs`.\n    If there is - it will log a warning or raise ValueError\n    (if configured by environmental var `SPARKWHEEL_STRICT_KEYS==1`)\n\n    Otherwise, it returns the dict made from this sequence.\n\n    Note: This function is kept for compatibility but is primarily used by the YAML loader.\n\n    Args:\n        ordered_pairs: sequence of (key, value)\n    \"\"\"\n    keys = set()\n    for k, _ in ordered_pairs:\n        if k in keys:\n            if os.environ.get(\"SPARKWHEEL_STRICT_KEYS\", \"0\") == \"1\":\n                raise ValueError(f\"Duplicate key: `{k}`\")\n            else:\n                warnings.warn(f\"Duplicate key: `{k}`\", stacklevel=2)\n        else:\n            keys.add(k)\n    return dict(ordered_pairs)\n</code></pre>"},{"location":"reference/utils/misc/#sparkwheel.utils.misc.ensure_tuple","title":"<code>ensure_tuple(vals)</code>","text":"<p>Returns a tuple of <code>vals</code>.</p> <p>Parameters:</p> Name Type Description Default <code>vals</code> <code>Any</code> <p>input data to convert to a tuple.</p> required Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def ensure_tuple(vals: Any) -&gt; tuple:\n    \"\"\"\n    Returns a tuple of `vals`.\n\n    Args:\n        vals: input data to convert to a tuple.\n    \"\"\"\n    return tuple(vals) if issequenceiterable(vals) else (vals,)\n</code></pre>"},{"location":"reference/utils/misc/#sparkwheel.utils.misc.first","title":"<code>first(iterable, default=None)</code>","text":"<p>Returns the first item in the given iterable or <code>default</code> if empty.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def first(iterable: Iterable[T], default: T | None = None) -&gt; T | None:\n    \"\"\"\n    Returns the first item in the given iterable or `default` if empty.\n    \"\"\"\n    for i in iterable:\n        return i\n    return default\n</code></pre>"},{"location":"reference/utils/misc/#sparkwheel.utils.misc.issequenceiterable","title":"<code>issequenceiterable(obj)</code>","text":"<p>Determine if the object is an iterable sequence and is not a string.</p> Source code in <code>src/sparkwheel/utils/misc.py</code> <pre><code>def issequenceiterable(obj: Any) -&gt; bool:\n    \"\"\"\n    Determine if the object is an iterable sequence and is not a string.\n    \"\"\"\n    try:\n        if hasattr(obj, \"ndim\") and obj.ndim == 0:\n            return False  # a 0-d tensor is not iterable\n    except Exception:\n        return False\n    return isinstance(obj, Iterable) and not isinstance(obj, (str, bytes))\n</code></pre>"},{"location":"reference/utils/module/","title":"module","text":""},{"location":"reference/utils/module/#sparkwheel.utils.module.OptionalImportError","title":"<code>OptionalImportError</code>","text":"<p>               Bases: <code>ImportError</code></p> <p>Could not import APIs from an optional dependency.</p> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>class OptionalImportError(ImportError):\n    \"\"\"\n    Could not import APIs from an optional dependency.\n    \"\"\"\n</code></pre>"},{"location":"reference/utils/module/#sparkwheel.utils.module.damerau_levenshtein_distance","title":"<code>damerau_levenshtein_distance(s1, s2)</code>","text":"<p>Calculates the Damerau\u2013Levenshtein distance between two strings for spelling correction. https://en.wikipedia.org/wiki/Damerau\u2013Levenshtein_distance</p> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def damerau_levenshtein_distance(s1: str, s2: str) -&gt; int:\n    \"\"\"\n    Calculates the Damerau\u2013Levenshtein distance between two strings for spelling correction.\n    https://en.wikipedia.org/wiki/Damerau\u2013Levenshtein_distance\n    \"\"\"\n    if s1 == s2:\n        return 0\n    string_1_length = len(s1)\n    string_2_length = len(s2)\n    if not s1:\n        return string_2_length\n    if not s2:\n        return string_1_length\n    d = {(i, -1): i + 1 for i in range(-1, string_1_length + 1)}\n    for j in range(-1, string_2_length + 1):\n        d[(-1, j)] = j + 1\n\n    for i, s1i in enumerate(s1):\n        for j, s2j in enumerate(s2):\n            cost = 0 if s1i == s2j else 1\n            d[(i, j)] = min(\n                d[(i - 1, j)] + 1,  # deletion\n                d[(i, j - 1)] + 1,  # insertion\n                d[(i - 1, j - 1)] + cost,  # substitution\n            )\n            if i and j and s1i == s2[j - 1] and s1[i - 1] == s2j:\n                d[(i, j)] = min(d[(i, j)], d[i - 2, j - 2] + cost)  # transposition\n\n    return d[string_1_length - 1, string_2_length - 1]\n</code></pre>"},{"location":"reference/utils/module/#sparkwheel.utils.module.instantiate","title":"<code>instantiate(__path, __mode, **kwargs)</code>","text":"<p>Create an object instance or call a callable object from a class or function represented by <code>__path</code>. <code>kwargs</code> will be part of the input arguments to the class constructor or function. The target component must be a class or a function, if not, return the component directly.</p> <p>Parameters:</p> Name Type Description Default <code>__path</code> <code>str</code> <p>if a string is provided, it's interpreted as the full path of the target class or function component. If a callable is provided, <code>__path(**kwargs)</code> will be invoked and returned for <code>__mode=\"default\"</code>. For <code>__mode=\"callable\"</code>, the callable will be returned as <code>__path</code> or, if <code>kwargs</code> are provided, as <code>functools.partial(__path, **kwargs)</code> for future invoking.</p> required <code>__mode</code> <code>str</code> <p>the operating mode for invoking the (callable) <code>component</code> represented by <code>__path</code>:</p> <ul> <li><code>\"default\"</code>: returns <code>component(**kwargs)</code></li> <li><code>\"callable\"</code>: returns <code>component</code> or, if <code>kwargs</code> are provided, <code>functools.partial(component, **kwargs)</code></li> <li><code>\"debug\"</code>: returns <code>pdb.runcall(component, **kwargs)</code></li> </ul> required <code>kwargs</code> <code>Any</code> <p>keyword arguments to the callable represented by <code>__path</code>.</p> <code>{}</code> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def instantiate(__path: str, __mode: str, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    Create an object instance or call a callable object from a class or function represented by ``__path``.\n    `kwargs` will be part of the input arguments to the class constructor or function.\n    The target component must be a class or a function, if not, return the component directly.\n\n    Args:\n        __path: if a string is provided, it's interpreted as the full path of the target class or function component.\n            If a callable is provided, ``__path(**kwargs)`` will be invoked and returned for ``__mode=\"default\"``.\n            For ``__mode=\"callable\"``, the callable will be returned as ``__path`` or, if ``kwargs`` are provided,\n            as ``functools.partial(__path, **kwargs)`` for future invoking.\n\n        __mode: the operating mode for invoking the (callable) ``component`` represented by ``__path``:\n\n            - ``\"default\"``: returns ``component(**kwargs)``\n            - ``\"callable\"``: returns ``component`` or, if ``kwargs`` are provided, ``functools.partial(component, **kwargs)``\n            - ``\"debug\"``: returns ``pdb.runcall(component, **kwargs)``\n\n        kwargs: keyword arguments to the callable represented by ``__path``.\n    \"\"\"\n    component = locate(__path) if isinstance(__path, str) else __path\n    if component is None:\n        raise ModuleNotFoundError(f\"Cannot locate class or function path: '{__path}'.\")\n    m = look_up_option(__mode, CompInitMode)\n    try:\n        if kwargs.pop(\"_debug_\", False) or run_debug:\n            warnings.warn(\n                f\"\\n\\npdb: instantiating component={component}, mode={m}\\n\"\n                f\"See also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n                stacklevel=2,\n            )\n            breakpoint()  # noqa: T100\n        if not callable(component):\n            warnings.warn(f\"Component {component} is not callable when mode={m}.\", stacklevel=2)\n            return component\n        if m == CompInitMode.DEFAULT:\n            return component(**kwargs)\n        if m == CompInitMode.CALLABLE:\n            return partial(component, **kwargs) if kwargs else component\n        if m == CompInitMode.DEBUG:\n            warnings.warn(\n                f\"\\n\\npdb: instantiating component={component}, mode={m}\\n\"\n                f\"See also Debugger commands documentation: https://docs.python.org/3/library/pdb.html\\n\",\n                stacklevel=2,\n            )\n            return pdb.runcall(component, **kwargs)\n    except Exception as e:\n        # Preserve the original exception type and message for better debugging\n        error_msg = (\n            f\"Failed to instantiate component '{__path}' with keywords: {','.join(kwargs.keys())}\\n\"\n            f\"  Original error ({type(e).__name__}): {str(e)}\\n\"\n            f\"  Set '_mode_={CompInitMode.DEBUG}' to enter debugging mode.\"\n        )\n        raise InstantiationError(error_msg) from e\n\n    warnings.warn(f\"Component to instantiate must represent a valid class or function, but got {__path}.\", stacklevel=2)\n    return component\n</code></pre>"},{"location":"reference/utils/module/#sparkwheel.utils.module.look_up_option","title":"<code>look_up_option(opt_str, supported, default='no_default', print_all_options=True)</code>","text":"<p>Look up the option in the supported collection and return the matched item. Raise a value error possibly with a guess of the closest match.</p> <p>Parameters:</p> Name Type Description Default <code>opt_str</code> <code>Hashable</code> <p>The option string or Enum to look up.</p> required <code>supported</code> <code>Collection | EnumMeta</code> <p>The collection of supported options, it can be list, tuple, set, dict, or Enum.</p> required <code>default</code> <code>Any</code> <p>If it is given, this method will return <code>default</code> when <code>opt_str</code> is not found, instead of raising a <code>ValueError</code>. Otherwise, it defaults to <code>\"no_default\"</code>, so that the method may raise a <code>ValueError</code>.</p> <code>'no_default'</code> <code>print_all_options</code> <code>bool</code> <p>whether to print all available options when <code>opt_str</code> is not found. Defaults to True</p> <code>True</code> <p>Examples:</p> <p>.. code-block:: python</p> <pre><code>from enum import Enum\nfrom sparkwheel.utils import look_up_option\nclass Color(Enum):\n    RED = \"red\"\n    BLUE = \"blue\"\nlook_up_option(\"red\", Color)  # &lt;Color.RED: 'red'&gt;\nlook_up_option(Color.RED, Color)  # &lt;Color.RED: 'red'&gt;\nlook_up_option(\"read\", Color)\n# ValueError: By 'read', did you mean 'red'?\n# 'read' is not a valid option.\n# Available options are {'blue', 'red'}.\nlook_up_option(\"red\", {\"red\", \"blue\"})  # \"red\"\n</code></pre> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def look_up_option(\n    opt_str: Hashable,\n    supported: Collection | enum.EnumMeta,\n    default: Any = \"no_default\",\n    print_all_options: bool = True,\n) -&gt; Any:\n    \"\"\"\n    Look up the option in the supported collection and return the matched item.\n    Raise a value error possibly with a guess of the closest match.\n\n    Args:\n        opt_str: The option string or Enum to look up.\n        supported: The collection of supported options, it can be list, tuple, set, dict, or Enum.\n        default: If it is given, this method will return `default` when `opt_str` is not found,\n            instead of raising a `ValueError`. Otherwise, it defaults to `\"no_default\"`,\n            so that the method may raise a `ValueError`.\n        print_all_options: whether to print all available options when `opt_str` is not found. Defaults to True\n\n    Examples:\n\n    .. code-block:: python\n\n        from enum import Enum\n        from sparkwheel.utils import look_up_option\n        class Color(Enum):\n            RED = \"red\"\n            BLUE = \"blue\"\n        look_up_option(\"red\", Color)  # &lt;Color.RED: 'red'&gt;\n        look_up_option(Color.RED, Color)  # &lt;Color.RED: 'red'&gt;\n        look_up_option(\"read\", Color)\n        # ValueError: By 'read', did you mean 'red'?\n        # 'read' is not a valid option.\n        # Available options are {'blue', 'red'}.\n        look_up_option(\"red\", {\"red\", \"blue\"})  # \"red\"\n    \"\"\"\n    if not isinstance(opt_str, Hashable):\n        raise ValueError(f\"Unrecognized option type: {type(opt_str)}:{opt_str}.\")\n    if isinstance(opt_str, str):\n        opt_str = opt_str.strip()\n    if isinstance(supported, enum.EnumMeta):\n        if isinstance(opt_str, str) and opt_str in {item.value for item in supported}:  # type: ignore[attr-defined]\n            # such as: \"example\" in MyEnum\n            return supported(opt_str)\n        if isinstance(opt_str, enum.Enum) and opt_str in supported:\n            # such as: MyEnum.EXAMPLE in MyEnum\n            return opt_str\n    elif isinstance(supported, dict) and opt_str in supported:\n        # such as: MyDict[key]\n        return supported[opt_str]\n    elif isinstance(supported, Collection) and opt_str in supported:\n        return opt_str\n\n    if default != \"no_default\":\n        return default\n\n    # find a close match\n    set_to_check: set\n    if isinstance(supported, enum.EnumMeta):\n        set_to_check = {item.value for item in supported}  # type: ignore[attr-defined]\n    else:\n        set_to_check = set(supported) if supported is not None else set()\n    if not set_to_check:\n        raise ValueError(f\"No options available: {supported}.\")\n    edit_dists = {}\n    opt_str = f\"{opt_str}\"\n    for key in set_to_check:\n        edit_dist = damerau_levenshtein_distance(f\"{key}\", opt_str)\n        if edit_dist &lt;= 3:\n            edit_dists[key] = edit_dist\n\n    supported_msg = f\"Available options are {set_to_check}.\\n\" if print_all_options else \"\"\n    if edit_dists:\n        guess_at_spelling = min(edit_dists, key=edit_dists.get)  # type: ignore[arg-type]\n        raise ValueError(\n            f\"By '{opt_str}', did you mean '{guess_at_spelling}'?\\n\" + f\"'{opt_str}' is not a valid value.\\n\" + supported_msg\n        )\n    raise ValueError(f\"Unsupported option '{opt_str}', \" + supported_msg)\n</code></pre>"},{"location":"reference/utils/module/#sparkwheel.utils.module.optional_import","title":"<code>optional_import(module, version='', name='')</code>","text":"<p>Imports an optional module specified by <code>module</code> string. Any importing related exceptions will be stored, and exceptions raise lazily when attempting to use the failed-to-import module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>name of the module to be imported.</p> required <code>version</code> <code>str</code> <p>version string (currently not checked, for future use).</p> <code>''</code> <code>name</code> <code>str</code> <p>a non-module attribute (such as method/class) to import from the imported module.</p> <code>''</code> <p>Returns:</p> Type Description <code>tuple[Any, bool]</code> <p>The imported module and a boolean flag indicating whether the import is successful.</p> <p>Examples::</p> <pre><code>&gt;&gt;&gt; yaml, flag = optional_import('yaml')\n&gt;&gt;&gt; print(flag)\nTrue\n\n&gt;&gt;&gt; the_module, flag = optional_import('unknown_module')\n&gt;&gt;&gt; print(flag)\nFalse\n&gt;&gt;&gt; the_module.method  # trying to access a module which is not imported\nOptionalImportError: import unknown_module (No module named 'unknown_module').\n</code></pre> Source code in <code>src/sparkwheel/utils/module.py</code> <pre><code>def optional_import(\n    module: str,\n    version: str = \"\",\n    name: str = \"\",\n) -&gt; tuple[Any, bool]:\n    \"\"\"\n    Imports an optional module specified by `module` string.\n    Any importing related exceptions will be stored, and exceptions raise lazily\n    when attempting to use the failed-to-import module.\n\n    Args:\n        module: name of the module to be imported.\n        version: version string (currently not checked, for future use).\n        name: a non-module attribute (such as method/class) to import from the imported module.\n\n    Returns:\n        The imported module and a boolean flag indicating whether the import is successful.\n\n    Examples::\n\n        &gt;&gt;&gt; yaml, flag = optional_import('yaml')\n        &gt;&gt;&gt; print(flag)\n        True\n\n        &gt;&gt;&gt; the_module, flag = optional_import('unknown_module')\n        &gt;&gt;&gt; print(flag)\n        False\n        &gt;&gt;&gt; the_module.method  # trying to access a module which is not imported\n        OptionalImportError: import unknown_module (No module named 'unknown_module').\n    \"\"\"\n    exception_str = \"\"\n    if name:\n        actual_cmd = f\"from {module} import {name}\"\n    else:\n        actual_cmd = f\"import {module}\"\n    try:\n        the_module = import_module(module)\n        if name:  # user specified to load class/function/... from the module\n            the_module = getattr(the_module, name)\n        return the_module, True\n    except Exception as import_exception:\n        exception_str = f\"{import_exception}\"\n\n    # Return a placeholder that raises on access\n    class _LazyRaise:\n        def __getattr__(self, name):\n            msg = f\"{actual_cmd}\"\n            if exception_str:\n                msg += f\" ({exception_str})\"\n            raise OptionalImportError(msg)\n\n    return _LazyRaise(), False\n</code></pre>"},{"location":"reference/utils/types/","title":"types","text":""},{"location":"user-guide/advanced/","title":"Advanced Features","text":""},{"location":"user-guide/advanced/#macros","title":"Macros (<code>%</code>)","text":"<p>Load raw YAML values from external files using <code>%</code>:</p> <pre><code># base.yaml\ndefaults:\n  learning_rate: 0.001\n\n# experiment.yaml\ntraining:\n  lr: \"%base.yaml::defaults::learning_rate\"\n</code></pre> <p>Important: <code>%</code> references get the raw YAML definition (not instantiated), while <code>@</code> references get the resolved/instantiated object from the current config.</p>"},{"location":"user-guide/advanced/#special-keys","title":"Special Keys","text":"<p>Sparkwheel recognizes these special keys in configuration:</p> <ul> <li><code>_target_</code>: Class or function path to instantiate (e.g., <code>\"torch.nn.Linear\"</code>)</li> <li><code>_disabled_</code>: Boolean or expression - skip instantiation if evaluates to <code>True</code></li> <li><code>_requires_</code>: List of dependencies to evaluate/instantiate first</li> <li><code>_mode_</code>: Operating mode for instantiation (see below)</li> </ul>"},{"location":"user-guide/advanced/#_mode_-instantiation-modes","title":"<code>_mode_</code> - Instantiation Modes","text":"<p>The <code>_mode_</code> key controls how the target is instantiated:</p> <ul> <li><code>\"default\"</code> (default): Returns <code>component(**kwargs)</code> - normal instantiation</li> <li><code>\"callable\"</code>: Returns the component itself, or <code>functools.partial(component, **kwargs)</code> if kwargs provided</li> <li><code>\"debug\"</code>: Returns <code>pdb.runcall(component, **kwargs)</code> - runs in debugger</li> </ul> <pre><code># Example: Get a callable instead of instance\nmodel_class:\n  _target_: torch.nn.Linear\n  _mode_: \"callable\"\n  in_features: 784\n  out_features: 10\n  # This returns functools.partial(torch.nn.Linear, in_features=784, out_features=10)\n  # instead of an instantiated Linear object\n\n# Example: Debug mode\nbuggy_component:\n  _target_: mymodule.BuggyClass\n  _mode_: \"debug\"  # Will run in pdb debugger\n  param: value\n</code></pre>"},{"location":"user-guide/advanced/#composition-operators","title":"Composition &amp; Operators","text":"<p>Sparkwheel uses composition-by-default: configs naturally merge (dicts) or extend (lists). Use operators for explicit control:</p>"},{"location":"user-guide/advanced/#default-behavior-composition","title":"Default Behavior: Composition","text":"<p>By default, configs compose naturally - no operators needed:</p> <pre><code># base.yaml\nmodel:\n  hidden_size: 512\n  activation: \"relu\"\n  dropout: 0.1\n</code></pre> <pre><code># override.yaml\nmodel:  # Merges by default!\n  hidden_size: 1024  # Update this\n  # activation and dropout are preserved!\n</code></pre> <pre><code>from sparkwheel import Config\n\nconfig = Config.load(\"base.yaml\")\nconfig.update(\"override.yaml\")\n\n# Result:\n# model:\n#   hidden_size: 1024  (updated)\n#   activation: \"relu\"  (preserved - composition!)\n#   dropout: 0.1        (preserved - composition!)\n</code></pre>"},{"location":"user-guide/advanced/#replace-operator","title":"Replace Operator (<code>=</code>)","text":"<p>Use <code>=key</code> when you need to completely replace instead of merge:</p> <pre><code># override.yaml\n=model:  # Replace entire model dict\n  hidden_size: 1024\n  # activation and dropout are GONE!\n</code></pre> <p>See Composition &amp; Operators for full details on composition-by-default and the <code>=</code> operator.</p>"},{"location":"user-guide/advanced/#delete-directive","title":"Delete Directive (<code>~</code>)","text":"<p>Use <code>~key: null</code> to delete a key, or <code>~key: [items]</code> to delete specific items from lists/dicts:</p> <pre><code># override.yaml\n~model::dropout: null  # Remove entire key\n\n# Remove specific list items by index\n~plugins: [0, 2, 4]  # Remove items at indices 0, 2, 4\n\n# Remove specific dict keys\n~dataloaders: [\"train\", \"test\"]  # Remove these keys\n\n# Negative indices work too\n~plugins: [-1]  # Remove last item\n</code></pre> <pre><code>config = Config.load(\"base.yaml\")\nconfig.update({\"~model::dropout\": None})  # Remove entire key\nconfig.update({\"~plugins\": [0, 2]})  # Remove list items\nconfig.update({\"~dataloaders\": [\"train\", \"test\"]})  # Remove dict keys\n</code></pre> <p>Note: The <code>~</code> directive is idempotent - it doesn't error if the key doesn't exist, enabling reusable configs.</p>"},{"location":"user-guide/advanced/#programmatic-updates","title":"Programmatic Updates","text":"<p>Apply operators programmatically:</p> <pre><code>config = Config.load(\"config.yaml\")\n\n# Set individual values\nconfig.set(\"model::hidden_size\", 1024)\n\n# Use operators\nconfig.update({\n    \"optimizer\": {\"lr\": 0.01},         # Compose (merge by default)\n    \"=database\": {\"host\": \"prod.db\"},  # Replace\n    \"~training::old_param\": None,      # Delete\n})\n</code></pre>"},{"location":"user-guide/advanced/#relative-id-references","title":"Relative ID References","text":"<p>Use relative references to navigate the config hierarchy:</p> <pre><code>model:\n  encoder:\n    hidden_size: 512\n    activation: \"relu\"\n  decoder:\n    # Reference sibling section\n    hidden_size: \"@::encoder::hidden_size\"  # Same level (model)\n    # Reference parent level\n    loss_fn: \"@::::training::loss\"  # Go up to root, then to training\n</code></pre> <p>Syntax: - <code>@::</code> - Same level (sibling) - <code>@::::</code> - Parent level - Add more <code>::</code> to go up more levels</p>"},{"location":"user-guide/advanced/#enhanced-error-messages","title":"Enhanced Error Messages","text":"<p>Sparkwheel provides helpful error messages with suggestions:</p> <pre><code>from sparkwheel import Config, ConfigKeyError\n\nconfig = Config.load({\n    \"model\": {\"hidden_size\": 512, \"num_layers\": 4},\n    \"training\": {\"batch_size\": 32}\n})\n\ntry:\n    # Typo in key name\n    value = config.resolve(\"model::hiden_size\")\nexcept ConfigKeyError as e:\n    print(e)\n    # Output:\n    # Config ID 'model::hiden_size' not found\n    #\n    # Did you mean one of these?\n    #   - model::hidden_size\n    #   - model::num_layers\n</code></pre> <p>Color output is auto-detected and respects <code>NO_COLOR</code> environment variable.</p>"},{"location":"user-guide/advanced/#globals-for-expressions","title":"Globals for Expressions","text":"<p>Pre-import modules for use in expressions:</p> <pre><code>from sparkwheel import Config\n\n# Pre-import torch for all expressions\nconfig = Config.load(\"config.yaml\", globals={\"torch\": \"torch\", \"np\": \"numpy\"})\n\n# Now expressions can use torch and np without importing\n</code></pre> <p>Example config:</p> <pre><code>device: \"$torch.device('cuda' if torch.cuda.is_available() else 'cpu')\"\ndata: \"$np.array([1, 2, 3])\"\n</code></pre>"},{"location":"user-guide/advanced/#type-hints","title":"Type Hints","text":"<pre><code>from sparkwheel import Config\n\nconfig: Config = Config.load(\"config.yaml\")\nresolved: dict = config.resolve()\n</code></pre> <p>For complete details, see the API Reference.</p>"},{"location":"user-guide/basics/","title":"Configuration Basics","text":"<p>Learn the fundamentals of Sparkwheel configuration files.</p>"},{"location":"user-guide/basics/#configuration-file-format","title":"Configuration File Format","text":"<p>Sparkwheel uses YAML for configuration:</p> <pre><code># config.yaml\nname: \"My Project\"\nversion: 1.0\nsettings:\n  debug: true\n  timeout: 30\n</code></pre> <p>YAML provides excellent readability and native support for comments, making it ideal for configuration files.</p>"},{"location":"user-guide/basics/#loading-configurations","title":"Loading Configurations","text":""},{"location":"user-guide/basics/#basic-loading","title":"Basic Loading","text":"<pre><code>from sparkwheel import Config\n\n# Load from file\nconfig = Config.load(\"config.yaml\")\n</code></pre>"},{"location":"user-guide/basics/#loading-from-dictionary","title":"Loading from Dictionary","text":"<pre><code>config_dict = {\n    \"name\": \"Test\",\n    \"value\": 42\n}\n\n# Load from dict\nconfig = Config.load(config_dict)\n</code></pre>"},{"location":"user-guide/basics/#loading-multiple-files","title":"Loading Multiple Files","text":"<pre><code># Load and merge multiple config files\nconfig = Config.load([\"base.yaml\", \"override.yaml\"])\n</code></pre>"},{"location":"user-guide/basics/#accessing-configuration-values","title":"Accessing Configuration Values","text":"<p>Sparkwheel provides two equivalent syntaxes for accessing nested configuration values:</p>"},{"location":"user-guide/basics/#two-ways-to-access-nested-values","title":"Two Ways to Access Nested Values","text":"<pre><code>config = Config.load(\"config.yaml\")\n\n# Method 1: Standard nested dictionary access\nname = config[\"name\"]\ndebug = config[\"settings\"][\"debug\"]\nlr = config[\"model\"][\"optimizer\"][\"lr\"]\n\n# Method 2: Path notation with :: separator\ndebug = config[\"settings::debug\"]\nlr = config[\"model::optimizer::lr\"]\n\n# Both methods work identically!\nassert config[\"settings\"][\"debug\"] == config[\"settings::debug\"]\n</code></pre> <p>When to use each:</p> <ul> <li>Nested access (<code>config[\"a\"][\"b\"]</code>) - Familiar Python syntax, works like any dict</li> <li>Path notation (<code>config[\"a::b\"]</code>) - More concise for deeply nested values, easier to pass as strings</li> </ul>"},{"location":"user-guide/basics/#using-get-and-resolve","title":"Using get() and resolve()","text":"<p>The same two syntaxes work with <code>get()</code> and <code>resolve()</code>:</p> <pre><code># Method 1: Nested access\nraw_value = config.get(\"model\")[\"optimizer\"][\"lr\"]\n\n# Method 2: Path notation (more convenient)\nraw_value = config.get(\"model::optimizer::lr\")\n\n# Both work with resolve() too\ndebug_mode = config.resolve(\"settings::debug\")\ndebug_mode = config.resolve(\"settings\")[\"debug\"]  # Also works\n\n# Resolve entire config\nall_config = config.resolve()\n\n# Resolve specific section\ntraining_config = config.resolve(\"training\")\n</code></pre> <p>Key difference: - <code>get()</code> returns raw values (references like <code>\"@model::lr\"</code> are not resolved) - <code>resolve()</code> resolves references, evaluates expressions, and instantiates objects</p>"},{"location":"user-guide/basics/#choosing-between-syntaxes","title":"Choosing Between Syntaxes","text":"<p>Both syntaxes have their place:</p>"},{"location":"user-guide/basics/#use-path-notation-when","title":"Use Path Notation (<code>::</code>) When:","text":"<pre><code># 1. Passing paths as function arguments\ndef get_param(config, path: str):\n    return config.get(path)\n\nlr = get_param(config, \"model::optimizer::lr\")\n\n# 2. Working with very deep nesting (more readable)\nvalue = config[\"a::b::c::d::e\"]\n\n# 3. Setting values programmatically\nconfig.set(\"model::optimizer::lr\", 0.001)\n\n# 4. Matching reference syntax in YAML\n# YAML: lr: \"@model::optimizer::base_lr\"\nbase_lr = config.get(\"model::optimizer::base_lr\")\n</code></pre>"},{"location":"user-guide/basics/#use-standard-dict-access-when","title":"Use Standard Dict Access When:","text":"<pre><code># 1. You want to work with intermediate sections\nmodel_config = config[\"model\"]\nmodel_config[\"dropout\"] = 0.1\nmodel_config[\"lr\"] = 0.001\n\n# 2. Iterating over config sections\nfor key in config[\"training\"].keys():\n    print(key, config[\"training\"][key])\n\n# 3. It feels more natural for your use case\nsettings = config[\"app\"][\"settings\"]\nif settings[\"debug\"]:\n    print(\"Debug mode enabled\")\n</code></pre>"},{"location":"user-guide/basics/#configuration-structure","title":"Configuration Structure","text":""},{"location":"user-guide/basics/#nested-structures","title":"Nested Structures","text":"<pre><code>project:\n  name: \"Sparkwheel Demo\"\n  version: 1.0\n\n  database:\n    host: \"localhost\"\n    port: 5432\n    credentials:\n      username: \"admin\"\n      password: \"secret\"\n\n  features:\n    authentication: true\n    logging: true\n</code></pre> <p>Access nested values with either syntax:</p> <pre><code># Path notation (concise)\ndb_host = config.resolve(\"project::database::host\")\nusername = config.resolve(\"project::database::credentials::username\")\n\n# Standard dict access (also works)\ndb_host = config.resolve(\"project\")[\"database\"][\"host\"]\nusername = config[\"project\"][\"database\"][\"credentials\"][\"username\"]\n</code></pre>"},{"location":"user-guide/basics/#lists-and-arrays","title":"Lists and Arrays","text":"<pre><code>colors:\n  - red\n  - green\n  - blue\n\nmatrix:\n  - [1, 2, 3]\n  - [4, 5, 6]\n  - [7, 8, 9]\n</code></pre> <p>Access list elements with either syntax:</p> <pre><code># Path notation\nfirst_color = config.resolve(\"colors::0\")  # \"red\"\nmatrix_row = config.resolve(\"matrix::1\")  # [4, 5, 6]\n\n# Standard list access\nfirst_color = config[\"colors\"][0]  # \"red\"\nmatrix_row = config[\"matrix\"][1]  # [4, 5, 6]\n</code></pre>"},{"location":"user-guide/basics/#configuration-sections","title":"Configuration Sections","text":""},{"location":"user-guide/basics/#organizing-large-configs","title":"Organizing Large Configs","text":"<p>Break large configurations into logical sections:</p> <pre><code># Application settings\napp:\n  name: \"My App\"\n  version: \"2.0.0\"\n  debug: false\n\n# Database configuration\ndatabase:\n  host: \"localhost\"\n  port: 5432\n  pool_size: 10\n\n# Logging configuration\nlogging:\n  level: \"INFO\"\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n  handlers:\n    - console\n    - file\n\n# Training configuration\ntraining:\n  batch_size: 32\n  epochs: 100\n  learning_rate: 0.001\n</code></pre>"},{"location":"user-guide/basics/#configuration-validation","title":"Configuration Validation","text":""},{"location":"user-guide/basics/#schema-validation-with-dataclasses","title":"Schema Validation with Dataclasses","text":"<p>Sparkwheel supports automatic validation using Python dataclasses. This is the recommended approach for production code:</p> <pre><code>from dataclasses import dataclass\nfrom sparkwheel import Config\n\n@dataclass\nclass AppConfig:\n    name: str\n    version: str\n    port: int\n    debug: bool = False\n\n# Validate automatically on load\nconfig = Config.load(\"config.yaml\", schema=AppConfig)\n\n# Or validate explicitly\nconfig = Config.load(\"config.yaml\")\nconfig.validate(AppConfig)\n</code></pre> <p>Schema validation provides: - Type checking: Ensures values have the correct types - Required fields: Catches missing configuration - Clear errors: Points directly to the problem with helpful messages</p> <p>See the Schema Validation Guide for complete details.</p>"},{"location":"user-guide/basics/#manual-validation","title":"Manual Validation","text":"<p>You can also validate manually:</p> <pre><code>from sparkwheel import Config\n\n# Load config\nconfig = Config.load(\"config.yaml\")\n\n# Validate required keys\nrequired_keys = [\"name\", \"version\", \"settings\"]\nfor key in required_keys:\n    if key not in config:\n        raise ValueError(f\"Missing required key: {key}\")\n\n# Validate by attempting resolution\ntry:\n    resolved = config.resolve()\n    print(\"Config resolved successfully!\")\nexcept Exception as e:\n    print(f\"Config validation failed: {e}\")\n</code></pre>"},{"location":"user-guide/basics/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/basics/#1-use-descriptive-keys","title":"1. Use Descriptive Keys","text":"<pre><code># Good\ndatabase_connection_pool_size: 10\nmax_retry_attempts: 3\n\n# Avoid\ndb_pool: 10\nretries: 3\n</code></pre>"},{"location":"user-guide/basics/#2-group-related-settings","title":"2. Group Related Settings","text":"<pre><code># Good - grouped by feature\nemail:\n  smtp_host: \"smtp.gmail.com\"\n  smtp_port: 587\n  from_address: \"noreply@example.com\"\n\n# Avoid - scattered\nsmtp_host: \"smtp.gmail.com\"\nsmtp_port: 587\nemail_from: \"noreply@example.com\"\n</code></pre>"},{"location":"user-guide/basics/#3-use-comments","title":"3. Use Comments","text":"<pre><code>training:\n  batch_size: 32  # Optimal for 16GB GPU\n  learning_rate: 0.001  # Recommended by paper X\n\n  # Experimental: improved convergence\n  warmup_steps: 1000\n</code></pre>"},{"location":"user-guide/basics/#4-separate-environment-specific-config","title":"4. Separate Environment-Specific Config","text":"<pre><code># base_config.yaml\ncommon:\n  app_name: \"My App\"\n  features:\n    caching: true\n\n# dev_config.yaml\nenvironment: development\ndebug: true\ndatabase:\n  host: \"localhost\"\n\n# prod_config.yaml\nenvironment: production\ndebug: false\ndatabase:\n  host: \"prod-db.example.com\"\n</code></pre>"},{"location":"user-guide/basics/#configuration-inheritance","title":"Configuration Inheritance","text":"<p>Load and merge multiple config files:</p> <pre><code>from sparkwheel import Config\n\n# Method 1: Load multiple files at once\nconfig = Config.load([\"base_config.yaml\", \"prod_config.yaml\"])\n\n# Method 2: Load then merge\nconfig = Config.load(\"base_config.yaml\")\nconfig.update(\"prod_config.yaml\")\n\n# Method 3: Merge Config instances\nbase = Config.load(\"base.yaml\")\ncli = Config.from_cli(\"override.yaml\", [\"model::lr=0.001\"])\nbase.merge(cli)  # Merge one Config into another\n\n# Later configs override earlier ones\nresolved = config.resolve()\n</code></pre> <p>See Composition &amp; Operators for details on composition-by-default, replace (<code>=</code>), and delete (<code>~</code>) operators.</p>"},{"location":"user-guide/basics/#special-keys","title":"Special Keys","text":"<p>Sparkwheel reserves certain keys with special meaning:</p> <ul> <li><code>_target_</code>: Specifies a class to instantiate</li> <li><code>_disabled_</code>: Skip instantiation if true</li> <li><code>_requires_</code>: Dependencies that must be resolved first</li> <li><code>_mode_</code>: Instantiation mode (default, callable, debug)</li> </ul> <p>These are covered in detail in Instantiation Guide.</p>"},{"location":"user-guide/basics/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/basics/#default-values","title":"Default Values","text":"<pre><code>defaults:\n  timeout: 30\n  retries: 3\n  debug: false\n\n# Override specific values\napi:\n  timeout: \"@defaults::timeout\"\n  retries: 5  # Override default\n  debug: \"@defaults::debug\"\n</code></pre>"},{"location":"user-guide/basics/#feature-flags","title":"Feature Flags","text":"<pre><code>features:\n  authentication: true\n  rate_limiting: true\n  caching: false\n  analytics: true\n\n# Reference in other parts\napi:\n  enable_auth: \"@features::authentication\"\n  enable_cache: \"@features::caching\"\n</code></pre>"},{"location":"user-guide/basics/#environment-variables","title":"Environment Variables","text":"<pre><code>database:\n  # Use environment variable with fallback\n  host: \"$import os; os.getenv('DB_HOST', 'localhost')\"\n  port: \"$import os; int(os.getenv('DB_PORT', '5432'))\"\n</code></pre>"},{"location":"user-guide/basics/#next-steps","title":"Next Steps","text":"<ul> <li>References - Link configuration values</li> <li>Expressions - Execute Python code</li> <li>Instantiation - Create objects from config</li> <li>Advanced Features - Power user techniques</li> </ul>"},{"location":"user-guide/cli/","title":"CLI Support","text":"<p>Parse command-line configuration overrides with built-in utilities.</p>"},{"location":"user-guide/cli/#quick-start","title":"Quick Start","text":"<pre><code>from sparkwheel import Config\n\n# Load config with CLI overrides\nconfig = Config.from_cli(\n    \"config.yaml\",\n    [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n)\n</code></pre>"},{"location":"user-guide/cli/#cli-override-format","title":"CLI Override Format","text":"<p>Overrides use path notation with <code>::</code> separators:</p> <pre><code>key::path=value\n</code></pre> <p>Examples:</p> <pre><code># Simple key\ndebug=True\n\n# Nested path\nmodel::lr=0.001\n\n# Deeply nested\nsystem::model::optimizer::lr=0.001\n</code></pre>"},{"location":"user-guide/cli/#type-parsing","title":"Type Parsing","text":"<p>Values are automatically parsed as Python literals:</p> Input Parsed As Result <code>100</code> int <code>100</code> <code>0.001</code> float <code>0.001</code> <code>True</code> bool <code>True</code> <code>None</code> None <code>None</code> <code>[0,1,2]</code> list <code>[0, 1, 2]</code> <code>{'a':1}</code> dict <code>{\"a\": 1}</code> <code>resnet50</code> str <code>\"resnet50\"</code> (fallback) <p>If parsing fails, values are kept as strings.</p>"},{"location":"user-guide/cli/#using-configfrom_cli","title":"Using Config.from_cli()","text":"<p>The easiest way to load configs with CLI overrides:</p> <pre><code>from sparkwheel import Config\n\nconfig = Config.from_cli(\n    source=\"config.yaml\",              # Config file(s)\n    cli_overrides=[\"model::lr=0.001\"], # CLI overrides\n    schema=MySchema,                   # Optional validation\n    globals={\"torch\": \"torch\"}         # Optional globals\n)\n</code></pre>"},{"location":"user-guide/cli/#parameters","title":"Parameters","text":"<ul> <li>source: File path, list of paths, or dict (same as <code>Config.load()</code>)</li> <li>cli_overrides: List of override strings in format <code>\"key::path=value\"</code></li> <li>schema: Optional dataclass schema for validation</li> <li>globals: Optional globals for expression evaluation</li> </ul>"},{"location":"user-guide/cli/#examples","title":"Examples","text":"<p>Single file with overrides:</p> <pre><code>config = Config.from_cli(\n    \"config.yaml\",\n    [\"model::lr=0.001\", \"trainer::max_epochs=100\"]\n)\n</code></pre> <p>Multiple files (merged in order):</p> <pre><code>config = Config.from_cli(\n    [\"base.yaml\", \"experiment.yaml\", \"prod.yaml\"],\n    [\"model::lr=0.001\", \"trainer::devices=[0,1,2]\"]\n)\n# Files are merged, then overrides applied\n</code></pre> <p>With schema validation:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass TrainingConfig:\n    model: dict\n    trainer: dict\n\nconfig = Config.from_cli(\n    \"config.yaml\",\n    [\"model::lr=0.001\"],\n    schema=TrainingConfig  # Validates after overrides\n)\n</code></pre> <p>No overrides:</p> <pre><code>config = Config.from_cli(\"config.yaml\", [])  # Empty list is fine\n</code></pre>"},{"location":"user-guide/cli/#building-a-cli-application","title":"Building a CLI Application","text":"<p>Sparkwheel works seamlessly with argument parsers.</p>"},{"location":"user-guide/cli/#using-argparse","title":"Using argparse","text":"<pre><code># train.py\nimport argparse\nfrom sparkwheel import Config\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"config\", help=\"Config file\")\n    parser.add_argument(\"overrides\", nargs=\"*\", help=\"Config overrides\")\n    args = parser.parse_args()\n\n    config = Config.from_cli(args.config, args.overrides)\n\n    # Use config\n    resolved = config.resolve()\n    print(f\"Training with lr={resolved['model']['lr']}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Usage:</p> <pre><code>python train.py config.yaml model::lr=0.001 trainer::max_epochs=100\n</code></pre>"},{"location":"user-guide/cli/#using-python-fire","title":"Using Python Fire","text":"<pre><code># train.py\nimport fire\nfrom sparkwheel import Config\n\nclass Trainer:\n    def fit(self, config: str, *overrides: str):\n        \"\"\"Train a model.\"\"\"\n        cfg = Config.from_cli(config, list(overrides))\n\n        resolved = cfg.resolve()\n        print(f\"Training with lr={resolved['model']['lr']}\")\n        # ... training logic ...\n\n    def test(self, config: str, *overrides: str):\n        \"\"\"Test a model.\"\"\"\n        cfg = Config.from_cli(config, list(overrides))\n        # ... testing logic ...\n\nif __name__ == \"__main__\":\n    fire.Fire(Trainer)\n</code></pre> <p>Usage:</p> <pre><code>python train.py fit config.yaml model::lr=0.001\n\npython train.py fit config.yaml \\\n  model::lr=0.001 \\\n  trainer::max_epochs=50 \\\n  trainer::devices=[0,1,2,3]\n</code></pre>"},{"location":"user-guide/cli/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/cli/#overriding-references","title":"Overriding References","text":"<p>CLI overrides work with references:</p> <pre><code># config.yaml\nbase_lr: 0.01\nmodel:\n  lr: \"@base_lr\"\n</code></pre> <pre><code>config = Config.from_cli(\n    \"config.yaml\",\n    [\"base_lr=0.001\"]  # Override the base value\n)\n\nresolved = config.resolve()\nprint(resolved[\"model\"][\"lr\"])  # 0.001 (resolved reference)\n</code></pre>"},{"location":"user-guide/cli/#overriding-in-expressions","title":"Overriding in Expressions","text":"<pre><code># config.yaml\nbatch_size: 32\nnum_batches: 100\ntotal_samples: \"$@batch_size * @num_batches\"\n</code></pre> <pre><code>config = Config.from_cli(\n    \"config.yaml\",\n    [\"batch_size=64\"]  # Change input to expression\n)\n\nresolved = config.resolve()\nprint(resolved[\"total_samples\"])  # 6400 (64 * 100)\n</code></pre>"},{"location":"user-guide/cli/#adding-new-keys","title":"Adding New Keys","text":"<p>CLI overrides can add new keys:</p> <pre><code>config = Config.from_cli(\n    {\"model\": {\"lr\": 0.01}},\n    [\n        \"model::dropout=0.1\",      # Add new key\n        \"trainer::max_epochs=100\"  # Add entire new section\n    ]\n)\n\nprint(config[\"model::dropout\"])      # 0.1\nprint(config[\"trainer::max_epochs\"]) # 100\n</code></pre>"},{"location":"user-guide/cli/#with-instantiation","title":"With Instantiation","text":"<p>CLI overrides work seamlessly with <code>_target_</code>:</p> <pre><code># config.yaml\nmodel:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n</code></pre> <pre><code>config = Config.from_cli(\n    \"config.yaml\",\n    [\"model::out_features=100\"]  # Override before instantiation\n)\n\nmodel = config.resolve(\"model\")  # Instantiates with out_features=100\n</code></pre>"},{"location":"user-guide/cli/#lower-level-api","title":"Lower-Level API","text":"<p>For more control, use parsing functions directly:</p>"},{"location":"user-guide/cli/#parse_override","title":"parse_override()","text":"<p>Parse a single override string:</p> <pre><code>from sparkwheel import parse_override\n\nkey, value = parse_override(\"model::lr=0.001\")\nprint(key)    # \"model::lr\"\nprint(value)  # 0.001 (float)\n</code></pre>"},{"location":"user-guide/cli/#parse_overrides","title":"parse_overrides()","text":"<p>Parse multiple override strings:</p> <pre><code>from sparkwheel import parse_overrides\n\noverrides = parse_overrides([\n    \"model::lr=0.001\",\n    \"trainer::max_epochs=100\",\n    \"trainer::devices=[0,1,2]\"\n])\n\nprint(overrides)\n# {\n#     \"model::lr\": 0.001,\n#     \"trainer::max_epochs\": 100,\n#     \"trainer::devices\": [0, 1, 2]\n# }\n</code></pre>"},{"location":"user-guide/cli/#manual-application","title":"Manual Application","text":"<pre><code>from sparkwheel import Config, parse_overrides\n\n# Load base config\nconfig = Config.load(\"config.yaml\")\n\n# Parse overrides\noverrides = parse_overrides([\"model::lr=0.001\"])\n\n# Apply manually\nfor key, value in overrides.items():\n    config.set(key, value)\n</code></pre>"},{"location":"user-guide/cli/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/cli/#hyperparameter-sweeps","title":"Hyperparameter Sweeps","text":"<pre><code># Sweep learning rates\nfor lr in 0.001 0.01 0.1; do\n    python train.py config.yaml model::lr=$lr\ndone\n\n# Grid search\nfor lr in 0.001 0.01; do\n    for dropout in 0.1 0.2 0.3; do\n        python train.py config.yaml \\\n            model::lr=$lr \\\n            model::dropout=$dropout\n    done\ndone\n</code></pre>"},{"location":"user-guide/cli/#environment-specific-overrides","title":"Environment-Specific Overrides","text":"<pre><code># Development\npython app.py dev.yaml debug=True\n\n# Production\npython app.py prod.yaml \\\n    database::pool_size=20 \\\n    cache::enabled=True\n</code></pre>"},{"location":"user-guide/cli/#multiple-configs-cli-overrides","title":"Multiple Configs + CLI Overrides","text":"<pre><code># Base + experiment + CLI overrides\npython train.py base.yaml,experiment.yaml \\\n    model::lr=0.001 \\\n    trainer::devices=[0,1,2,3]\n</code></pre> <p>Note: Comma-separate multiple config files.</p>"},{"location":"user-guide/cli/#debug-runs","title":"Debug Runs","text":"<pre><code># Quick debug run with overrides\npython train.py config.yaml \\\n    trainer::max_epochs=1 \\\n    trainer::fast_dev_run=True \\\n    data::subset=0.01\n</code></pre>"},{"location":"user-guide/cli/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/cli/#always-use-for-paths","title":"Always Use :: for Paths","text":"<pre><code># \u2705 Correct\nmodel::optimizer::lr=0.001\n\n# \u274c Wrong (dots are for expressions, not CLI)\nmodel.optimizer.lr=0.001\n</code></pre>"},{"location":"user-guide/cli/#quote-complex-values","title":"Quote Complex Values","text":"<p>For strings with spaces or special shell characters:</p> <pre><code># Strings with spaces\npython app.py config.yaml \"model::name=ResNet 50\"\n\n# Dicts/lists usually don't need quotes\npython app.py config.yaml model::layers=[128,256,512]\n</code></pre>"},{"location":"user-guide/cli/#validate-after-overrides","title":"Validate After Overrides","text":"<p>Use schema validation to catch override errors:</p> <pre><code>config = Config.from_cli(\n    \"config.yaml\",\n    cli_overrides,\n    schema=MySchema  # Validates after applying overrides\n)\n</code></pre>"},{"location":"user-guide/cli/#provide-sensible-defaults","title":"Provide Sensible Defaults","text":"<p>Make most overrides optional:</p> <pre><code># config.yaml - good defaults\nmodel:\n  lr: 0.001        # Sensible default\n  hidden_size: 256 # Sensible default\n\n# Users only override what they need\n# python app.py config.yaml model::lr=0.01\n</code></pre>"},{"location":"user-guide/cli/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/cli/#invalid-format","title":"Invalid Format","text":"<pre><code>from sparkwheel import parse_override\n\ntry:\n    parse_override(\"invalid_no_equals\")\nexcept ValueError as e:\n    print(e)  # \"Invalid override format: ...\"\n</code></pre>"},{"location":"user-guide/cli/#validation-errors","title":"Validation Errors","text":"<pre><code>from sparkwheel import Config, ValidationError\n\ntry:\n    config = Config.from_cli(\n        \"config.yaml\",\n        [\"model::lr=not_a_number\"],\n        schema=MySchema\n    )\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"user-guide/cli/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Basics - Core config features</li> <li>Composition &amp; Operators - Config composition with <code>=</code> and <code>~</code></li> <li>Schema Validation - Validate with dataclasses</li> </ul>"},{"location":"user-guide/expressions/","title":"Expressions","text":"<p>Execute Python code directly in your configuration files using the <code>$</code> prefix.</p>"},{"location":"user-guide/expressions/#basic-expressions","title":"Basic Expressions","text":"<pre><code># Simple math\nresult: \"$2 + 2\"  # 4\nsquare: \"$10 ** 2\"  # 100\n\n# String operations\nmessage: \"$'Hello, ' + 'World!'\"\n\n# Lists\nnumbers: \"$[1, 2, 3, 4, 5]\"\nsquares: \"$[x**2 for x in range(5)]\"\n</code></pre>"},{"location":"user-guide/expressions/#combining-with-references","title":"Combining with References","text":"<p>Expressions can use references:</p> <pre><code>training:\n  batch_size: 32\n  total_samples: 10000\n  steps_per_epoch: \"$@training::total_samples // @training::batch_size\"\n</code></pre>"},{"location":"user-guide/expressions/#importing-modules","title":"Importing Modules","text":"<p>Import Python libraries in expressions:</p> <pre><code># Math operations\npi: \"$import math; math.pi\"\nsqrt_2: \"$import math; math.sqrt(2)\"\n\n# Check for GPU\ndevice: \"$import torch; 'cuda' if torch.cuda.is_available() else 'cpu'\"\n\n# Get environment variable\ndb_host: \"$import os; os.getenv('DB_HOST', 'localhost')\"\n</code></pre>"},{"location":"user-guide/expressions/#complex-expressions","title":"Complex Expressions","text":""},{"location":"user-guide/expressions/#multi-line-logic","title":"Multi-line Logic","text":"<pre><code>learning_rate: \"$\n  0.001 if @training::batch_size &lt; 64\n  else 0.0001 if @training::batch_size &lt; 128\n  else 0.00001\n\"\n</code></pre>"},{"location":"user-guide/expressions/#list-comprehensions","title":"List Comprehensions","text":"<pre><code># Generate range\nvalues: \"$list(range(10))\"\n\n# Transform data\nscaled: \"$[x / 255.0 for x in @raw_values]\"\n\n# Filter\nevens: \"$[x for x in @numbers if x % 2 == 0]\"\n</code></pre>"},{"location":"user-guide/expressions/#function-definitions","title":"Function Definitions","text":"<pre><code># Define and call function\nprocessed: \"$\n  (lambda x: x ** 2 + 2 * x + 1)(@input_value)\n\"\n</code></pre>"},{"location":"user-guide/expressions/#calling-object-methods","title":"Calling Object Methods","text":"<p>Reference object methods when instantiation is involved:</p> <pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\noptimizer:\n  _target_: torch.optim.Adam\n  lr: 0.001\n  params: \"$@model.parameters()\"  # Call model's parameters() method\n</code></pre>"},{"location":"user-guide/expressions/#expression-scope","title":"Expression Scope","text":""},{"location":"user-guide/expressions/#global-scope","title":"Global Scope","text":"<p>Imports are added to global scope:</p> <pre><code>setup: \"$import numpy as np\"  # np is now available globally\n\ndata:\n  array: \"$np.array([1, 2, 3])\"  # Can use np here\n</code></pre>"},{"location":"user-guide/expressions/#local-variables","title":"Local Variables","text":"<p>Access config values as variables:</p> <pre><code>value_a: 10\nvalue_b: 20\nsum: \"$value_a + value_b\"  # Error: use @value_a instead\n</code></pre> <p>Use references (<code>@</code>) to access config values.</p>"},{"location":"user-guide/expressions/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/expressions/#environment-detection","title":"Environment Detection","text":"<pre><code>config:\n  is_production: \"$import os; os.getenv('ENV') == 'production'\"\n  debug: \"$not @config::is_production\"\n</code></pre>"},{"location":"user-guide/expressions/#conditional-paths","title":"Conditional Paths","text":"<pre><code>paths:\n  base: \"/data\"\n  train: \"$@paths::base + '/train' if @mode == 'train' else @paths::base + '/val'\"\n</code></pre>"},{"location":"user-guide/expressions/#dynamic-imports","title":"Dynamic Imports","text":"<pre><code>backend: \"torch\"\n\ntensor_fn: \"$\n  __import__('torch').tensor if @backend == 'torch'\n  else __import__('tensorflow').constant\n\"\n</code></pre>"},{"location":"user-guide/expressions/#calculate-derived-values","title":"Calculate Derived Values","text":"<pre><code>model:\n  input_shape: [3, 224, 224]\n  input_size: \"$@model::input_shape[0] * @model::input_shape[1] * @model::input_shape[2]\"\n</code></pre>"},{"location":"user-guide/expressions/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/expressions/#syntax-errors","title":"Syntax Errors","text":"<pre><code># Bad: Python syntax error\nresult: \"$2 +\"  # SyntaxError\n</code></pre>"},{"location":"user-guide/expressions/#runtime-errors","title":"Runtime Errors","text":"<pre><code># Bad: NameError\nresult: \"$undefined_variable\"  # Will raise error\n\n# Good: Use references\nvalue: 10\nresult: \"$@value * 2\"\n</code></pre>"},{"location":"user-guide/expressions/#safe-evaluation","title":"Safe Evaluation","text":"<p>Check before using:</p> <pre><code># Check if module exists\nhas_torch: \"$\n  try:\n      import torch\n      True\n  except ImportError:\n      False\n\"\n\ndevice: \"$'cuda' if @has_torch and torch.cuda.is_available() else 'cpu'\"\n</code></pre>"},{"location":"user-guide/expressions/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/expressions/#1-keep-expressions-simple","title":"1. Keep Expressions Simple","text":"<pre><code># Good\nsteps: \"$@samples // @batch_size\"\n\n# Avoid\nsteps: \"$\n  sum([1 for _ in range(@samples)]) //\n  (lambda x: x if x &gt; 0 else 1)(@batch_size)\n\"\n</code></pre>"},{"location":"user-guide/expressions/#2-use-comments","title":"2. Use Comments","text":"<pre><code># Calculate learning rate based on batch size\n# Formula from paper: lr = base_lr * sqrt(batch_size)\nlearning_rate: \"$0.001 * (@training::batch_size ** 0.5)\"\n</code></pre>"},{"location":"user-guide/expressions/#3-validate-expressions","title":"3. Validate Expressions","text":"<pre><code># In your Python code\nfrom sparkwheel import Config\n\ntry:\n    config = Config.load(\"config.yaml\")\n    resolved = config.resolve()\nexcept SyntaxError as e:\n    print(f\"Expression syntax error: {e}\")\nexcept Exception as e:\n    print(f\"Expression evaluation error: {e}\")\n</code></pre>"},{"location":"user-guide/expressions/#security-considerations","title":"Security Considerations","text":"<p>Expression Safety</p> <p>Expressions execute arbitrary Python code. Only load configurations from trusted sources.</p> <pre><code># Dangerous if config is from untrusted source!\ndangerous: \"$__import__('os').system('rm -rf /')\"\n</code></pre> <p>Always validate configuration sources in production.</p>"},{"location":"user-guide/expressions/#next-steps","title":"Next Steps","text":"<ul> <li>Instantiation - Create objects with expressions</li> <li>Advanced Features - Complex expression patterns</li> <li>Examples - Real-world expression usage</li> </ul>"},{"location":"user-guide/instantiation/","title":"Instantiation","text":"<p>Create Python objects directly from configuration using the <code>_target_</code> key.</p>"},{"location":"user-guide/instantiation/#basic-instantiation","title":"Basic Instantiation","text":"<pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n</code></pre> <pre><code>from sparkwheel import Config\n\nconfig = Config.load(\"config.yaml\")\n\n# Instantiate the object\nmodel = config.resolve(\"model\")\n# model is now a torch.nn.Linear(784, 10) instance!\n</code></pre>"},{"location":"user-guide/instantiation/#the-_target_-key","title":"The <code>_target_</code> Key","text":"<p><code>_target_</code> specifies the full Python path to a class or function:</p> <pre><code>examples:\n  # Class instantiation\n  linear:\n    _target_: torch.nn.Linear\n    in_features: 100\n    out_features: 10\n\n  # Class with multiple parameters\n  adam:\n    _target_: torch.optim.Adam\n    params: \"$@model.parameters()\"\n    lr: 0.001\n    betas: [0.9, 0.999]\n\n  # Custom class\n  custom:\n    _target_: myproject.models.CustomModel\n    hidden_size: 256\n</code></pre>"},{"location":"user-guide/instantiation/#nested-instantiation","title":"Nested Instantiation","text":"<p>Instantiate objects within objects:</p> <pre><code># Nested components\ntransform:\n  _target_: torchvision.transforms.Compose\n  transforms:\n    - _target_: torchvision.transforms.Resize\n      size: [224, 224]\n    - _target_: torchvision.transforms.ToTensor\n    - _target_: torchvision.transforms.Normalize\n      mean: [0.485, 0.456, 0.406]\n      std: [0.229, 0.224, 0.225]\n</code></pre>"},{"location":"user-guide/instantiation/#complex-example","title":"Complex Example","text":"<pre><code># Complete training setup\ndataset:\n  path: \"/data/cifar10\"\n\ntransform:\n  _target_: torchvision.transforms.Compose\n  transforms:\n    - _target_: torchvision.transforms.ToTensor\n    - _target_: torchvision.transforms.Normalize\n      mean: [0.5, 0.5, 0.5]\n      std: [0.5, 0.5, 0.5]\n\ndataloader:\n  _target_: torch.utils.data.DataLoader\n  dataset: \"@dataset\"\n  batch_size: 32\n  shuffle: true\n\nmodel:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\noptimizer:\n  _target_: torch.optim.Adam\n  params: \"$@model.parameters()\"\n  lr: 0.001\n</code></pre>"},{"location":"user-guide/instantiation/#special-keys","title":"Special Keys","text":""},{"location":"user-guide/instantiation/#_mode_-instantiation-modes","title":"<code>_mode_</code> - Instantiation Modes","text":"<p>Control how objects are instantiated with <code>_mode_</code>:</p> <pre><code># Default: instantiate normally\nmodel:\n  _target_: torch.nn.Linear\n  _mode_: \"default\"  # Optional, this is the default\n  in_features: 784\n  out_features: 10\n  # Returns: Linear(in_features=784, out_features=10)\n\n# Callable: return the class/function, not an instance\nmodel_factory:\n  _target_: torch.nn.Linear\n  _mode_: \"callable\"\n  in_features: 784\n  # Returns: functools.partial(torch.nn.Linear, in_features=784)\n\n# Debug: run in debugger\ndebug_component:\n  _target_: mymodule.MyClass\n  _mode_: \"debug\"\n  # Runs in pdb debugger\n</code></pre>"},{"location":"user-guide/instantiation/#other-special-keys","title":"Other Special Keys","text":"<ul> <li><code>_disabled_</code>: Skip instantiation if <code>True</code></li> <li><code>_requires_</code>: Dependencies to resolve first</li> <li><code>_target_</code>: Class or function path to instantiate</li> </ul> <p>For complete details, see the Advanced Features and API Reference.</p>"},{"location":"user-guide/operators/","title":"Composition &amp; Operators","text":"<p>Sparkwheel uses composition-by-default: configs merge naturally with just 2 operators (<code>=</code>, <code>~</code>) for explicit control.</p>"},{"location":"user-guide/operators/#composition-by-default","title":"Composition by Default","text":"<p>By default, configs compose naturally - dicts merge, lists extend:</p> <p>Dicts merge automatically:</p> <pre><code># base.yaml\nmodel:\n  hidden_size: 512\n  activation: \"relu\"\n  dropout: 0.1\n</code></pre> <pre><code># override.yaml\nmodel:\n  hidden_size: 1024  # Update this field\n  # Other fields preserved!\n</code></pre> <pre><code>config = Config.load([\"base.yaml\", \"override.yaml\"])\n# Result:\n# model:\n#   hidden_size: 1024   (updated)\n#   activation: \"relu\"  (preserved)\n#   dropout: 0.1        (preserved)\n</code></pre> <p>Lists extend automatically:</p> <pre><code># base.yaml\nplugins:\n  - logger\n  - metrics\n\n# override.yaml\nplugins:\n  - cache  # Adds to the list!\n\n# Result: [logger, metrics, cache]\n</code></pre> <p>Natural Composition</p> <p>No operators needed for the common case! Sparkwheel merges dicts and extends lists by default, matching how you naturally think about config layering.</p>"},{"location":"user-guide/operators/#the-operator-explicit-replace","title":"The <code>=</code> Operator: Explicit Replace","text":"<p>When you need to completely replace something, use <code>=key</code>:</p> <pre><code># override.yaml\n=model:  # Replace the entire model dict\n  hidden_size: 1024\n  # Old fields (activation, dropout) are GONE!\n</code></pre> <pre><code>config = Config.load([\"base.yaml\", \"override.yaml\"])\n# Result:\n# model:\n#   hidden_size: 1024  (only this remains)\n</code></pre>"},{"location":"user-guide/operators/#when-to-use","title":"When to Use <code>=</code>","text":"<p>Use <code>=</code> when you want to: - Replace an entire section with a fresh start - Change the type of a value (e.g., dict \u2192 list) - Clear out all previous settings</p> <pre><code># Replace list entirely (no extension)\n=plugins: [redis, cache]\n\n# Replace nested section\ntraining:\n  =optimizer:  # Replace optimizer, but merge training\n    type: \"sgd\"\n    lr: 0.1\n</code></pre> <p>Quoting in YAML Files</p> <p>When using <code>=</code> in YAML files, you can quote the key (<code>'=model'</code>) for clarity, but it's not required. In Python code, no quoting is needed.</p>"},{"location":"user-guide/operators/#the-operator-delete","title":"The <code>~</code> Operator: Delete","text":"<p>Remove keys or list items with <code>~key</code>:</p>"},{"location":"user-guide/operators/#delete-entire-keys","title":"Delete Entire Keys","text":"<pre><code># Remove keys (idempotent - no error if missing!)\n~old_param: null\n~debug_settings: null\n</code></pre>"},{"location":"user-guide/operators/#delete-dict-keys","title":"Delete Dict Keys","text":"<p>Use path notation for nested keys:</p> <pre><code># Path notation\n~model::dropout: null\n~training::old_params: null\n</code></pre> <p>Or structural notation:</p> <pre><code># Structural notation (works without parent operator!)\nmodel:\n  lr: 0.01           # Update\n  ~dropout: null     # Delete\n  ~batch_norm: null  # Delete\n</code></pre> <p>No Parent Context Required!</p> <p>With composition-by-default, nested <code>~</code> just works - no special parent operator needed!</p>"},{"location":"user-guide/operators/#delete-from-lists","title":"Delete from Lists","text":"<p>Remove items by index (batch syntax):</p> <pre><code># base.yaml\nplugins:\n  - logger    # 0\n  - metrics   # 1\n  - cache     # 2\n  - auth      # 3\n  - debug     # 4\n\n# override.yaml - Remove by indices\n~plugins: [0, 2, 4]  # Remove indices 0, 2, 4\n\n# Result: [metrics, auth]\n</code></pre> <p>Negative indices work too:</p> <pre><code>~plugins: [-1]      # Remove last item\n~plugins: [0, -1]   # Remove first and last\n</code></pre>"},{"location":"user-guide/operators/#delete-from-dicts","title":"Delete from Dicts","text":"<p>Remove nested dict keys by name:</p> <pre><code># base.yaml\ndataloaders:\n  train: {batch_size: 32}\n  val: {batch_size: 16}\n  test: {batch_size: 8}\n\n# override.yaml\n~dataloaders: [\"train\", \"test\"]\n\n# Result:\n# dataloaders:\n#   val: {batch_size: 16}\n</code></pre> <p>Removing List Items</p> <p>To remove items from a list, you must use the batch syntax <code>~key: [indices]</code>:</p> <pre><code># \u2713 CORRECT - Batch deletion syntax\n~plugins: [0, 2, 4]\n</code></pre> <pre><code># \u2717 WRONG - Path notation doesn't work for list items!\n~plugins::0: null\n</code></pre> <p>Why? Path notation is designed for dict keys, not list indices. The batch syntax handles index normalization and processes deletions correctly (high to low order).</p>"},{"location":"user-guide/operators/#idempotent-delete","title":"Idempotent Delete","text":"<p>Delete operations don't error if the key doesn't exist:</p> <pre><code># production.yaml - Remove debug settings if they exist\n~debug_mode: null\n~dev_logger: null\n~test_data: null\n# No errors if these don't exist!\n</code></pre> <p>This enables reusable configs that work with multiple bases:</p> <pre><code># production.yaml works with ANY base config\n~debug_settings: null\n~verbose_logging: null\ndatabase:\n  pool_size: 100\n</code></pre>"},{"location":"user-guide/operators/#combining-operators","title":"Combining Operators","text":"<p>Mix composition, replace, and delete:</p> <pre><code># base.yaml\napplication:\n  name: \"MyApp\"\n  version: 1.0\n  features:\n    auth: enabled\n    cache: enabled\n    debug: enabled\n  plugins: [logger, metrics]\n  database:\n    host: localhost\n    port: 5432\n    pool_size: 10\n\n# production.yaml\napplication:\n  version: 1.1              # Compose: update (default)\n  features:                 # Compose: merge (default)\n    cache: redis            # Update\n    ~debug: null            # Delete\n  plugins: [monitor]        # Compose: extend (default!)\n  =database:                # Replace: fresh db config\n    host: prod.example.com\n    port: 5432\n    ssl: true\n\n# Result:\n# application:\n#   name: \"MyApp\"           (preserved)\n#   version: 1.1            (updated)\n#   features:\n#     auth: enabled         (preserved)\n#     cache: redis          (updated)\n#     # debug removed\n#   plugins: [logger, metrics, monitor]  (extended!)\n#   database:               (replaced entirely)\n#     host: prod.example.com\n#     port: 5432\n#     ssl: true\n</code></pre>"},{"location":"user-guide/operators/#programmatic-usage","title":"Programmatic Usage","text":"<p>Apply operators in Python:</p> <pre><code>from sparkwheel import Config\n\nconfig = Config.load(\"base.yaml\")\n\n# Compose (merge dict) - default behavior\nconfig.update({\"model\": {\"hidden_size\": 1024}})\n\n# Replace explicitly\nconfig.update({\"=optimizer\": {\"type\": \"sgd\", \"lr\": 0.1}})\n\n# Delete keys (idempotent)\nconfig.update({\n    \"~training::old_param\": None,\n    \"~model::dropout\": None\n})\n\n# Combine operations\nconfig.update({\n    \"model\": {                      # Merge\n        \"hidden_size\": 1024,        # Update\n        \"~dropout\": None            # Delete\n    },\n    \"=database\": {                  # Replace\n        \"host\": \"prod.example.com\"\n    }\n})\n\n# Remove list items by index\nconfig.update({\"~plugins\": [0, 2, 4]})\n\n# Remove dict keys\nconfig.update({\"~dataloaders\": [\"train\", \"test\"]})\n</code></pre>"},{"location":"user-guide/operators/#merging-config-instances","title":"Merging Config Instances","text":"<p>Configs compose when merged:</p> <pre><code>base = Config.load(\"base.yaml\")\noverride = Config.load(\"override.yaml\")\n\n# Merge one Config into another (composes by default!)\nbase.update(override)\n</code></pre>"},{"location":"user-guide/operators/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/operators/#environment-specific-configs","title":"Environment-Specific Configs","text":"<pre><code># base.yaml\ndatabase:\n  host: \"localhost\"\n  port: 5432\n  pool_size: 10\n  ssl: false\n\n# production.yaml (merges automatically!)\ndatabase:\n  host: \"prod-db.example.com\"\n  ssl: true\n  pool_size: 50\n  # Other settings inherited from base\n</code></pre>"},{"location":"user-guide/operators/#experiment-variations","title":"Experiment Variations","text":"<pre><code># base_model.yaml\nmodel:\n  hidden_size: 512\n  num_layers: 6\n  dropout: 0.1\n\n# experiment_large.yaml (merges automatically!)\nmodel:\n  hidden_size: 1024\n  num_layers: 12\n\n# experiment_no_dropout.yaml (merges automatically, deletes dropout)\nmodel:\n  ~dropout: null\n</code></pre>"},{"location":"user-guide/operators/#feature-flags","title":"Feature Flags","text":"<pre><code># base.yaml\nplugins:\n  - logger\n  - metrics\n  - profiler\n  - debugger\n  - test_reporter\n\n# production.yaml - Remove debug/test plugins\n~plugins: [2, 3, 4]  # Remove profiler, debugger, test_reporter\n\n# Result: [logger, metrics]\n</code></pre>"},{"location":"user-guide/operators/#layered-configuration","title":"Layered Configuration","text":"<pre><code># Build configs in layers (all compose naturally!)\nconfig = Config.load(\"defaults.yaml\")\nconfig.update(\"models/resnet50.yaml\")\nconfig.update(\"datasets/imagenet.yaml\")\nconfig.update(\"experiments/exp_042.yaml\")\nconfig.update(\"env/production.yaml\")\n</code></pre>"},{"location":"user-guide/operators/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/operators/#leverage-composition","title":"Leverage Composition","text":"<pre><code># Good - natural composition (no operators!)\noptimizer:\n  lr: 0.01\n\n# Unnecessary - = not needed for simple updates\n=optimizer:\n  lr: 0.01\n</code></pre>"},{"location":"user-guide/operators/#use-only-when-needed","title":"Use <code>=</code> Only When Needed","text":"<pre><code># Use = when completely replacing\n=optimizer:  # Start fresh, discard all old settings\n  type: \"sgd\"\n  lr: 0.1\n\n# Default composition is usually what you want\noptimizer:   # Keep other settings, update lr\n  lr: 0.01\n</code></pre>"},{"location":"user-guide/operators/#choose-path-vs-structural-notation","title":"Choose Path vs Structural Notation","text":"<p>Use path notation for single, independent operations:</p> <pre><code># Quick single updates/deletes\n~model::dropout: null\n~training::old_param: null\n</code></pre> <p>Use structural notation for bulk related operations:</p> <pre><code># Multiple related changes\nmodel:\n  hidden_size: 1024\n  num_layers: 12\n  ~dropout: null\n  ~batch_norm: null\n</code></pre>"},{"location":"user-guide/operators/#write-reusable-configs","title":"Write Reusable Configs","text":"<p>Use idempotent delete for portable configs:</p> <pre><code># production.yaml - works with ANY base!\n~debug_mode: null        # Remove if exists\n~verbose_logging: null   # No error if missing\ndatabase:\n  pool_size: 100\n  ssl: true\n</code></pre>"},{"location":"user-guide/operators/#common-mistakes","title":"Common Mistakes","text":""},{"location":"user-guide/operators/#using-when-not-needed","title":"Using <code>=</code> When Not Needed","text":"<pre><code># Unnecessary - composition merges by default!\n=model:\n  hidden_size: 1024\n\n# Better - let it compose naturally\nmodel:\n  hidden_size: 1024\n</code></pre>"},{"location":"user-guide/operators/#expecting-list-replacement-by-default","title":"Expecting List Replacement by Default","text":"<pre><code># This EXTENDS the list (doesn't replace)\nplugins: [cache]\n\n# Use = to replace\n=plugins: [cache]\n</code></pre>"},{"location":"user-guide/operators/#wrong-list-deletion-syntax","title":"Wrong List Deletion Syntax","text":"<pre><code># Wrong - path notation doesn't work for list indices\n~plugins::0: null\n\n# Correct - use batch syntax\n~plugins: [0]\n</code></pre>"},{"location":"user-guide/operators/#forgetting-quotes-for-operators","title":"Forgetting Quotes for Operators","text":"<pre><code># Wrong - YAML might misinterpret\n=model:\n  lr: 0.001\n\n# Safer - quote operators (optional but clearer)\n'=model':\n  lr: 0.001\n</code></pre>"},{"location":"user-guide/operators/#comparison-with-other-systems","title":"Comparison with Other Systems","text":""},{"location":"user-guide/operators/#vs-hydra","title":"vs Hydra","text":"Feature Hydra Sparkwheel Dict merge default Yes \u2705 Yes \u2705 List extend default No \u274c Yes \u2705 Operators in YAML No \u274c Yes \u2705 (<code>=</code>, <code>~</code>) Operator count 4 (<code>+</code>, <code>++</code>, <code>~</code>) 2 (<code>=</code>, <code>~</code>) \u2705 Delete dict keys No \u274c Yes \u2705 Delete list items No \u274c Yes \u2705 Idempotent delete N/A Yes \u2705 <p>Sparkwheel goes beyond Hydra with: - Full composition-first philosophy (dicts and lists) - Operators directly in YAML files - Just 2 simple operators - Delete operations for fine-grained control</p>"},{"location":"user-guide/operators/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Basics - Core config management</li> <li>Advanced Features - Macros and power features</li> <li>Examples - Real-world patterns</li> </ul>"},{"location":"user-guide/references/","title":"References","text":"<p>Sparkwheel provides two types of references for linking configuration values:</p> <ul> <li><code>@</code> - Resolved References: Get the final, instantiated/evaluated value</li> <li><code>%</code> - Raw References: Get the unprocessed YAML content</li> </ul>"},{"location":"user-guide/references/#resolved-references","title":"Resolved References (<code>@</code>)","text":"<p>Use <code>@</code> followed by the key path with <code>::</code> separator to reference resolved values (after instantiation, expression evaluation, etc.):</p> <pre><code>dataset:\n  path: \"/data/images\"\n  num_classes: 10\n  batch_size: 32\n\nmodel:\n  num_outputs: \"@dataset::num_classes\"\n\ntraining:\n  batch: \"@dataset::batch_size\"\n</code></pre> <pre><code>config = Config.load(\"config.yaml\")\n\n# References are resolved when you call resolve()\nnum_outputs = config.resolve(\"model::num_outputs\")  # 10\nbatch = config.resolve(\"training::batch\")  # 32\n</code></pre>"},{"location":"user-guide/references/#list-references","title":"List References","text":"<p>Reference list elements by index (0-based):</p> <pre><code>transforms:\n  - resize\n  - normalize\n  - augment\n\nfirst_transform: \"@transforms::0\"  # \"resize\"\nlast_transform: \"@transforms::2\"   # \"augment\"\n</code></pre>"},{"location":"user-guide/references/#nested-references","title":"Nested References","text":"<p>References can reference other references:</p> <pre><code>base:\n  value: 100\n\nderived:\n  double: \"$@base::value * 2\"  # 200\n\nfinal:\n  quad: \"$@derived::double * 2\"  # 400\n</code></pre>"},{"location":"user-guide/references/#resolution-order","title":"Resolution Order","text":"<p>Sparkwheel resolves references in dependency order:</p> <pre><code>a: 10\nb: \"@a\"              # Resolved first\nc: \"$@a + @b\"        # Resolved after a and b\nd: \"$@c * 2\"         # Resolved last\n</code></pre>"},{"location":"user-guide/references/#circular-references","title":"Circular References","text":"<p>Circular references raise an error:</p> <pre><code># This will fail!\na: \"@b\"\nb: \"@a\"\n</code></pre>"},{"location":"user-guide/references/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"user-guide/references/#conditional-references","title":"Conditional References","text":"<pre><code>environment: \"production\"\n\ndatabase:\n  prod_host: \"prod.db.example.com\"\n  dev_host: \"localhost\"\n  host: \"$@database::prod_host if @environment == 'production' else @database::dev_host\"\n</code></pre>"},{"location":"user-guide/references/#dynamic-selection","title":"Dynamic Selection","text":"<pre><code>datasets:\n  train: \"/data/train\"\n  test: \"/data/test\"\n  val: \"/data/val\"\n\nmode: \"train\"\ncurrent_dataset: \"$@datasets[@mode]\"  # Dynamically select based on mode\n</code></pre> <p>Note: This requires Python expression evaluation.</p>"},{"location":"user-guide/references/#raw-references","title":"Raw References (<code>%</code>)","text":"<p>Use <code>%</code> to reference raw YAML content (unprocessed, before instantiation/evaluation). Works with both external files and within the same file:</p>"},{"location":"user-guide/references/#external-file-raw-references","title":"External File Raw References","text":"<pre><code># base.yaml\ndefaults:\n  learning_rate: 0.001\n  batch_size: 32\n\nmodel:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\n# experiment.yaml\ntraining:\n  lr: \"%base.yaml::defaults::learning_rate\"  # Gets raw value: 0.001\n  batch: \"%base.yaml::defaults::batch_size\"   # Gets raw value: 32\n\n# Gets the raw dict definition (with _target_), NOT the instantiated object\nmodel_template: \"%base.yaml::model\"\n</code></pre>"},{"location":"user-guide/references/#local-raw-references","title":"Local Raw References","text":"<pre><code># config.yaml\ndefaults:\n  timeout: 30\n  retries: 3\n\n# Copy raw YAML from same file\napi_config:\n  timeout: \"%defaults::timeout\"  # Gets raw value: 30\n\n# Copy entire section\nbackup_defaults: \"%defaults\"  # Gets the whole defaults dict\n</code></pre>"},{"location":"user-guide/references/#key-distinction","title":"Key Distinction","text":"Reference Type Symbol What You Get When To Use Resolved Reference <code>@</code> Final value after instantiation/evaluation When you want the computed result or object instance Raw Reference <code>%</code> Unprocessed YAML content When you want to copy/reuse configuration definitions <p>Example showing the difference:</p> <pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\n# Resolved reference - gets the actual instantiated torch.nn.Linear object\ntrained_model: \"@model\"\n\n# Raw reference - gets the raw dict with _target_, in_features, out_features\nmodel_config_copy: \"%model\"\n</code></pre> <p>See Advanced Features for more on raw references.</p>"},{"location":"user-guide/references/#common-use-cases","title":"Common Use Cases","text":""},{"location":"user-guide/references/#shared-hyperparameters","title":"Shared Hyperparameters","text":"<pre><code># Single source of truth\nmodel_config:\n  hidden_size: 512\n\nencoder:\n  size: \"@model_config::hidden_size\"\n\ndecoder:\n  size: \"@model_config::hidden_size\"\n</code></pre>"},{"location":"user-guide/references/#computed-values","title":"Computed Values","text":"<pre><code>dataset:\n  samples: 10000\n  batch_size: 32\n\ntraining:\n  steps: \"$@dataset::samples // @dataset::batch_size\"  # 312\n</code></pre>"},{"location":"user-guide/references/#object-parameters","title":"Object Parameters","text":"<pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n\noptimizer:\n  _target_: torch.optim.Adam\n  params: \"$@model.parameters()\"  # Call model's method\n  lr: 0.001\n</code></pre>"},{"location":"user-guide/references/#next-steps","title":"Next Steps","text":"<ul> <li>Expressions - Execute Python code in configs</li> <li>Instantiation - Create objects with references</li> <li>Advanced Features - Complex reference patterns</li> </ul>"},{"location":"user-guide/schema-validation/","title":"Schema Validation","text":"<p>Validate configurations at runtime using Python dataclasses.</p>"},{"location":"user-guide/schema-validation/#quick-start","title":"Quick Start","text":"<p>Define a schema with dataclasses:</p> <pre><code>from dataclasses import dataclass\nfrom sparkwheel import Config\n\n@dataclass\nclass AppConfig:\n    name: str\n    port: int\n    debug: bool = False\n\n# Validate on load\nconfig = Config.load(\"config.yaml\", schema=AppConfig)\n\n# Or validate explicitly\nconfig = Config.load(\"config.yaml\")\nconfig.validate(AppConfig)\n</code></pre> <p>If validation fails, you get clear errors:</p> <pre><code># config.yaml:\n# name: \"myapp\"\n# port: \"not a number\"  # Wrong type!\n\nconfig = Config.load(\"config.yaml\", schema=AppConfig)\n# ValidationError: Validation error at 'port': Type mismatch\n#   Expected type: int\n#   Actual type: str\n#   Actual value: 'not a number'\n</code></pre>"},{"location":"user-guide/schema-validation/#defining-schemas","title":"Defining Schemas","text":"<p>Schemas are Python dataclasses with type hints.</p>"},{"location":"user-guide/schema-validation/#basic-types","title":"Basic Types","text":"<pre><code>@dataclass\nclass Config:\n    text: str\n    count: int\n    ratio: float\n    enabled: bool\n    items: list[str]\n    mapping: dict[str, int]\n</code></pre>"},{"location":"user-guide/schema-validation/#optional-fields","title":"Optional Fields","text":"<pre><code>from typing import Optional\n\n@dataclass\nclass Config:\n    required: str\n    optional_with_none: Optional[int] = None\n    optional_with_default: int = 42\n</code></pre>"},{"location":"user-guide/schema-validation/#nested-dataclasses","title":"Nested Dataclasses","text":"<pre><code>@dataclass\nclass DatabaseConfig:\n    host: str\n    port: int\n    pool_size: int = 10\n\n@dataclass\nclass AppConfig:\n    database: DatabaseConfig  # Nested\n    secret_key: str\n</code></pre> <p>Corresponding YAML:</p> <pre><code>database:\n  host: localhost\n  port: 5432\n  # pool_size uses default\n\nsecret_key: my-secret\n</code></pre>"},{"location":"user-guide/schema-validation/#lists-of-dataclasses","title":"Lists of Dataclasses","text":"<pre><code>@dataclass\nclass PluginConfig:\n    name: str\n    enabled: bool = True\n\n@dataclass\nclass AppConfig:\n    plugins: list[PluginConfig]\n</code></pre> <pre><code>plugins:\n  - name: logger\n    enabled: true\n  - name: metrics\n  - name: cache\n    enabled: false\n</code></pre>"},{"location":"user-guide/schema-validation/#dictionaries-with-dataclass-values","title":"Dictionaries with Dataclass Values","text":"<pre><code>@dataclass\nclass ModelConfig:\n    hidden_size: int\n    dropout: float\n\n@dataclass\nclass Config:\n    models: dict[str, ModelConfig]\n</code></pre> <pre><code>models:\n  small:\n    hidden_size: 128\n    dropout: 0.1\n  large:\n    hidden_size: 512\n    dropout: 0.2\n</code></pre>"},{"location":"user-guide/schema-validation/#custom-validation","title":"Custom Validation","text":"<p>Add validation logic with <code>@validator</code>:</p> <pre><code>from sparkwheel import validator\n\n@dataclass\nclass TrainingConfig:\n    lr: float\n    batch_size: int\n\n    @validator\n    def check_lr(self):\n        \"\"\"Validate learning rate.\"\"\"\n        if not (0 &lt; self.lr &lt; 1):\n            raise ValueError(f\"lr must be between 0 and 1, got {self.lr}\")\n\n    @validator\n    def check_batch_size(self):\n        \"\"\"Validate batch size is power of 2.\"\"\"\n        if self.batch_size &lt;= 0:\n            raise ValueError(\"batch_size must be positive\")\n        if self.batch_size &amp; (self.batch_size - 1) != 0:\n            raise ValueError(\"batch_size must be power of 2\")\n</code></pre>"},{"location":"user-guide/schema-validation/#cross-field-validation","title":"Cross-Field Validation","text":"<p>Validators can check relationships between fields:</p> <pre><code>@dataclass\nclass Config:\n    start_epoch: int\n    end_epoch: int\n    warmup_epochs: int\n\n    @validator\n    def check_epochs(self):\n        \"\"\"Ensure epoch configuration is valid.\"\"\"\n        if self.end_epoch &lt;= self.start_epoch:\n            raise ValueError(\"end_epoch must be &gt; start_epoch\")\n        if self.warmup_epochs &gt;= (self.end_epoch - self.start_epoch):\n            raise ValueError(\"warmup_epochs too large\")\n</code></pre>"},{"location":"user-guide/schema-validation/#with-optional-fields","title":"With Optional Fields","text":"<pre><code>@dataclass\nclass Config:\n    value: float\n    max_value: Optional[float] = None\n\n    @validator\n    def check_max(self):\n        \"\"\"Check value doesn't exceed max if specified.\"\"\"\n        if self.max_value is not None and self.value &gt; self.max_value:\n            raise ValueError(f\"value ({self.value}) exceeds max_value ({self.max_value})\")\n</code></pre> <p>Note: Validators run after type checking. If types are wrong, validation stops there.</p>"},{"location":"user-guide/schema-validation/#discriminated-unions","title":"Discriminated Unions","text":"<p>Use tagged unions for type-safe variants:</p> <pre><code>from typing import Literal, Union\n\n@dataclass\nclass SGDOptimizer:\n    type: Literal[\"sgd\"]  # Discriminator\n    lr: float\n    momentum: float = 0.9\n\n@dataclass\nclass AdamOptimizer:\n    type: Literal[\"adam\"]  # Discriminator\n    lr: float\n    beta1: float = 0.9\n\n@dataclass\nclass Config:\n    optimizer: Union[SGDOptimizer, AdamOptimizer]\n</code></pre> <p>YAML:</p> <pre><code>optimizer:\n  type: sgd  # Selects SGDOptimizer\n  lr: 0.01\n  momentum: 0.95\n</code></pre> <p>Sparkwheel detects <code>type</code> as a discriminator and validates against the matching schema.</p> <p>Error examples:</p> <pre><code># Missing discriminator\n{\"optimizer\": {\"lr\": 0.01}}\n# ValidationError: Missing discriminator field 'type'\n\n# Invalid value\n{\"optimizer\": {\"type\": \"rmsprop\", \"lr\": 0.01}}\n# ValidationError: Invalid discriminator value 'rmsprop'. Valid: 'sgd', 'adam'\n\n# Wrong fields for type\n{\"optimizer\": {\"type\": \"adam\", \"momentum\": 0.9}}\n# ValidationError: Missing required field 'lr'\n</code></pre>"},{"location":"user-guide/schema-validation/#with-sparkwheel-features","title":"With Sparkwheel Features","text":"<p>Validation works with references, expressions, and instantiation.</p>"},{"location":"user-guide/schema-validation/#references","title":"References","text":"<pre><code>@dataclass\nclass Config:\n    base_lr: float\n    optimizer_lr: float  # Can be a reference\n\nconfig = Config.load({\n    \"base_lr\": 0.001,\n    \"optimizer_lr\": \"@base_lr\"  # Reference allowed\n}, schema=Config)\n</code></pre>"},{"location":"user-guide/schema-validation/#expressions","title":"Expressions","text":"<pre><code>@dataclass\nclass Config:\n    batch_size: int\n    total_steps: int  # Computed\n\nconfig = Config.load({\n    \"batch_size\": 32,\n    \"total_steps\": \"$@batch_size * 100\"  # Expression allowed\n}, schema=Config)\n</code></pre>"},{"location":"user-guide/schema-validation/#instantiation","title":"Instantiation","text":"<p>Special keys like <code>_target_</code> are automatically ignored:</p> <pre><code>@dataclass\nclass OptimizerConfig:\n    lr: float\n    momentum: float = 0.9\n\nconfig = Config.load({\n    \"_target_\": \"torch.optim.SGD\",  # Ignored by validation\n    \"lr\": 0.001,\n    \"momentum\": 0.95\n}, schema=OptimizerConfig)\n</code></pre>"},{"location":"user-guide/schema-validation/#error-messages","title":"Error Messages","text":""},{"location":"user-guide/schema-validation/#type-mismatch","title":"Type Mismatch","text":"<pre><code># Expected int, got str\n# ValidationError: Validation error at 'port': Type mismatch\n#   Expected type: int\n#   Actual type: str\n#   Actual value: '8080'\n</code></pre>"},{"location":"user-guide/schema-validation/#missing-field","title":"Missing Field","text":"<pre><code># ValidationError: Validation error at 'required_field':\n#   Missing required field 'required_field'\n#   Expected type: str\n</code></pre>"},{"location":"user-guide/schema-validation/#unexpected-field","title":"Unexpected Field","text":"<pre><code># ValidationError: Validation error at 'unexpected':\n#   Unexpected field 'unexpected' not in schema Config\n</code></pre>"},{"location":"user-guide/schema-validation/#nested-errors","title":"Nested Errors","text":"<pre><code># ValidationError: Validation error at 'database.port': Type mismatch\n#   Expected type: int\n#   Actual type: str\n#   Actual value: 'wrong'\n</code></pre>"},{"location":"user-guide/schema-validation/#validation-timing","title":"Validation Timing","text":""},{"location":"user-guide/schema-validation/#on-load-recommended","title":"On Load (Recommended)","text":"<pre><code>config = Config.load(\"config.yaml\", schema=MySchema)\n# Raises ValidationError immediately\n</code></pre>"},{"location":"user-guide/schema-validation/#explicit","title":"Explicit","text":"<pre><code>config = Config.load(\"config.yaml\")\n# ... maybe modify ...\nconfig.validate(MySchema)\n</code></pre>"},{"location":"user-guide/schema-validation/#standalone-function","title":"Standalone Function","text":"<pre><code>from sparkwheel import validate\n\nvalidate(config_dict, AppSchema)\n</code></pre>"},{"location":"user-guide/schema-validation/#complete-example","title":"Complete Example","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Optional\nfrom sparkwheel import Config, validator\n\n@dataclass\nclass DatabaseConfig:\n    host: str\n    port: int\n    database: str\n    username: str\n    password: str\n    pool_size: int = 10\n    timeout: int = 30\n\n@dataclass\nclass APIConfig:\n    host: str = \"0.0.0.0\"\n    port: int = 8000\n    workers: int = 4\n\n    @validator\n    def check_port(self):\n        if not (1024 &lt;= self.port &lt;= 65535):\n            raise ValueError(f\"port must be 1024-65535, got {self.port}\")\n\n@dataclass\nclass AppConfig:\n    app_name: str\n    environment: str\n    debug: bool = False\n    api: APIConfig\n    database: DatabaseConfig\n\n# Load and validate\nconfig = Config.load(\"production.yaml\", schema=AppConfig)\n\n# Access validated config\nprint(f\"Starting {config['app_name']} on port {config['api::port']}\")\n</code></pre> <p>The YAML:</p> <pre><code>app_name: \"My API\"\nenvironment: production\ndebug: false\n\napi:\n  port: 3000\n  workers: 8\n\ndatabase:\n  host: db.example.com\n  port: 5432\n  database: myapp\n  username: \"$import os; os.getenv('DB_USER')\"\n  password: \"$import os; os.getenv('DB_PASSWORD')\"\n  pool_size: 20\n</code></pre>"},{"location":"user-guide/schema-validation/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Basics - Learn config management</li> <li>References - Link values with @</li> <li>Expressions - Compute values with $</li> </ul>"}]}